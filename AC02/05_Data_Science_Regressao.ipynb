{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdjdKRIg1k3E"
      },
      "source": [
        "# Redes Neurais: Problemas de Regressão\n",
        "\n",
        "Autor:\n",
        "- Larissa Ionafa RA:1903166\n",
        "- Roberta Yumi Romero Takahashi RA:1903220"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1qL5M8g3c0C"
      },
      "source": [
        "# Atividade\n",
        "\n",
        "A base '05_df_treino_teste.csv' envolve características de imóveis e o preço de venda desses respectivos imóveis. Nessa base contém um conjunto variáveis explicativas. **Algumas dessas variáveis** são geradas após a venda do imóvel. Por esse motivo, na base '05_validacao.csv', constam menos colunas.\n",
        "\n",
        "Da atividade:\n",
        "1. Tratamento de dados: tratamento de missing, conversão de variável categórica para numérica e criação de novas variáveis;\n",
        "2. Teste diferentes arquiteturas de redes neurais, utilizando a base '05_df_treino_teste.csv'. Não esqueça de dividir entre treino e teste.\n",
        "3. Faça a predição na base '05_validacao.csv'. Cada grupo poderá enviar até 3 colunas de predição. É obrigatório enviar a coluna PRT_ID e as três colunas de predição.\n",
        "\n",
        "Lembrem-se que a coluna **PRT_ID** não é uma variável explicativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu-5PE9l1pJD"
      },
      "source": [
        "## Lendo as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vp3d0i551NPW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score,mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "klEgrMmG_5zH"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sseoduvS1qzf"
      },
      "outputs": [],
      "source": [
        "# Define a semente\n",
        "seed_value = 2023\n",
        "tf.random.set_seed(seed_value)\n",
        "np.random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdseiXeA113S"
      },
      "source": [
        "## Base de Dados Chennai_House_Price_Prediction\n",
        "\n",
        "* Fonte: https://www.kaggle.com/code/prabhulpradeepkumar/chennai-house-price-prediction\n",
        "\n",
        "Há tanto o banco de dados quanto um dicionário de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "AkB2fu2W2YXN",
        "outputId": "e07ac3ee-ef6d-45c2-f214-16d5760d892d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRT_ID</th>\n",
              "      <th>AREA</th>\n",
              "      <th>INT_SQFT</th>\n",
              "      <th>DATE_SALE</th>\n",
              "      <th>DIST_MAINROAD</th>\n",
              "      <th>N_BEDROOM</th>\n",
              "      <th>N_BATHROOM</th>\n",
              "      <th>N_ROOM</th>\n",
              "      <th>SALE_COND</th>\n",
              "      <th>PARK_FACIL</th>\n",
              "      <th>DATE_BUILD</th>\n",
              "      <th>BUILDTYPE</th>\n",
              "      <th>UTILITY_AVAIL</th>\n",
              "      <th>STREET</th>\n",
              "      <th>MZZONE</th>\n",
              "      <th>QS_ROOMS</th>\n",
              "      <th>QS_BATHROOM</th>\n",
              "      <th>QS_BEDROOM</th>\n",
              "      <th>QS_OVERALL</th>\n",
              "      <th>REG_FEE</th>\n",
              "      <th>COMMIS</th>\n",
              "      <th>SALES_PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>P07626</td>\n",
              "      <td>KK Nagar</td>\n",
              "      <td>1733</td>\n",
              "      <td>17-09-2008</td>\n",
              "      <td>148</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>AbNormal</td>\n",
              "      <td>No</td>\n",
              "      <td>21-09-1993</td>\n",
              "      <td>Commercial</td>\n",
              "      <td>NoSeWa</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>RL</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.9</td>\n",
              "      <td>4.180</td>\n",
              "      <td>709109</td>\n",
              "      <td>132958</td>\n",
              "      <td>14773100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>P04588</td>\n",
              "      <td>Karapakkam</td>\n",
              "      <td>1459</td>\n",
              "      <td>04-08-2010</td>\n",
              "      <td>35</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Partial</td>\n",
              "      <td>Yes</td>\n",
              "      <td>06-08-2002</td>\n",
              "      <td>House</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>RH</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.260</td>\n",
              "      <td>333648</td>\n",
              "      <td>207403</td>\n",
              "      <td>9017500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>P00161</td>\n",
              "      <td>Anna Nagar</td>\n",
              "      <td>1854</td>\n",
              "      <td>02-11-2014</td>\n",
              "      <td>120</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Normal Sale</td>\n",
              "      <td>Yes</td>\n",
              "      <td>07-11-1993</td>\n",
              "      <td>Others</td>\n",
              "      <td>ELO</td>\n",
              "      <td>No Access</td>\n",
              "      <td>RL</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.750</td>\n",
              "      <td>404223</td>\n",
              "      <td>236959</td>\n",
              "      <td>13938740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>P08529</td>\n",
              "      <td>Anna Nagar</td>\n",
              "      <td>1617</td>\n",
              "      <td>20-11-2007</td>\n",
              "      <td>58</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>AdjLand</td>\n",
              "      <td>Yes</td>\n",
              "      <td>21-11-2001</td>\n",
              "      <td>House</td>\n",
              "      <td>ELO</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>RM</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.665</td>\n",
              "      <td>367007</td>\n",
              "      <td>211735</td>\n",
              "      <td>14115670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>P05833</td>\n",
              "      <td>Karapakkam</td>\n",
              "      <td>725</td>\n",
              "      <td>13-12-2009</td>\n",
              "      <td>147</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>AdjLand</td>\n",
              "      <td>Yes</td>\n",
              "      <td>21-12-1976</td>\n",
              "      <td>House</td>\n",
              "      <td>ELO</td>\n",
              "      <td>Paved</td>\n",
              "      <td>C</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.670</td>\n",
              "      <td>178317</td>\n",
              "      <td>49533</td>\n",
              "      <td>4953250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      PRT_ID        AREA  INT_SQFT   DATE_SALE  DIST_MAINROAD  N_BEDROOM  \\\n",
              "4995  P07626    KK Nagar      1733  17-09-2008            148        2.0   \n",
              "4996  P04588  Karapakkam      1459  04-08-2010             35        2.0   \n",
              "4997  P00161  Anna Nagar      1854  02-11-2014            120        2.0   \n",
              "4998  P08529  Anna Nagar      1617  20-11-2007             58        1.0   \n",
              "4999  P05833  Karapakkam       725  13-12-2009            147        1.0   \n",
              "\n",
              "      N_BATHROOM  N_ROOM    SALE_COND PARK_FACIL  DATE_BUILD   BUILDTYPE  \\\n",
              "4995         1.0       4     AbNormal         No  21-09-1993  Commercial   \n",
              "4996         2.0       4      Partial        Yes  06-08-2002       House   \n",
              "4997         1.0       5  Normal Sale        Yes  07-11-1993      Others   \n",
              "4998         1.0       4      AdjLand        Yes  21-11-2001       House   \n",
              "4999         1.0       2      AdjLand        Yes  21-12-1976       House   \n",
              "\n",
              "     UTILITY_AVAIL     STREET MZZONE  QS_ROOMS  QS_BATHROOM  QS_BEDROOM  \\\n",
              "4995        NoSeWa     Gravel     RL       2.9          4.5         4.9   \n",
              "4996        AllPub     Gravel     RH       2.0          3.0         4.4   \n",
              "4997           ELO  No Access     RL       2.3          3.3         2.8   \n",
              "4998           ELO     Gravel     RM       3.9          4.4         3.0   \n",
              "4999           ELO      Paved      C       2.0          3.7         2.4   \n",
              "\n",
              "      QS_OVERALL  REG_FEE  COMMIS  SALES_PRICE  \n",
              "4995       4.180   709109  132958     14773100  \n",
              "4996       3.260   333648  207403      9017500  \n",
              "4997       2.750   404223  236959     13938740  \n",
              "4998       3.665   367007  211735     14115670  \n",
              "4999       2.670   178317   49533      4953250  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treino = pd.read_csv('./05_df_treino_teste.csv')\n",
        "df_treino.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRT_ID</th>\n",
              "      <th>AREA</th>\n",
              "      <th>INT_SQFT</th>\n",
              "      <th>DIST_MAINROAD</th>\n",
              "      <th>N_BEDROOM</th>\n",
              "      <th>N_BATHROOM</th>\n",
              "      <th>N_ROOM</th>\n",
              "      <th>SALE_COND</th>\n",
              "      <th>PARK_FACIL</th>\n",
              "      <th>DATE_BUILD</th>\n",
              "      <th>BUILDTYPE</th>\n",
              "      <th>UTILITY_AVAIL</th>\n",
              "      <th>STREET</th>\n",
              "      <th>MZZONE</th>\n",
              "      <th>QS_ROOMS</th>\n",
              "      <th>QS_BATHROOM</th>\n",
              "      <th>QS_BEDROOM</th>\n",
              "      <th>QS_OVERALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2104</th>\n",
              "      <td>P09034</td>\n",
              "      <td>Anna Nagar</td>\n",
              "      <td>1838</td>\n",
              "      <td>31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>AdjLand</td>\n",
              "      <td>Yes</td>\n",
              "      <td>16/05/1971</td>\n",
              "      <td>Commercial</td>\n",
              "      <td>ELO</td>\n",
              "      <td>No Access</td>\n",
              "      <td>RH</td>\n",
              "      <td>2.7</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>3.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>P02617</td>\n",
              "      <td>Chrompet</td>\n",
              "      <td>1191</td>\n",
              "      <td>189</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Partial</td>\n",
              "      <td>Yes</td>\n",
              "      <td>07/09/1988</td>\n",
              "      <td>House</td>\n",
              "      <td>ELO</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>RL</td>\n",
              "      <td>4.1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>3.7</td>\n",
              "      <td>3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>P03449</td>\n",
              "      <td>KK Nagar</td>\n",
              "      <td>2317</td>\n",
              "      <td>37</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>AbNormal</td>\n",
              "      <td>No</td>\n",
              "      <td>31/03/1983</td>\n",
              "      <td>House</td>\n",
              "      <td>NoSewr</td>\n",
              "      <td>Paved</td>\n",
              "      <td>RH</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>3.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>P06766</td>\n",
              "      <td>KK Nagar</td>\n",
              "      <td>2344</td>\n",
              "      <td>181</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6</td>\n",
              "      <td>Normal Sale</td>\n",
              "      <td>No</td>\n",
              "      <td>04/06/1992</td>\n",
              "      <td>Commercial</td>\n",
              "      <td>NoSeWa</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>RM</td>\n",
              "      <td>3.8</td>\n",
              "      <td>2.4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>P05763</td>\n",
              "      <td>Karapakkam</td>\n",
              "      <td>1008</td>\n",
              "      <td>194</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Partial</td>\n",
              "      <td>Yes</td>\n",
              "      <td>03/01/1979</td>\n",
              "      <td>Commercial</td>\n",
              "      <td>NoSeWa</td>\n",
              "      <td>No Access</td>\n",
              "      <td>RL</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3.46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      PRT_ID        AREA  INT_SQFT  DIST_MAINROAD  N_BEDROOM  N_BATHROOM  \\\n",
              "2104  P09034  Anna Nagar      1838             31        2.0         1.0   \n",
              "2105  P02617    Chrompet      1191            189        1.0         1.0   \n",
              "2106  P03449    KK Nagar      2317             37        4.0         2.0   \n",
              "2107  P06766    KK Nagar      2344            181        4.0         2.0   \n",
              "2108  P05763  Karapakkam      1008            194        1.0         1.0   \n",
              "\n",
              "      N_ROOM    SALE_COND PARK_FACIL  DATE_BUILD   BUILDTYPE UTILITY_AVAIL  \\\n",
              "2104       5      AdjLand        Yes  16/05/1971  Commercial           ELO   \n",
              "2105       3      Partial        Yes  07/09/1988       House           ELO   \n",
              "2106       6     AbNormal         No  31/03/1983       House       NoSewr    \n",
              "2107       6  Normal Sale         No  04/06/1992  Commercial        NoSeWa   \n",
              "2108       3      Partial        Yes  03/01/1979  Commercial        NoSeWa   \n",
              "\n",
              "         STREET MZZONE  QS_ROOMS  QS_BATHROOM  QS_BEDROOM  QS_OVERALL  \n",
              "2104  No Access     RH       2.7          3.7         3.2        3.15  \n",
              "2105     Gravel     RL       4.1          2.9         3.7        3.50  \n",
              "2106      Paved     RH       5.0          4.6         2.2        3.76  \n",
              "2107     Gravel     RM       3.8          2.4         4.6        3.70  \n",
              "2108  No Access     RL       2.5          4.5         3.4        3.46  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_validacao = pd.read_csv('./05_validacao.csv', sep=';')\n",
        "df_validacao.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q762gwitnMxh"
      },
      "source": [
        "## Tratamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cY48X3Gd9Oha"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "missing_data_treino: \n",
            "N_BATHROOM     4\n",
            "QS_OVERALL    29\n",
            "dtype: int64 \n",
            "\n",
            "missing_data_validacao: \n",
            "N_BEDROOM      1\n",
            "N_BATHROOM     1\n",
            "QS_OVERALL    19\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verificando valores faltantes no dataframe\n",
        "missing_data_treino = df_treino.isnull().sum()\n",
        "missing_data_validacao = df_validacao.isnull().sum()\n",
        "\n",
        "# Filtrando apenas colunas que têm valores faltantes\n",
        "missing_data_treino = missing_data_treino[missing_data_treino > 0]\n",
        "missing_data_validacao = missing_data_validacao[missing_data_validacao > 0]\n",
        "\n",
        "print(f\"missing_data_treino: \\n{missing_data_treino} \\n\\nmissing_data_validacao: \\n{missing_data_validacao}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bjw8pxUBmOWC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N_BATHROOM</th>\n",
              "      <th>QS_OVERALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4996.000000</td>\n",
              "      <td>4971.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.215973</td>\n",
              "      <td>3.502875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.411537</td>\n",
              "      <td>0.527007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        N_BATHROOM   QS_OVERALL\n",
              "count  4996.000000  4971.000000\n",
              "mean      1.215973     3.502875\n",
              "std       0.411537     0.527007\n",
              "min       1.000000     2.060000\n",
              "25%       1.000000     3.120000\n",
              "50%       1.000000     3.500000\n",
              "75%       1.000000     3.890000\n",
              "max       2.000000     4.970000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualizando informações básicas sobre as colunas com valores faltantes\n",
        "df_treino[['N_BATHROOM', 'QS_OVERALL']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>N_BATHROOM</th>\n",
              "      <th>QS_OVERALL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2108.000000</td>\n",
              "      <td>2090.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.206831</td>\n",
              "      <td>3.504156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.405129</td>\n",
              "      <td>0.527862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.940000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        N_BATHROOM   QS_OVERALL\n",
              "count  2108.000000  2090.000000\n",
              "mean      1.206831     3.504156\n",
              "std       0.405129     0.527862\n",
              "min       1.000000     2.000000\n",
              "25%       1.000000     3.140000\n",
              "50%       1.000000     3.500000\n",
              "75%       1.000000     3.870000\n",
              "max       2.000000     4.940000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_validacao[['N_BATHROOM', 'QS_OVERALL']].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "37GrpuZ7mSMZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_treino: \n",
            "0 \n",
            "\n",
            "df_validacao: \n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# Preenchendo os valores faltantes\n",
        "\n",
        "# Moda\n",
        "df_treino['N_BATHROOM'].fillna(df_treino['N_BATHROOM'].mode()[0], inplace=True)\n",
        "df_validacao['N_BATHROOM'].fillna(df_validacao['N_BATHROOM'].mode()[0], inplace=True)\n",
        "\n",
        "# Mediana\n",
        "df_treino['QS_OVERALL'].fillna(df_treino['QS_OVERALL'].median(), inplace=True)\n",
        "df_validacao['QS_OVERALL'].fillna(df_validacao['QS_OVERALL'].median(), inplace=True)\n",
        "\n",
        "# Verificando se ainda há valores faltantes\n",
        "\n",
        "print(f\"df_treino: \\n{df_treino.isnull().sum().sum()} \\n\\ndf_validacao: \\n{df_validacao.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lTGrerNGmXud"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_treino: \n",
            "Index(['PRT_ID', 'AREA', 'DATE_SALE', 'SALE_COND', 'PARK_FACIL', 'DATE_BUILD',\n",
            "       'BUILDTYPE', 'UTILITY_AVAIL', 'STREET', 'MZZONE'],\n",
            "      dtype='object') \n",
            "\n",
            "df_validacao: \n",
            "Index(['PRT_ID', 'AREA', 'SALE_COND', 'PARK_FACIL', 'DATE_BUILD', 'BUILDTYPE',\n",
            "       'UTILITY_AVAIL', 'STREET', 'MZZONE'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Identificando colunas categóricas\n",
        "categorical_columns_treino = df_treino.select_dtypes(include=['object']).columns\n",
        "categorical_columns_validacao = df_validacao.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(f\"df_treino: \\n{categorical_columns_treino} \\n\\ndf_validacao: \\n{categorical_columns_validacao}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PRT_ID            object\n",
              "AREA              object\n",
              "INT_SQFT           int64\n",
              "DATE_SALE         object\n",
              "DIST_MAINROAD      int64\n",
              "N_BEDROOM        float64\n",
              "N_BATHROOM       float64\n",
              "N_ROOM             int64\n",
              "SALE_COND         object\n",
              "PARK_FACIL        object\n",
              "DATE_BUILD        object\n",
              "BUILDTYPE         object\n",
              "UTILITY_AVAIL     object\n",
              "STREET            object\n",
              "MZZONE            object\n",
              "QS_ROOMS         float64\n",
              "QS_BATHROOM      float64\n",
              "QS_BEDROOM       float64\n",
              "QS_OVERALL       float64\n",
              "REG_FEE            int64\n",
              "COMMIS             int64\n",
              "SALES_PRICE        int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treino.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KVMZP3YumcV-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ionaf\\AppData\\Local\\Temp\\ipykernel_17604\\1982441556.py:62: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "  data_obj = pd.to_datetime(data, errors='coerce')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ionaf\\AppData\\Local\\Temp\\ipykernel_17604\\1982441556.py:62: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
            "  data_obj = pd.to_datetime(data, errors='coerce')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'AREA': array(['KK Nagar', 'Karapakkam', 'Velachery', 'Chrompet', 'T Nagar',\n",
              "        'Anna Nagar', 'Adyar'], dtype=object),\n",
              " 'SALE_COND': array(['Adj Land', 'AbNormal', 'Partial', 'Family', 'Normal Sale'],\n",
              "       dtype=object),\n",
              " 'PARK_FACIL': array(['Yes', 'No'], dtype=object),\n",
              " 'BUILDTYPE': array(['Others', 'House', 'Commercial'], dtype=object),\n",
              " 'UTILITY_AVAIL': array(['NoSeWa', 'AllPub', 'ELO'], dtype=object),\n",
              " 'STREET': array(['Paved', 'Gravel', 'No Access'], dtype=object),\n",
              " 'DECADE_BUILD': array([1990, 1970, 1980, 1960, 2000, 1950, 2010], dtype=int64)}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# AREA\n",
        "area_mappings = {\n",
        "    'Ann Nagar': 'Anna Nagar',\n",
        "    'Ana Nagar' : 'Anna Nagar',\n",
        "    'Velchery': 'Velachery',\n",
        "    'Chrompt': 'Chrompet',\n",
        "    'Chormpet': 'Chrompet',\n",
        "    'Chrmpet': 'Chrompet',\n",
        "    'Karapakam': 'Karapakkam',\n",
        "    'KKNagar': 'KK Nagar',\n",
        "    'TNagar': 'T Nagar',\n",
        "    'Adyr': 'Adyar',\n",
        "}\n",
        "df_treino['AREA'] = df_treino['AREA'].replace(area_mappings)\n",
        "df_validacao['AREA'] = df_validacao['AREA'].replace(area_mappings)\n",
        "\n",
        "# SALE_COND\n",
        "sale_cond_mappings = {\n",
        "    'AdjLand': 'Adj Land',\n",
        "    'Ab Normal': 'AbNormal',\n",
        "    'Partiall' : 'Partial',\n",
        "    'PartiaLl' : 'Partial'\n",
        "\n",
        "}\n",
        "df_treino['SALE_COND'] = df_treino['SALE_COND'].replace(sale_cond_mappings)\n",
        "df_validacao['SALE_COND'] = df_validacao['SALE_COND'].replace(sale_cond_mappings)\n",
        "\n",
        "# PARK_FACIL\n",
        "park_facil_mappings = {\n",
        "    'Noo': 'No'\n",
        "}\n",
        "df_treino['PARK_FACIL'] = df_treino['PARK_FACIL'].replace(park_facil_mappings)\n",
        "df_validacao['PARK_FACIL'] = df_validacao['PARK_FACIL'].replace(park_facil_mappings)\n",
        "\n",
        "# BUILDTYPE\n",
        "buildtype_mappings = {\n",
        "    'Comercial': 'Commercial',\n",
        "    'Other': 'Others'\n",
        "}\n",
        "df_treino['BUILDTYPE'] = df_treino['BUILDTYPE'].replace(buildtype_mappings)\n",
        "df_validacao['BUILDTYPE'] = df_validacao['BUILDTYPE'].replace(buildtype_mappings)\n",
        "\n",
        "# UTILITY_AVAIL\n",
        "utility_mappings = {\n",
        "    'NoSewr ': 'NoSeWa',\n",
        "    'All Pub': 'AllPub'\n",
        "}\n",
        "df_treino['UTILITY_AVAIL'] = df_treino['UTILITY_AVAIL'].replace(utility_mappings)\n",
        "df_validacao['UTILITY_AVAIL'] = df_validacao['UTILITY_AVAIL'].replace(utility_mappings)\n",
        "\n",
        "# STREET\n",
        "street_mappings = {\n",
        "    'Pavd': 'Paved',\n",
        "    'NoAccess': 'No Access'\n",
        "}\n",
        "df_treino['STREET'] = df_treino['STREET'].replace(street_mappings)\n",
        "df_validacao['STREET'] = df_validacao['STREET'].replace(street_mappings)\n",
        "\n",
        "# Definir uma função para extrair a década\n",
        "def extrair_decada(data):\n",
        "    if pd.notnull(data):\n",
        "        data_obj = pd.to_datetime(data, errors='coerce')\n",
        "        return (data_obj.year // 10) * 10\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Aplicar a função para extrair a década\n",
        "df_treino['DECADE_BUILD'] = df_treino['DATE_BUILD'].apply(extrair_decada)\n",
        "df_validacao['DECADE_BUILD'] = df_validacao['DATE_BUILD'].apply(extrair_decada)\n",
        "\n",
        "\n",
        "# Verificando novamente os valores únicos após as correções\n",
        "unique_values_corrected = {}\n",
        "for column in ['AREA', 'SALE_COND', 'PARK_FACIL', 'BUILDTYPE', 'UTILITY_AVAIL', 'STREET', 'DECADE_BUILD']:\n",
        "    unique_values_corrected[column] = df_treino[column].unique()\n",
        "    unique_values_corrected[column] = df_validacao[column].unique()\n",
        "\n",
        "unique_values_corrected\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Adj Land       433\n",
              "Family         425\n",
              "Partial        420\n",
              "Normal Sale    416\n",
              "AbNormal       415\n",
              "Name: SALE_COND, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_validacao['SALE_COND'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Partial        1013\n",
              "Normal Sale    1007\n",
              "Adj Land       1006\n",
              "AbNormal        996\n",
              "Family          978\n",
              "Name: SALE_COND, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treino['SALE_COND'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TzAOLCosmi8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PRT_ID                    object\n",
              "INT_SQFT                   int64\n",
              "DATE_SALE                 object\n",
              "DIST_MAINROAD              int64\n",
              "N_BEDROOM                float64\n",
              "N_BATHROOM               float64\n",
              "N_ROOM                     int64\n",
              "DATE_BUILD                object\n",
              "QS_ROOMS                 float64\n",
              "QS_BATHROOM              float64\n",
              "QS_BEDROOM               float64\n",
              "QS_OVERALL               float64\n",
              "REG_FEE                    int64\n",
              "COMMIS                     int64\n",
              "SALES_PRICE                int64\n",
              "DECADE_BUILD               int64\n",
              "AREA_Anna Nagar            uint8\n",
              "AREA_Chrompet              uint8\n",
              "AREA_KK Nagar              uint8\n",
              "AREA_Karapakkam            uint8\n",
              "AREA_T Nagar               uint8\n",
              "AREA_Velachery             uint8\n",
              "SALE_COND_Adj Land         uint8\n",
              "SALE_COND_Family           uint8\n",
              "SALE_COND_Normal Sale      uint8\n",
              "SALE_COND_Partial          uint8\n",
              "PARK_FACIL_Yes             uint8\n",
              "BUILDTYPE_House            uint8\n",
              "BUILDTYPE_Others           uint8\n",
              "UTILITY_AVAIL_ELO          uint8\n",
              "UTILITY_AVAIL_NoSeWa       uint8\n",
              "STREET_No Access           uint8\n",
              "STREET_Paved               uint8\n",
              "MZZONE_C                   uint8\n",
              "MZZONE_I                   uint8\n",
              "MZZONE_RH                  uint8\n",
              "MZZONE_RL                  uint8\n",
              "MZZONE_RM                  uint8\n",
              "dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aplicando codificação one-hot\n",
        "df_encoded_treino = pd.get_dummies(df_treino, columns=['AREA', 'SALE_COND', 'PARK_FACIL', 'BUILDTYPE', 'UTILITY_AVAIL', 'STREET', 'MZZONE'], drop_first=True)\n",
        "df_encoded_validacao = pd.get_dummies(df_validacao, columns=['AREA', 'SALE_COND', 'PARK_FACIL', 'BUILDTYPE', 'UTILITY_AVAIL', 'STREET', 'MZZONE'], drop_first=True)\n",
        "\n",
        "# Verificando as primeiras linhas do dataframe após a codificação\n",
        "df_encoded_treino.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOzkaGzj8raS"
      },
      "source": [
        "### Dividindo a base entre treino, teste e validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KeSpZAh28raT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Treino 4000, Teste 1000, Validacao 2109\n"
          ]
        }
      ],
      "source": [
        "# Remover colunas 'PRT_ID' e 'DATE_SALE'\n",
        "df_encoded_treino.drop(\n",
        "    columns=['DATE_SALE', 'DATE_BUILD','COMMIS','REG_FEE'], inplace=True)\n",
        "df_encoded_validacao.drop(columns=['DATE_BUILD'], inplace=True)\n",
        "\n",
        "X = df_encoded_treino.drop(columns=['PRT_ID', 'SALES_PRICE'])\n",
        "y = df_encoded_treino['SALES_PRICE']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "ID = df_encoded_validacao['PRT_ID']\n",
        "X_val = df_encoded_validacao.drop(columns=['PRT_ID'])\n",
        "\n",
        "print(f\" Treino {len(X_train)}, Teste {len(X_test)}, Validacao {len(X_val)}\")\n",
        "#Teremos uma amostra maior para treinar o modelo, uma menor para testar.\n",
        "#Fora isso, temos uma parte dos dados que não fizeram parte da modelagem (dados \"novos\") para validar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalizando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in list(X_train.columns):\n",
        "    maximo = X_train[col].max()\n",
        "    minimo = X_train[col].min()\n",
        "\n",
        "    X_train[col] = (X_train[col] - minimo) / (maximo - minimo)\n",
        "\n",
        "#Novamente, uso os dados de X_train para replicar no treino e validação\n",
        "    X_test[col] = (X_test[col] - minimo) / (maximo - minimo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val = df_encoded_validacao.drop(columns=['PRT_ID'])\n",
        "ID = df_encoded_validacao.PRT_ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMXKEnTlBx1W"
      },
      "source": [
        "## Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_ZUYPlCbM9"
      },
      "source": [
        "### Parametros da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyUY8WezCdZ1"
      },
      "source": [
        "* Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2JsWRtaBBzT3"
      },
      "outputs": [],
      "source": [
        "# Incluindo early stopping\n",
        "\n",
        "# Defina o callback EarlyStopping\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',  # Métrica a ser monitorada\n",
        "    patience=50,          # Número de épocas sem melhoria antes de parar o treinamento\n",
        "    restore_best_weights=True  # Restaura os melhores pesos encontrados durante o treinamento\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgyiMMGBCoVd"
      },
      "source": [
        "* Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z86GVbyKCpO2"
      },
      "outputs": [],
      "source": [
        "# Definindo a função para agendar o learning rate\n",
        "def lr_scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.005\n",
        "    elif epoch < 100:\n",
        "        return 0.001\n",
        "    elif epoch < 150:\n",
        "        return 0.0005\n",
        "    else:\n",
        "        return 0.0001\n",
        "\n",
        "# Criando o callback para o Learning Rate Scheduler\n",
        "lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "# Optei por alterar o learning rate a cada 50 epocas,\n",
        "# pois o early stop vai encerrar o treinamento quando 50 epocas se passarem sem melhorar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sudEfEKEDd2d"
      },
      "source": [
        "Lembrete: esses parâmetros (early stopping e learning rate) são utilizados como callbacks:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Treinando o modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=16, callbacks=[lr_scheduler_callback,early_stopping_callback])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFffemuREztO"
      },
      "source": [
        "* Treinamento com Treino e Teste\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Treinando o modelo com os dados de treinamento e calculando a perda no conjunto de teste\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5fr2JOZKjR5"
      },
      "source": [
        "### Modelo 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "khkTLSdEDnQU"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo sequencial\n",
        "model = tf.keras.models.Sequential() #Definimos que é um modelo de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model.add(tf.keras.layers.Dense(1, activation='relu')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.Huber(delta=1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TvqkjPbdD901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 604033 (2.30 MB)\n",
            "Trainable params: 604033 (2.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5FmOjRocEB1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 223ms/step - loss: 10906449.0000 - val_loss: 10902360.0000 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 10906329.0000 - val_loss: 10901512.0000 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 10904832.0000 - val_loss: 10894942.0000 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 10894855.0000 - val_loss: 10861609.0000 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 10848070.0000 - val_loss: 10730248.0000 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 10672598.0000 - val_loss: 10294000.0000 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 10109128.0000 - val_loss: 9013500.0000 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8492295.0000 - val_loss: 5671089.5000 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 4723627.0000 - val_loss: 4392549.5000 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 4920205.5000 - val_loss: 4335965.0000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3924384.7500 - val_loss: 3113392.5000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3337517.2500 - val_loss: 4298516.5000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 4206436.0000 - val_loss: 3788925.5000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 3469318.2500 - val_loss: 2716231.5000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2834177.5000 - val_loss: 3365226.0000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 3399881.5000 - val_loss: 2773094.0000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2689708.0000 - val_loss: 2712706.5000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2769912.7500 - val_loss: 2941947.5000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2779742.0000 - val_loss: 2365919.2500 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2348082.5000 - val_loss: 2520215.0000 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2557387.7500 - val_loss: 2313780.2500 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 2252525.7500 - val_loss: 2249075.7500 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 2244579.7500 - val_loss: 2276002.0000 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 2168839.7500 - val_loss: 2015355.8750 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 2014358.1250 - val_loss: 2044864.6250 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2026804.7500 - val_loss: 1893251.2500 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1862804.0000 - val_loss: 1945753.6250 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1890240.1250 - val_loss: 1799028.2500 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1767548.6250 - val_loss: 1773660.6250 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1774964.2500 - val_loss: 1688641.6250 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1673644.7500 - val_loss: 1683410.7500 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1653299.8750 - val_loss: 1586592.5000 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1563331.1250 - val_loss: 1528974.0000 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1532564.7500 - val_loss: 1450127.6250 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1446379.6250 - val_loss: 1419276.5000 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1404915.7500 - val_loss: 1321253.1250 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1321064.8750 - val_loss: 1260561.3750 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1265734.1250 - val_loss: 1185471.7500 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1191545.3750 - val_loss: 1133411.5000 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1131110.3750 - val_loss: 1059745.5000 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1062494.7500 - val_loss: 1002673.6875 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1001018.3125 - val_loss: 947293.0625 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 945426.5625 - val_loss: 895044.3125 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 889647.3125 - val_loss: 856054.1250 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 849828.1250 - val_loss: 824973.6875 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 808521.3750 - val_loss: 796181.5625 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 781963.2500 - val_loss: 773360.6250 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 749852.8125 - val_loss: 745355.5000 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 720507.9375 - val_loss: 726439.0625 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 694446.8750 - val_loss: 710394.1250 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 675140.1875 - val_loss: 701574.2500 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 666912.3125 - val_loss: 697174.0000 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 662821.5000 - val_loss: 690018.3750 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 655450.4375 - val_loss: 684865.5625 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 650154.6875 - val_loss: 677855.7500 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 643614.4375 - val_loss: 671960.3125 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 639018.6250 - val_loss: 665949.0625 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 632853.5000 - val_loss: 660801.6250 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 628215.9375 - val_loss: 654591.8750 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 622373.1250 - val_loss: 649906.6875 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 617758.1875 - val_loss: 644363.2500 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 612706.0000 - val_loss: 639812.9375 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 607949.0000 - val_loss: 634571.7500 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 602888.0000 - val_loss: 629843.4375 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 597794.0625 - val_loss: 624793.0625 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 592756.1250 - val_loss: 620348.3125 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 587930.2500 - val_loss: 616209.6875 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 583487.4375 - val_loss: 611828.1875 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 578554.0625 - val_loss: 607430.3750 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 574144.5000 - val_loss: 602887.3125 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 569307.6250 - val_loss: 598570.3750 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 564907.9375 - val_loss: 593785.5625 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 560266.0000 - val_loss: 589408.7500 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 555854.8125 - val_loss: 584787.7500 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 551129.6875 - val_loss: 580310.2500 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 546634.7500 - val_loss: 575679.6250 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 542098.8125 - val_loss: 571190.8125 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 537600.2500 - val_loss: 566638.9375 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 533276.0625 - val_loss: 562219.5625 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 528724.5000 - val_loss: 557858.6250 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 524382.1250 - val_loss: 553505.4375 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 519942.4062 - val_loss: 549246.0625 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 515210.1562 - val_loss: 545365.1250 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 511310.0625 - val_loss: 540517.0625 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 506342.7188 - val_loss: 536342.1250 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 501882.8438 - val_loss: 532064.3125 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 497375.8125 - val_loss: 527718.5625 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 493264.7812 - val_loss: 523386.7500 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 488443.4062 - val_loss: 518854.6250 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 483798.1250 - val_loss: 514703.5312 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 479968.7188 - val_loss: 510027.0312 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 475359.6562 - val_loss: 505490.5312 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 470787.1250 - val_loss: 501070.0625 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 466242.5625 - val_loss: 496932.8125 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 462117.3750 - val_loss: 494429.6250 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 461266.8438 - val_loss: 489220.9062 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 455027.5938 - val_loss: 484082.8125 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 450661.1875 - val_loss: 479478.5625 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 446754.3750 - val_loss: 475471.7188 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 440798.5938 - val_loss: 470790.3750 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 437935.3125 - val_loss: 468171.0312 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 435005.8438 - val_loss: 466511.9375 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 432644.3750 - val_loss: 463942.0312 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 430807.6250 - val_loss: 461798.6562 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 428069.3125 - val_loss: 460666.2188 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 426305.5938 - val_loss: 457824.4688 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 423968.1250 - val_loss: 455827.4062 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 421732.0938 - val_loss: 454251.2812 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 419803.2812 - val_loss: 451785.6875 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 417682.6875 - val_loss: 449637.0000 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 415311.0938 - val_loss: 448190.2812 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 413628.3750 - val_loss: 445499.6562 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 411106.1250 - val_loss: 443376.7188 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 409091.9688 - val_loss: 441701.1875 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 407579.8438 - val_loss: 439219.7188 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 405676.0312 - val_loss: 437203.8750 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 403749.5000 - val_loss: 436172.0938 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 401427.9062 - val_loss: 432800.3750 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 399083.5938 - val_loss: 430625.3750 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 396671.0312 - val_loss: 429279.5000 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 394963.5312 - val_loss: 426476.5312 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 392557.2500 - val_loss: 424360.8125 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 390524.0625 - val_loss: 422869.7812 - lr: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 388584.2500 - val_loss: 420850.3125 - lr: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 386449.8438 - val_loss: 418392.0312 - lr: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 384623.9375 - val_loss: 416535.4688 - lr: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 382291.4688 - val_loss: 415263.8750 - lr: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 380718.4688 - val_loss: 412182.1562 - lr: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 378928.2812 - val_loss: 410101.8438 - lr: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 376565.1875 - val_loss: 409008.1875 - lr: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 374898.1875 - val_loss: 405944.1250 - lr: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 372473.4062 - val_loss: 404147.9062 - lr: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 370478.5938 - val_loss: 402123.7500 - lr: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 368397.3438 - val_loss: 399740.2188 - lr: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 366404.3438 - val_loss: 398784.5312 - lr: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 364808.2188 - val_loss: 396202.4062 - lr: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 362601.6562 - val_loss: 393778.5625 - lr: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 360680.9062 - val_loss: 392683.7812 - lr: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 358507.0625 - val_loss: 389917.9688 - lr: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 356496.8438 - val_loss: 388141.5625 - lr: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 354422.7188 - val_loss: 386628.3125 - lr: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 352627.8125 - val_loss: 384169.9375 - lr: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 350505.2188 - val_loss: 381935.6875 - lr: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 348589.5000 - val_loss: 380832.0000 - lr: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 346742.7812 - val_loss: 378268.4688 - lr: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 344601.0938 - val_loss: 376319.1562 - lr: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 342641.1875 - val_loss: 374413.6250 - lr: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 340616.7812 - val_loss: 372274.5625 - lr: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 338835.0938 - val_loss: 370309.5000 - lr: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 336697.6250 - val_loss: 368137.2812 - lr: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 335058.8125 - val_loss: 367829.1250 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 334593.5000 - val_loss: 367657.9062 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 334337.8750 - val_loss: 367321.5000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 333925.6250 - val_loss: 366632.9375 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 333421.8438 - val_loss: 366077.6250 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 333071.1875 - val_loss: 365632.5000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 332664.5625 - val_loss: 365349.0000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 332256.6875 - val_loss: 365194.4062 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 331930.5938 - val_loss: 364741.2500 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 331549.6562 - val_loss: 364149.0938 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 331045.7500 - val_loss: 363663.5625 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 330660.3438 - val_loss: 363252.7812 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 330271.2812 - val_loss: 362902.2812 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 329868.4375 - val_loss: 362529.1250 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 329527.8125 - val_loss: 362215.2812 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 329068.0000 - val_loss: 361723.1875 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 328661.2188 - val_loss: 361351.5938 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 328262.6875 - val_loss: 360963.2500 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 327862.5312 - val_loss: 360583.4375 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 327466.9375 - val_loss: 360261.8125 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 327068.7500 - val_loss: 359927.4375 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 326671.5938 - val_loss: 359471.4375 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 326268.1875 - val_loss: 359013.2500 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 325880.5000 - val_loss: 358672.3125 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 325455.1562 - val_loss: 358400.8438 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 325120.1250 - val_loss: 357987.5938 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 324696.6875 - val_loss: 357503.2500 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 324281.7188 - val_loss: 357068.7188 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 323882.5938 - val_loss: 356740.0938 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 323480.5312 - val_loss: 356336.2812 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 323085.7188 - val_loss: 355928.5625 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 322717.0312 - val_loss: 355530.7500 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 322302.5312 - val_loss: 355074.5000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 321937.4688 - val_loss: 354695.5000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 321518.2812 - val_loss: 354462.6562 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 321138.8125 - val_loss: 354131.1250 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 320776.4688 - val_loss: 353576.5000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 320337.7188 - val_loss: 353073.6562 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 319992.6875 - val_loss: 352681.9688 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 319579.8438 - val_loss: 352394.2500 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 319204.6250 - val_loss: 352066.6250 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 318817.0000 - val_loss: 351519.2812 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 318396.7500 - val_loss: 351025.5000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 318055.6875 - val_loss: 350615.4688 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 317655.3750 - val_loss: 350332.9375 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 317229.0000 - val_loss: 349889.8438 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 316837.5000 - val_loss: 349425.9062 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 316436.8125 - val_loss: 349008.0938 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 316026.7812 - val_loss: 348553.6562 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 315635.5000 - val_loss: 348117.8750 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 315250.5625 - val_loss: 347729.4062 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 314846.4375 - val_loss: 347338.9688 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 314518.5938 - val_loss: 346860.0312 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 314040.1875 - val_loss: 346486.4062 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 313656.9062 - val_loss: 346008.5000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 313263.6250 - val_loss: 345589.3125 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 312876.4062 - val_loss: 345216.5000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 312466.9375 - val_loss: 344736.8125 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 312085.3750 - val_loss: 344294.4062 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 311667.7188 - val_loss: 344036.8750 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 311353.3438 - val_loss: 343709.1875 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 310963.0625 - val_loss: 343074.1875 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 310468.5000 - val_loss: 342631.4062 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 310085.1250 - val_loss: 342240.4375 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 309657.1562 - val_loss: 341941.3125 - lr: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 309306.7188 - val_loss: 341545.7188 - lr: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 308885.5625 - val_loss: 340983.6875 - lr: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 308510.0938 - val_loss: 340581.5625 - lr: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 308101.5938 - val_loss: 340325.7812 - lr: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 307757.7500 - val_loss: 339856.0312 - lr: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 307282.0625 - val_loss: 339333.1875 - lr: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 306975.5312 - val_loss: 338961.7812 - lr: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 306489.5000 - val_loss: 338733.0938 - lr: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 306167.4062 - val_loss: 338349.5938 - lr: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 305759.4688 - val_loss: 337691.4062 - lr: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 305332.7188 - val_loss: 337270.6875 - lr: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 305210.9375 - val_loss: 336871.2188 - lr: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 304614.5000 - val_loss: 336990.5625 - lr: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 304393.6875 - val_loss: 336369.0938 - lr: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 303826.3125 - val_loss: 335607.4062 - lr: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 303362.7500 - val_loss: 335157.6562 - lr: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 303008.9062 - val_loss: 334806.5938 - lr: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 302527.0000 - val_loss: 334481.9375 - lr: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 302150.8125 - val_loss: 334043.7188 - lr: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 301760.6875 - val_loss: 333539.8438 - lr: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 301342.2188 - val_loss: 333138.1250 - lr: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 300931.9688 - val_loss: 332667.0000 - lr: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 300549.0312 - val_loss: 332244.8750 - lr: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 300196.7812 - val_loss: 331885.6875 - lr: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 299760.2188 - val_loss: 331635.5625 - lr: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 299440.8750 - val_loss: 331039.3750 - lr: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 298939.9062 - val_loss: 330576.0000 - lr: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 298569.3438 - val_loss: 330226.4688 - lr: 1.0000e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 298134.6562 - val_loss: 329932.1562 - lr: 1.0000e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 297766.8438 - val_loss: 329535.5625 - lr: 1.0000e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 297420.5938 - val_loss: 329061.4375 - lr: 1.0000e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 296951.7188 - val_loss: 328793.0625 - lr: 1.0000e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 296556.1250 - val_loss: 328361.4062 - lr: 1.0000e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 296159.4062 - val_loss: 327955.1250 - lr: 1.0000e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 295788.2188 - val_loss: 327659.4688 - lr: 1.0000e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 295356.7500 - val_loss: 327182.7500 - lr: 1.0000e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 295078.5312 - val_loss: 326862.0938 - lr: 1.0000e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 294598.1250 - val_loss: 326665.1875 - lr: 1.0000e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 294269.8750 - val_loss: 325977.2188 - lr: 1.0000e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 293760.2188 - val_loss: 325545.0000 - lr: 1.0000e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 293434.1562 - val_loss: 325170.6875 - lr: 1.0000e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 292984.8750 - val_loss: 324852.0938 - lr: 1.0000e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 292566.9688 - val_loss: 324403.7812 - lr: 1.0000e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 292162.7500 - val_loss: 323986.9062 - lr: 1.0000e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 291778.0938 - val_loss: 323607.8750 - lr: 1.0000e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 291367.7188 - val_loss: 323224.0938 - lr: 1.0000e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 290960.7188 - val_loss: 322838.5000 - lr: 1.0000e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 290569.0312 - val_loss: 322385.1875 - lr: 1.0000e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 290160.7188 - val_loss: 321994.5312 - lr: 1.0000e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 289777.2500 - val_loss: 321576.5312 - lr: 1.0000e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 289396.4375 - val_loss: 321161.2188 - lr: 1.0000e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 288964.2812 - val_loss: 320852.2188 - lr: 1.0000e-04\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 288628.3750 - val_loss: 320431.7188 - lr: 1.0000e-04\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 288206.8438 - val_loss: 319965.9375 - lr: 1.0000e-04\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 287838.4062 - val_loss: 319605.2188 - lr: 1.0000e-04\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 287340.3750 - val_loss: 319230.0938 - lr: 1.0000e-04\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 286951.8750 - val_loss: 318815.4688 - lr: 1.0000e-04\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 286587.0938 - val_loss: 318390.9688 - lr: 1.0000e-04\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 286164.5000 - val_loss: 317996.3438 - lr: 1.0000e-04\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 285805.4688 - val_loss: 317754.9688 - lr: 1.0000e-04\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 285566.6562 - val_loss: 317479.2812 - lr: 1.0000e-04\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 285081.7812 - val_loss: 316804.0312 - lr: 1.0000e-04\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 284735.8125 - val_loss: 316400.5625 - lr: 1.0000e-04\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 284196.4062 - val_loss: 316211.6562 - lr: 1.0000e-04\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 283901.8125 - val_loss: 315749.6250 - lr: 1.0000e-04\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 283390.8438 - val_loss: 315232.9062 - lr: 1.0000e-04\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 283137.2812 - val_loss: 314876.8125 - lr: 1.0000e-04\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 282687.5000 - val_loss: 314756.7500 - lr: 1.0000e-04\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 282366.6562 - val_loss: 314129.9688 - lr: 1.0000e-04\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 281785.1562 - val_loss: 313724.3438 - lr: 1.0000e-04\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 281558.8125 - val_loss: 313410.5938 - lr: 1.0000e-04\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 281029.3125 - val_loss: 313125.1250 - lr: 1.0000e-04\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 280666.3438 - val_loss: 312645.3125 - lr: 1.0000e-04\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 280294.8438 - val_loss: 312215.2188 - lr: 1.0000e-04\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 279861.7812 - val_loss: 311884.0625 - lr: 1.0000e-04\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 279487.9688 - val_loss: 311528.2812 - lr: 1.0000e-04\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 279101.2188 - val_loss: 311127.9375 - lr: 1.0000e-04\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 278752.2500 - val_loss: 310631.8750 - lr: 1.0000e-04\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 278360.9375 - val_loss: 310231.9688 - lr: 1.0000e-04\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 278092.5938 - val_loss: 309979.6562 - lr: 1.0000e-04\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 277582.2500 - val_loss: 309701.5312 - lr: 1.0000e-04\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 277205.3125 - val_loss: 309143.8438 - lr: 1.0000e-04\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 276839.1562 - val_loss: 308794.9062 - lr: 1.0000e-04\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 276359.2188 - val_loss: 308579.8438 - lr: 1.0000e-04\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 276093.0000 - val_loss: 308118.1562 - lr: 1.0000e-04\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 275646.2812 - val_loss: 307648.2500 - lr: 1.0000e-04\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 275275.6562 - val_loss: 307370.5625 - lr: 1.0000e-04\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 274931.6250 - val_loss: 307010.2812 - lr: 1.0000e-04\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 274453.2500 - val_loss: 306497.5625 - lr: 1.0000e-04\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 274154.3750 - val_loss: 306141.9375 - lr: 1.0000e-04\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 273730.2812 - val_loss: 305851.2812 - lr: 1.0000e-04\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 273361.7812 - val_loss: 305420.7500 - lr: 1.0000e-04\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 272959.8750 - val_loss: 305033.0312 - lr: 1.0000e-04\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 272574.4062 - val_loss: 304631.7188 - lr: 1.0000e-04\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 272222.3125 - val_loss: 304289.5938 - lr: 1.0000e-04\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 271834.6250 - val_loss: 303962.0312 - lr: 1.0000e-04\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 271533.8438 - val_loss: 303512.9062 - lr: 1.0000e-04\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 271074.7500 - val_loss: 303022.3438 - lr: 1.0000e-04\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 270828.6875 - val_loss: 302660.5625 - lr: 1.0000e-04\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 270359.9688 - val_loss: 302408.5312 - lr: 1.0000e-04\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 270031.2188 - val_loss: 301913.9062 - lr: 1.0000e-04\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 269803.5312 - val_loss: 301532.0938 - lr: 1.0000e-04\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 269213.5000 - val_loss: 301368.9062 - lr: 1.0000e-04\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 269098.9375 - val_loss: 300801.7188 - lr: 1.0000e-04\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 268521.5000 - val_loss: 300378.2500 - lr: 1.0000e-04\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 268224.4375 - val_loss: 300081.4062 - lr: 1.0000e-04\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 267800.4375 - val_loss: 299873.8438 - lr: 1.0000e-04\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 267579.4375 - val_loss: 299387.8125 - lr: 1.0000e-04\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 267095.0312 - val_loss: 298914.8125 - lr: 1.0000e-04\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 266874.4062 - val_loss: 298680.4375 - lr: 1.0000e-04\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 266642.8125 - val_loss: 298508.1562 - lr: 1.0000e-04\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 266140.7188 - val_loss: 297803.1250 - lr: 1.0000e-04\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 265956.8750 - val_loss: 297443.8125 - lr: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 265521.3125 - val_loss: 297517.7188 - lr: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 265229.1875 - val_loss: 296664.3125 - lr: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 264673.6875 - val_loss: 296298.4062 - lr: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 264340.0625 - val_loss: 296119.9688 - lr: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 263953.1875 - val_loss: 295816.1250 - lr: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 263719.7812 - val_loss: 295225.6562 - lr: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 263210.2188 - val_loss: 294978.5000 - lr: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 262884.0938 - val_loss: 294643.5625 - lr: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 262534.3438 - val_loss: 294150.5000 - lr: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 262139.6094 - val_loss: 293915.0000 - lr: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 261806.5938 - val_loss: 293480.4062 - lr: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 261417.4844 - val_loss: 293022.7812 - lr: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 261156.0156 - val_loss: 292687.4375 - lr: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 260768.3594 - val_loss: 292442.1562 - lr: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 260400.6562 - val_loss: 291907.0312 - lr: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 260259.3906 - val_loss: 291572.4375 - lr: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 259715.3750 - val_loss: 291433.4688 - lr: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 259481.7969 - val_loss: 290798.7188 - lr: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 259055.9062 - val_loss: 290412.5938 - lr: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 258668.8438 - val_loss: 290209.3438 - lr: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 258410.7500 - val_loss: 289675.8750 - lr: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 258031.5312 - val_loss: 289270.4688 - lr: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 257652.9844 - val_loss: 289051.2500 - lr: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 257373.3906 - val_loss: 288547.1875 - lr: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 256985.2812 - val_loss: 288214.6250 - lr: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 256667.1406 - val_loss: 287892.5938 - lr: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 256373.5469 - val_loss: 287409.5312 - lr: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 256025.2188 - val_loss: 287135.6250 - lr: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 255590.4062 - val_loss: 286735.1875 - lr: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 255265.7969 - val_loss: 286325.5000 - lr: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 254971.7500 - val_loss: 285968.7812 - lr: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 254576.5156 - val_loss: 285694.5312 - lr: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 254310.3125 - val_loss: 285246.0312 - lr: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 253942.5312 - val_loss: 284833.1875 - lr: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 253892.8906 - val_loss: 284543.9688 - lr: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 253351.8438 - val_loss: 284076.5312 - lr: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 252946.4375 - val_loss: 283845.9375 - lr: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 252666.3906 - val_loss: 283346.6250 - lr: 1.0000e-04\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 252241.5938 - val_loss: 282961.7812 - lr: 1.0000e-04\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 251969.7188 - val_loss: 282670.2188 - lr: 1.0000e-04\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 251651.0156 - val_loss: 282336.9062 - lr: 1.0000e-04\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 251392.0625 - val_loss: 281913.8750 - lr: 1.0000e-04\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 250964.9688 - val_loss: 281734.3438 - lr: 1.0000e-04\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 250662.5312 - val_loss: 281262.0938 - lr: 1.0000e-04\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 250292.7656 - val_loss: 280922.7500 - lr: 1.0000e-04\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 249954.5625 - val_loss: 280622.2812 - lr: 1.0000e-04\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 249640.6719 - val_loss: 280299.9688 - lr: 1.0000e-04\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 249444.8438 - val_loss: 279823.9375 - lr: 1.0000e-04\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 249324.3438 - val_loss: 279446.1562 - lr: 1.0000e-04\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 249089.9219 - val_loss: 279333.8750 - lr: 1.0000e-04\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 248387.4219 - val_loss: 278765.2188 - lr: 1.0000e-04\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 248326.4688 - val_loss: 278374.9688 - lr: 1.0000e-04\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 247808.6719 - val_loss: 278267.6562 - lr: 1.0000e-04\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 247621.2188 - val_loss: 277689.1250 - lr: 1.0000e-04\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 247132.3906 - val_loss: 277373.3438 - lr: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 246783.5156 - val_loss: 277082.0625 - lr: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 246458.4688 - val_loss: 276676.4062 - lr: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 246169.5625 - val_loss: 276331.3125 - lr: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 245875.5156 - val_loss: 276049.4375 - lr: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 245575.4375 - val_loss: 275776.3125 - lr: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 245248.5469 - val_loss: 275339.2812 - lr: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 245022.4219 - val_loss: 275059.4375 - lr: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 244553.5625 - val_loss: 274663.3750 - lr: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 244306.0000 - val_loss: 274390.4375 - lr: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 243962.8594 - val_loss: 274038.9062 - lr: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 243638.4062 - val_loss: 273616.8438 - lr: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 243397.6562 - val_loss: 273347.2188 - lr: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 243047.8125 - val_loss: 272968.0312 - lr: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 242702.0781 - val_loss: 272660.8750 - lr: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 242430.7500 - val_loss: 272282.3125 - lr: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 242109.4219 - val_loss: 272027.9688 - lr: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 241891.9375 - val_loss: 271638.7812 - lr: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 241580.0625 - val_loss: 271274.9688 - lr: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 241225.3438 - val_loss: 271092.1875 - lr: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 240995.2812 - val_loss: 270573.0000 - lr: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 240600.0469 - val_loss: 270302.0312 - lr: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 240277.8594 - val_loss: 270046.5312 - lr: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 239984.3125 - val_loss: 269590.3438 - lr: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 239775.0156 - val_loss: 269259.2500 - lr: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 239391.1094 - val_loss: 269049.6562 - lr: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 239093.9375 - val_loss: 268609.1562 - lr: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 238756.6875 - val_loss: 268245.7812 - lr: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 238470.6250 - val_loss: 267957.9375 - lr: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 238236.2969 - val_loss: 267683.8438 - lr: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 238015.3750 - val_loss: 267372.7500 - lr: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 237649.2812 - val_loss: 266945.1250 - lr: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 237386.4688 - val_loss: 266811.3125 - lr: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 237035.5469 - val_loss: 266440.1562 - lr: 1.0000e-04\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 236660.1875 - val_loss: 266013.5625 - lr: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 236623.7656 - val_loss: 265810.5312 - lr: 1.0000e-04\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 236282.5781 - val_loss: 265722.0312 - lr: 1.0000e-04\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 235934.0000 - val_loss: 265093.2500 - lr: 1.0000e-04\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 235789.0156 - val_loss: 264827.5938 - lr: 1.0000e-04\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 235223.8750 - val_loss: 264895.9062 - lr: 1.0000e-04\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 235138.6719 - val_loss: 264137.5000 - lr: 1.0000e-04\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 234688.9219 - val_loss: 263850.2188 - lr: 1.0000e-04\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 234455.9844 - val_loss: 263725.1250 - lr: 1.0000e-04\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 234031.3594 - val_loss: 263229.2812 - lr: 1.0000e-04\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 233826.8438 - val_loss: 262923.8750 - lr: 1.0000e-04\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 233490.1406 - val_loss: 262866.1562 - lr: 1.0000e-04\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 233234.4688 - val_loss: 262359.3750 - lr: 1.0000e-04\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 232846.9531 - val_loss: 262039.1875 - lr: 1.0000e-04\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 232665.5781 - val_loss: 261955.3281 - lr: 1.0000e-04\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 232414.7188 - val_loss: 261484.5312 - lr: 1.0000e-04\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 231894.9062 - val_loss: 261057.0938 - lr: 1.0000e-04\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 231868.8594 - val_loss: 260792.7656 - lr: 1.0000e-04\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 231436.3594 - val_loss: 260586.5469 - lr: 1.0000e-04\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 231102.0469 - val_loss: 260019.8906 - lr: 1.0000e-04\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 230916.6719 - val_loss: 259777.9531 - lr: 1.0000e-04\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 230540.1719 - val_loss: 259648.6719 - lr: 1.0000e-04\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 230287.8125 - val_loss: 259105.7656 - lr: 1.0000e-04\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 230239.6094 - val_loss: 258831.1562 - lr: 1.0000e-04\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 229739.0469 - val_loss: 258552.7031 - lr: 1.0000e-04\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 229417.9531 - val_loss: 258533.3594 - lr: 1.0000e-04\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 229149.3594 - val_loss: 257994.0781 - lr: 1.0000e-04\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 228810.9062 - val_loss: 257730.5781 - lr: 1.0000e-04\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 228504.2188 - val_loss: 257596.4531 - lr: 1.0000e-04\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 228246.9375 - val_loss: 257168.9844 - lr: 1.0000e-04\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 227986.8750 - val_loss: 256910.3750 - lr: 1.0000e-04\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 227620.7500 - val_loss: 256846.0469 - lr: 1.0000e-04\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 227487.7031 - val_loss: 256356.6875 - lr: 1.0000e-04\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 227055.8125 - val_loss: 255956.0156 - lr: 1.0000e-04\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 226973.7656 - val_loss: 255779.4531 - lr: 1.0000e-04\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 226497.5000 - val_loss: 255685.9844 - lr: 1.0000e-04\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 226347.9062 - val_loss: 255107.3594 - lr: 1.0000e-04\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 226174.4375 - val_loss: 254808.6406 - lr: 1.0000e-04\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 225690.2656 - val_loss: 254969.9844 - lr: 1.0000e-04\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 225653.2812 - val_loss: 254183.1250 - lr: 1.0000e-04\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 225191.4062 - val_loss: 253881.3750 - lr: 1.0000e-04\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 224872.2188 - val_loss: 253865.9844 - lr: 1.0000e-04\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 224660.2969 - val_loss: 253295.1406 - lr: 1.0000e-04\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 224378.5625 - val_loss: 253036.2812 - lr: 1.0000e-04\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 224057.7031 - val_loss: 252967.4531 - lr: 1.0000e-04\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 223770.7500 - val_loss: 252381.7344 - lr: 1.0000e-04\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 223645.3438 - val_loss: 252232.9844 - lr: 1.0000e-04\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 223210.4219 - val_loss: 251983.3906 - lr: 1.0000e-04\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 222896.2188 - val_loss: 251576.2812 - lr: 1.0000e-04\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 222656.8281 - val_loss: 251466.7500 - lr: 1.0000e-04\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 222435.4531 - val_loss: 251153.8906 - lr: 1.0000e-04\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 222128.3750 - val_loss: 250661.3281 - lr: 1.0000e-04\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 221904.3750 - val_loss: 250484.6406 - lr: 1.0000e-04\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 221540.7656 - val_loss: 250311.7344 - lr: 1.0000e-04\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 221315.0156 - val_loss: 249763.7500 - lr: 1.0000e-04\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 221117.1094 - val_loss: 249575.9375 - lr: 1.0000e-04\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 221026.2344 - val_loss: 249372.5469 - lr: 1.0000e-04\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 220439.6875 - val_loss: 248858.7812 - lr: 1.0000e-04\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 220418.7500 - val_loss: 248919.4062 - lr: 1.0000e-04\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 220204.7031 - val_loss: 248471.5781 - lr: 1.0000e-04\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 219797.4375 - val_loss: 247979.2188 - lr: 1.0000e-04\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 219542.6875 - val_loss: 248149.8438 - lr: 1.0000e-04\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 219336.5781 - val_loss: 247493.9375 - lr: 1.0000e-04\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 218903.6875 - val_loss: 247199.5625 - lr: 1.0000e-04\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 218651.8438 - val_loss: 247202.6094 - lr: 1.0000e-04\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 218553.9375 - val_loss: 246781.2344 - lr: 1.0000e-04\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 218114.2656 - val_loss: 246407.9375 - lr: 1.0000e-04\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 218058.3906 - val_loss: 246471.0469 - lr: 1.0000e-04\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 217651.7500 - val_loss: 246029.2656 - lr: 1.0000e-04\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 217360.5156 - val_loss: 245770.5000 - lr: 1.0000e-04\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 217187.8594 - val_loss: 245691.7188 - lr: 1.0000e-04\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 216819.1094 - val_loss: 245266.5000 - lr: 1.0000e-04\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 216596.6094 - val_loss: 245081.4531 - lr: 1.0000e-04\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 216316.3906 - val_loss: 244801.2344 - lr: 1.0000e-04\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 216085.2812 - val_loss: 244550.4688 - lr: 1.0000e-04\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 215892.1406 - val_loss: 244298.1406 - lr: 1.0000e-04\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 215769.2188 - val_loss: 244010.2656 - lr: 1.0000e-04\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 215379.1875 - val_loss: 244035.8438 - lr: 1.0000e-04\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 215153.5625 - val_loss: 243380.6094 - lr: 1.0000e-04\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 215122.4062 - val_loss: 243240.4844 - lr: 1.0000e-04\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 214743.7188 - val_loss: 243203.5469 - lr: 1.0000e-04\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 214348.4688 - val_loss: 242547.8750 - lr: 1.0000e-04\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 214521.3750 - val_loss: 242395.7500 - lr: 1.0000e-04\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 213961.5156 - val_loss: 242391.2031 - lr: 1.0000e-04\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 213598.4219 - val_loss: 241727.2344 - lr: 1.0000e-04\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 213966.8125 - val_loss: 241591.9375 - lr: 1.0000e-04\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 213351.2344 - val_loss: 241908.0156 - lr: 1.0000e-04\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 213432.2500 - val_loss: 240900.7031 - lr: 1.0000e-04\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 212939.3594 - val_loss: 240793.6562 - lr: 1.0000e-04\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 212384.3906 - val_loss: 240635.3594 - lr: 1.0000e-04\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 212269.2188 - val_loss: 240366.6250 - lr: 1.0000e-04\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 211910.4062 - val_loss: 240250.0000 - lr: 1.0000e-04\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 211711.9688 - val_loss: 239980.6094 - lr: 1.0000e-04\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 211406.6250 - val_loss: 239851.3906 - lr: 1.0000e-04\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 211173.2188 - val_loss: 239568.0625 - lr: 1.0000e-04\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 210945.8281 - val_loss: 239340.1250 - lr: 1.0000e-04\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 210713.6562 - val_loss: 239287.6094 - lr: 1.0000e-04\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 210609.7656 - val_loss: 238879.4844 - lr: 1.0000e-04\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 210529.3125 - val_loss: 238531.2656 - lr: 1.0000e-04\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 210051.5469 - val_loss: 238822.6406 - lr: 1.0000e-04\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 210036.4844 - val_loss: 237944.8438 - lr: 1.0000e-04\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 209716.4531 - val_loss: 237797.3125 - lr: 1.0000e-04\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 209219.3906 - val_loss: 237982.8125 - lr: 1.0000e-04\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 209312.7031 - val_loss: 237235.3594 - lr: 1.0000e-04\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 208972.8281 - val_loss: 237008.7344 - lr: 1.0000e-04\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 208545.5938 - val_loss: 237228.4219 - lr: 1.0000e-04\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 208562.5000 - val_loss: 236542.0469 - lr: 1.0000e-04\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 208206.2500 - val_loss: 236380.4688 - lr: 1.0000e-04\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 207956.0312 - val_loss: 236344.0625 - lr: 1.0000e-04\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 207626.7812 - val_loss: 235788.5781 - lr: 1.0000e-04\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 207569.2500 - val_loss: 235667.5938 - lr: 1.0000e-04\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 207232.6406 - val_loss: 235393.8438 - lr: 1.0000e-04\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 206961.5312 - val_loss: 235021.4062 - lr: 1.0000e-04\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 206667.6562 - val_loss: 234959.5156 - lr: 1.0000e-04\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 206501.3438 - val_loss: 234429.7500 - lr: 1.0000e-04\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 206273.5312 - val_loss: 234299.5625 - lr: 1.0000e-04\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 206031.8906 - val_loss: 234054.8906 - lr: 1.0000e-04\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 205768.7656 - val_loss: 233685.2188 - lr: 1.0000e-04\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 205504.9844 - val_loss: 233737.2188 - lr: 1.0000e-04\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 205358.6875 - val_loss: 233225.5938 - lr: 1.0000e-04\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 205174.4531 - val_loss: 233047.0938 - lr: 1.0000e-04\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 204975.9531 - val_loss: 233135.6875 - lr: 1.0000e-04\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 204633.2969 - val_loss: 232580.2188 - lr: 1.0000e-04\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 204453.3438 - val_loss: 232559.0938 - lr: 1.0000e-04\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 204175.6406 - val_loss: 232359.0156 - lr: 1.0000e-04\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 203947.3281 - val_loss: 231826.6250 - lr: 1.0000e-04\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 203793.4375 - val_loss: 231605.0938 - lr: 1.0000e-04\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 203474.5781 - val_loss: 231692.6562 - lr: 1.0000e-04\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 203314.2812 - val_loss: 231077.4844 - lr: 1.0000e-04\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 203240.7656 - val_loss: 230898.0156 - lr: 1.0000e-04\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 202902.1094 - val_loss: 230620.9531 - lr: 1.0000e-04\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 202683.5781 - val_loss: 230306.2656 - lr: 1.0000e-04\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 202506.4688 - val_loss: 230331.8750 - lr: 1.0000e-04\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 202356.8750 - val_loss: 229834.3438 - lr: 1.0000e-04\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 201894.2812 - val_loss: 229934.4375 - lr: 1.0000e-04\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 201793.0156 - val_loss: 229365.1562 - lr: 1.0000e-04\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 201648.9531 - val_loss: 229197.1719 - lr: 1.0000e-04\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 201480.5938 - val_loss: 229047.9375 - lr: 1.0000e-04\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 201072.9062 - val_loss: 228638.6250 - lr: 1.0000e-04\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 200954.8125 - val_loss: 228866.7188 - lr: 1.0000e-04\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 201003.2031 - val_loss: 228181.3750 - lr: 1.0000e-04\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 200707.9844 - val_loss: 227916.0938 - lr: 1.0000e-04\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 200082.1094 - val_loss: 228640.6406 - lr: 1.0000e-04\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 200635.7969 - val_loss: 227471.8438 - lr: 1.0000e-04\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 199920.4844 - val_loss: 227249.8750 - lr: 1.0000e-04\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 199712.3906 - val_loss: 227465.4062 - lr: 1.0000e-04\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 199881.0781 - val_loss: 226761.9688 - lr: 1.0000e-04\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 199209.4375 - val_loss: 227058.2969 - lr: 1.0000e-04\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 199085.0156 - val_loss: 226345.6250 - lr: 1.0000e-04\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 198771.3594 - val_loss: 226196.6719 - lr: 1.0000e-04\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 198549.2656 - val_loss: 226025.9375 - lr: 1.0000e-04\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 198276.7031 - val_loss: 225687.3125 - lr: 1.0000e-04\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 198076.9531 - val_loss: 225866.1406 - lr: 1.0000e-04\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 198045.8594 - val_loss: 225314.0781 - lr: 1.0000e-04\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 197710.0469 - val_loss: 225072.1875 - lr: 1.0000e-04\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 197492.9375 - val_loss: 225081.6562 - lr: 1.0000e-04\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 197325.9219 - val_loss: 224633.0312 - lr: 1.0000e-04\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 197039.2812 - val_loss: 224745.1250 - lr: 1.0000e-04\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 196979.8750 - val_loss: 224171.3906 - lr: 1.0000e-04\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 196862.5312 - val_loss: 224089.6250 - lr: 1.0000e-04\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 196472.9844 - val_loss: 224084.2969 - lr: 1.0000e-04\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 196326.0781 - val_loss: 223428.9844 - lr: 1.0000e-04\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 196151.2031 - val_loss: 223809.6406 - lr: 1.0000e-04\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 196121.9219 - val_loss: 223094.0938 - lr: 1.0000e-04\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 195618.9531 - val_loss: 222740.1094 - lr: 1.0000e-04\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 195496.1875 - val_loss: 222961.2812 - lr: 1.0000e-04\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 195354.1719 - val_loss: 222273.9531 - lr: 1.0000e-04\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 195348.0000 - val_loss: 222191.7500 - lr: 1.0000e-04\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 195031.1250 - val_loss: 222332.8906 - lr: 1.0000e-04\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 194834.7812 - val_loss: 221583.2969 - lr: 1.0000e-04\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 194441.1250 - val_loss: 222058.8750 - lr: 1.0000e-04\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 194634.7969 - val_loss: 221356.7500 - lr: 1.0000e-04\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 194147.8281 - val_loss: 221224.4531 - lr: 1.0000e-04\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 193864.6094 - val_loss: 221099.8281 - lr: 1.0000e-04\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 193770.6875 - val_loss: 220688.9219 - lr: 1.0000e-04\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 193411.0625 - val_loss: 220849.7656 - lr: 1.0000e-04\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 193331.6406 - val_loss: 220301.6875 - lr: 1.0000e-04\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 193077.6250 - val_loss: 220329.2812 - lr: 1.0000e-04\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 192909.8281 - val_loss: 219898.9375 - lr: 1.0000e-04\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 192849.7500 - val_loss: 219703.7812 - lr: 1.0000e-04\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 192484.1406 - val_loss: 219676.7344 - lr: 1.0000e-04\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 192298.0469 - val_loss: 219052.8125 - lr: 1.0000e-04\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 192201.3594 - val_loss: 219370.2344 - lr: 1.0000e-04\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 192146.2500 - val_loss: 218643.0312 - lr: 1.0000e-04\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 192001.0469 - val_loss: 218534.2344 - lr: 1.0000e-04\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 191621.2188 - val_loss: 218819.1719 - lr: 1.0000e-04\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 191441.8750 - val_loss: 217970.9375 - lr: 1.0000e-04\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 191440.5312 - val_loss: 218256.6719 - lr: 1.0000e-04\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 191212.4375 - val_loss: 217743.0312 - lr: 1.0000e-04\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 190873.5000 - val_loss: 217544.7031 - lr: 1.0000e-04\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 190810.2031 - val_loss: 217702.7500 - lr: 1.0000e-04\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 190619.2500 - val_loss: 217186.6250 - lr: 1.0000e-04\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 190250.9062 - val_loss: 217418.1250 - lr: 1.0000e-04\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 190115.1719 - val_loss: 216702.7031 - lr: 1.0000e-04\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 190013.0156 - val_loss: 216902.7500 - lr: 1.0000e-04\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 189714.0156 - val_loss: 216612.8594 - lr: 1.0000e-04\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 189503.7500 - val_loss: 216288.1562 - lr: 1.0000e-04\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 189321.5625 - val_loss: 216236.2031 - lr: 1.0000e-04\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 189175.4219 - val_loss: 215802.3438 - lr: 1.0000e-04\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 189213.2812 - val_loss: 215934.2031 - lr: 1.0000e-04\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 188907.2969 - val_loss: 215738.3125 - lr: 1.0000e-04\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 188782.3438 - val_loss: 215427.0156 - lr: 1.0000e-04\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 188338.0156 - val_loss: 215704.3750 - lr: 1.0000e-04\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 188363.4531 - val_loss: 214855.3438 - lr: 1.0000e-04\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 188111.7188 - val_loss: 215044.5781 - lr: 1.0000e-04\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 187912.0625 - val_loss: 214562.8438 - lr: 1.0000e-04\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 187646.1875 - val_loss: 214289.8906 - lr: 1.0000e-04\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 187515.3594 - val_loss: 214123.2031 - lr: 1.0000e-04\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 187269.4844 - val_loss: 213748.2656 - lr: 1.0000e-04\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 187282.8281 - val_loss: 213639.6875 - lr: 1.0000e-04\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 186927.9688 - val_loss: 213512.8906 - lr: 1.0000e-04\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 186726.2500 - val_loss: 213537.2969 - lr: 1.0000e-04\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 186630.4688 - val_loss: 213192.0781 - lr: 1.0000e-04\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 186363.1719 - val_loss: 213188.1094 - lr: 1.0000e-04\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 186224.7969 - val_loss: 212711.2344 - lr: 1.0000e-04\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 186188.4219 - val_loss: 212868.4219 - lr: 1.0000e-04\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 186119.8438 - val_loss: 212419.4844 - lr: 1.0000e-04\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 185788.7344 - val_loss: 212187.4375 - lr: 1.0000e-04\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 185653.3594 - val_loss: 212375.4844 - lr: 1.0000e-04\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 185346.2031 - val_loss: 211609.4062 - lr: 1.0000e-04\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 185440.1719 - val_loss: 212193.7344 - lr: 1.0000e-04\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 185365.7656 - val_loss: 211207.7188 - lr: 1.0000e-04\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 185057.7812 - val_loss: 211112.2188 - lr: 1.0000e-04\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 184925.7344 - val_loss: 211012.0625 - lr: 1.0000e-04\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 184730.2031 - val_loss: 210643.3281 - lr: 1.0000e-04\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 184400.3594 - val_loss: 211319.3906 - lr: 1.0000e-04\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 184582.0781 - val_loss: 210158.6250 - lr: 1.0000e-04\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 184278.1875 - val_loss: 210539.0938 - lr: 1.0000e-04\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 184008.7969 - val_loss: 209979.6406 - lr: 1.0000e-04\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 183670.2812 - val_loss: 209778.8438 - lr: 1.0000e-04\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 183496.5469 - val_loss: 209924.8438 - lr: 1.0000e-04\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 183267.7344 - val_loss: 209377.7500 - lr: 1.0000e-04\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 183232.1562 - val_loss: 209927.6250 - lr: 1.0000e-04\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 183162.5781 - val_loss: 209114.4531 - lr: 1.0000e-04\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 182895.3438 - val_loss: 209128.1562 - lr: 1.0000e-04\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 182809.3906 - val_loss: 208915.4219 - lr: 1.0000e-04\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 182706.3594 - val_loss: 208614.3594 - lr: 1.0000e-04\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 182279.5000 - val_loss: 209144.1562 - lr: 1.0000e-04\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 182579.4531 - val_loss: 208255.2031 - lr: 1.0000e-04\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 181975.7500 - val_loss: 208602.2500 - lr: 1.0000e-04\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 181890.0938 - val_loss: 207809.7344 - lr: 1.0000e-04\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 181843.9375 - val_loss: 208049.7344 - lr: 1.0000e-04\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 181706.9531 - val_loss: 207451.5469 - lr: 1.0000e-04\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 181757.9062 - val_loss: 207205.7656 - lr: 1.0000e-04\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 181432.4531 - val_loss: 207653.0625 - lr: 1.0000e-04\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 181494.4375 - val_loss: 206731.7188 - lr: 1.0000e-04\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 181086.2344 - val_loss: 207702.8750 - lr: 1.0000e-04\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 181003.4375 - val_loss: 206473.7812 - lr: 1.0000e-04\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 180856.6719 - val_loss: 206818.7812 - lr: 1.0000e-04\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 180875.9062 - val_loss: 206407.7188 - lr: 1.0000e-04\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 180374.1406 - val_loss: 206064.5156 - lr: 1.0000e-04\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 180540.3594 - val_loss: 206509.5938 - lr: 1.0000e-04\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 180059.8125 - val_loss: 205669.8750 - lr: 1.0000e-04\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 179879.7812 - val_loss: 206403.4219 - lr: 1.0000e-04\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 179919.9375 - val_loss: 205283.4531 - lr: 1.0000e-04\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 179739.2812 - val_loss: 205528.2500 - lr: 1.0000e-04\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 179326.5625 - val_loss: 205524.8125 - lr: 1.0000e-04\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 179055.9844 - val_loss: 204814.1094 - lr: 1.0000e-04\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 179166.4062 - val_loss: 205646.6562 - lr: 1.0000e-04\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 179274.6875 - val_loss: 204478.8125 - lr: 1.0000e-04\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 178796.0625 - val_loss: 204225.3438 - lr: 1.0000e-04\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 178566.3125 - val_loss: 205046.2031 - lr: 1.0000e-04\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 178735.9062 - val_loss: 203900.6094 - lr: 1.0000e-04\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 178129.8594 - val_loss: 203685.7656 - lr: 1.0000e-04\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 178012.9844 - val_loss: 203672.5781 - lr: 1.0000e-04\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 177806.0469 - val_loss: 203255.7344 - lr: 1.0000e-04\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 177815.2031 - val_loss: 203637.9375 - lr: 1.0000e-04\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 177905.8281 - val_loss: 202991.5469 - lr: 1.0000e-04\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 177478.2031 - val_loss: 202932.5156 - lr: 1.0000e-04\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 177394.0625 - val_loss: 203135.1094 - lr: 1.0000e-04\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 176984.6094 - val_loss: 202537.9062 - lr: 1.0000e-04\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 177170.6875 - val_loss: 202890.1406 - lr: 1.0000e-04\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 176856.5312 - val_loss: 202221.3594 - lr: 1.0000e-04\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 176752.2188 - val_loss: 202193.6094 - lr: 1.0000e-04\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 176371.4375 - val_loss: 202415.5312 - lr: 1.0000e-04\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 176344.7812 - val_loss: 201629.5156 - lr: 1.0000e-04\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 176373.9844 - val_loss: 202298.7031 - lr: 1.0000e-04\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 176513.9219 - val_loss: 201316.4531 - lr: 1.0000e-04\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 176092.2188 - val_loss: 201255.5156 - lr: 1.0000e-04\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 175712.0000 - val_loss: 201767.4531 - lr: 1.0000e-04\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 175655.5938 - val_loss: 200826.8750 - lr: 1.0000e-04\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 175760.6406 - val_loss: 201349.1250 - lr: 1.0000e-04\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 175435.7188 - val_loss: 200548.0000 - lr: 1.0000e-04\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 175366.7500 - val_loss: 200714.4062 - lr: 1.0000e-04\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 175037.2344 - val_loss: 200539.6875 - lr: 1.0000e-04\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 174749.2188 - val_loss: 199999.5000 - lr: 1.0000e-04\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 174869.2500 - val_loss: 200412.2969 - lr: 1.0000e-04\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 174738.2344 - val_loss: 199913.4062 - lr: 1.0000e-04\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 174402.8438 - val_loss: 200103.5781 - lr: 1.0000e-04\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 174360.8750 - val_loss: 199502.3906 - lr: 1.0000e-04\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 174088.7812 - val_loss: 199410.0625 - lr: 1.0000e-04\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 173892.5312 - val_loss: 199478.5625 - lr: 1.0000e-04\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 173766.4062 - val_loss: 199030.9531 - lr: 1.0000e-04\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 173736.3594 - val_loss: 199477.7812 - lr: 1.0000e-04\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 173684.1719 - val_loss: 198792.4844 - lr: 1.0000e-04\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 173401.7344 - val_loss: 198885.2188 - lr: 1.0000e-04\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 173282.2031 - val_loss: 198498.6250 - lr: 1.0000e-04\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 173063.9219 - val_loss: 198412.9531 - lr: 1.0000e-04\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 172903.0156 - val_loss: 198426.9531 - lr: 1.0000e-04\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 172909.4531 - val_loss: 198214.5000 - lr: 1.0000e-04\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 172610.4375 - val_loss: 198068.7656 - lr: 1.0000e-04\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 172470.6875 - val_loss: 197844.4219 - lr: 1.0000e-04\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 172326.8594 - val_loss: 197902.3750 - lr: 1.0000e-04\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 172223.5312 - val_loss: 197404.2500 - lr: 1.0000e-04\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 172242.9062 - val_loss: 197942.7188 - lr: 1.0000e-04\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 172254.9688 - val_loss: 197158.4375 - lr: 1.0000e-04\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 171948.4531 - val_loss: 197154.1406 - lr: 1.0000e-04\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 171768.6250 - val_loss: 197200.6250 - lr: 1.0000e-04\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 171485.3750 - val_loss: 196694.8438 - lr: 1.0000e-04\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 171605.3125 - val_loss: 196945.4531 - lr: 1.0000e-04\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 171300.2500 - val_loss: 196394.0625 - lr: 1.0000e-04\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 171313.6875 - val_loss: 196762.9375 - lr: 1.0000e-04\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 171219.2500 - val_loss: 196206.3438 - lr: 1.0000e-04\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 171112.4062 - val_loss: 196286.4062 - lr: 1.0000e-04\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 170890.8438 - val_loss: 196225.2812 - lr: 1.0000e-04\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 170984.6250 - val_loss: 195781.5000 - lr: 1.0000e-04\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 170338.8750 - val_loss: 196709.1562 - lr: 1.0000e-04\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 170757.2656 - val_loss: 195506.9688 - lr: 1.0000e-04\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 170766.4375 - val_loss: 195898.6875 - lr: 1.0000e-04\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 170311.2031 - val_loss: 195488.7344 - lr: 1.0000e-04\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 169975.5156 - val_loss: 195130.8125 - lr: 1.0000e-04\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 170212.2031 - val_loss: 195372.4844 - lr: 1.0000e-04\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 169967.3125 - val_loss: 194838.7188 - lr: 1.0000e-04\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 169588.9062 - val_loss: 195539.9531 - lr: 1.0000e-04\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 169870.8438 - val_loss: 194609.5625 - lr: 1.0000e-04\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 169240.4688 - val_loss: 194673.8906 - lr: 1.0000e-04\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 169105.8281 - val_loss: 194239.3906 - lr: 1.0000e-04\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 169069.3750 - val_loss: 194346.5938 - lr: 1.0000e-04\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 168882.2500 - val_loss: 193912.4375 - lr: 1.0000e-04\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 168754.9219 - val_loss: 193919.5938 - lr: 1.0000e-04\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 168539.1406 - val_loss: 193772.9219 - lr: 1.0000e-04\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 168391.8906 - val_loss: 193565.2656 - lr: 1.0000e-04\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 168331.4531 - val_loss: 193517.9688 - lr: 1.0000e-04\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 168135.6562 - val_loss: 193387.2812 - lr: 1.0000e-04\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 168073.7812 - val_loss: 193253.2031 - lr: 1.0000e-04\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 167876.9531 - val_loss: 193043.4062 - lr: 1.0000e-04\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 167743.4531 - val_loss: 193368.4219 - lr: 1.0000e-04\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 167733.1875 - val_loss: 192709.6562 - lr: 1.0000e-04\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 167757.7031 - val_loss: 192840.1094 - lr: 1.0000e-04\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 167345.3750 - val_loss: 192671.0469 - lr: 1.0000e-04\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 167228.2344 - val_loss: 192721.8906 - lr: 1.0000e-04\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 167136.5938 - val_loss: 192294.2969 - lr: 1.0000e-04\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 167017.2500 - val_loss: 192722.7500 - lr: 1.0000e-04\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 167072.5781 - val_loss: 192019.0156 - lr: 1.0000e-04\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 166803.0469 - val_loss: 192091.2031 - lr: 1.0000e-04\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 166594.6094 - val_loss: 191927.4844 - lr: 1.0000e-04\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 166719.0156 - val_loss: 191966.1562 - lr: 1.0000e-04\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 166725.1562 - val_loss: 191462.5781 - lr: 1.0000e-04\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 166553.7500 - val_loss: 191417.5625 - lr: 1.0000e-04\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 166361.9219 - val_loss: 191925.0469 - lr: 1.0000e-04\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 166260.5156 - val_loss: 190985.0312 - lr: 1.0000e-04\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 166528.5156 - val_loss: 192034.5938 - lr: 1.0000e-04\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 166546.8125 - val_loss: 190682.0000 - lr: 1.0000e-04\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 166262.5625 - val_loss: 190758.4062 - lr: 1.0000e-04\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 165504.8750 - val_loss: 191413.9375 - lr: 1.0000e-04\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 165757.5000 - val_loss: 190329.9062 - lr: 1.0000e-04\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 165351.4375 - val_loss: 191134.5625 - lr: 1.0000e-04\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 165429.9375 - val_loss: 190111.7188 - lr: 1.0000e-04\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 165120.2188 - val_loss: 190126.9375 - lr: 1.0000e-04\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 165043.7812 - val_loss: 190121.6094 - lr: 1.0000e-04\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 164636.5156 - val_loss: 189683.0625 - lr: 1.0000e-04\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 164957.4375 - val_loss: 190116.9688 - lr: 1.0000e-04\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 164548.2500 - val_loss: 189589.3750 - lr: 1.0000e-04\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 164391.4844 - val_loss: 189584.5781 - lr: 1.0000e-04\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 164165.3906 - val_loss: 189239.6562 - lr: 1.0000e-04\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 164298.9688 - val_loss: 189223.7188 - lr: 1.0000e-04\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 164080.8594 - val_loss: 189310.7188 - lr: 1.0000e-04\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 164000.0312 - val_loss: 189001.1094 - lr: 1.0000e-04\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 163876.7188 - val_loss: 188822.4688 - lr: 1.0000e-04\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 163729.1094 - val_loss: 188980.4531 - lr: 1.0000e-04\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 163607.9062 - val_loss: 188499.4219 - lr: 1.0000e-04\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 163488.4062 - val_loss: 189009.0312 - lr: 1.0000e-04\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 163341.9531 - val_loss: 188357.2656 - lr: 1.0000e-04\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 163086.0625 - val_loss: 188723.2031 - lr: 1.0000e-04\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 163011.9688 - val_loss: 188000.1562 - lr: 1.0000e-04\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 163107.9688 - val_loss: 188419.8125 - lr: 1.0000e-04\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 162813.9531 - val_loss: 187887.5781 - lr: 1.0000e-04\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 162937.7656 - val_loss: 188173.4062 - lr: 1.0000e-04\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 162598.9688 - val_loss: 187818.3125 - lr: 1.0000e-04\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 162456.5000 - val_loss: 187505.5000 - lr: 1.0000e-04\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 162222.0469 - val_loss: 187679.1406 - lr: 1.0000e-04\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 162105.3750 - val_loss: 187155.7812 - lr: 1.0000e-04\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 162067.5781 - val_loss: 187150.0312 - lr: 1.0000e-04\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 161818.2969 - val_loss: 186843.8125 - lr: 1.0000e-04\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 161773.6406 - val_loss: 186852.2031 - lr: 1.0000e-04\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 161651.5156 - val_loss: 186857.3594 - lr: 1.0000e-04\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 161521.0625 - val_loss: 186537.4688 - lr: 1.0000e-04\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 161377.9844 - val_loss: 186382.9531 - lr: 1.0000e-04\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 161286.7188 - val_loss: 186680.0625 - lr: 1.0000e-04\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 161143.2656 - val_loss: 186166.7500 - lr: 1.0000e-04\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 161257.0312 - val_loss: 186711.7500 - lr: 1.0000e-04\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 161012.5156 - val_loss: 186012.8438 - lr: 1.0000e-04\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 160811.6406 - val_loss: 186055.8125 - lr: 1.0000e-04\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 160708.1875 - val_loss: 185726.5938 - lr: 1.0000e-04\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 160682.2812 - val_loss: 185866.1406 - lr: 1.0000e-04\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 160698.7188 - val_loss: 185401.0312 - lr: 1.0000e-04\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 160599.7031 - val_loss: 185474.2969 - lr: 1.0000e-04\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 160184.5469 - val_loss: 185844.8906 - lr: 1.0000e-04\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 160229.4219 - val_loss: 184853.3906 - lr: 1.0000e-04\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 160162.1250 - val_loss: 185657.3281 - lr: 1.0000e-04\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 159950.7500 - val_loss: 184686.9688 - lr: 1.0000e-04\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 159834.6562 - val_loss: 185294.0312 - lr: 1.0000e-04\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 159674.9688 - val_loss: 184576.1562 - lr: 1.0000e-04\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 159504.6406 - val_loss: 184716.7500 - lr: 1.0000e-04\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 159302.9062 - val_loss: 184338.2031 - lr: 1.0000e-04\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 159199.1094 - val_loss: 184758.7969 - lr: 1.0000e-04\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 159167.3594 - val_loss: 184165.5156 - lr: 1.0000e-04\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 158957.7031 - val_loss: 184412.9844 - lr: 1.0000e-04\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 158864.1562 - val_loss: 184074.6562 - lr: 1.0000e-04\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 158705.2969 - val_loss: 184218.7969 - lr: 1.0000e-04\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 158605.4688 - val_loss: 183874.3594 - lr: 1.0000e-04\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 158480.0781 - val_loss: 184276.4219 - lr: 1.0000e-04\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 158469.1406 - val_loss: 183594.0156 - lr: 1.0000e-04\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 158313.3438 - val_loss: 183648.2188 - lr: 1.0000e-04\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 158116.4688 - val_loss: 183386.4844 - lr: 1.0000e-04\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 158033.1719 - val_loss: 183491.4062 - lr: 1.0000e-04\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 157931.8906 - val_loss: 183454.3125 - lr: 1.0000e-04\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 157830.4688 - val_loss: 183341.8906 - lr: 1.0000e-04\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 157694.5469 - val_loss: 182967.9844 - lr: 1.0000e-04\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 157535.6562 - val_loss: 183055.5625 - lr: 1.0000e-04\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 157442.4062 - val_loss: 182624.4375 - lr: 1.0000e-04\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 157536.4844 - val_loss: 183696.5938 - lr: 1.0000e-04\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 157699.2500 - val_loss: 182428.0312 - lr: 1.0000e-04\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 157593.2031 - val_loss: 183141.3125 - lr: 1.0000e-04\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 157264.7656 - val_loss: 182251.7344 - lr: 1.0000e-04\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 156951.2969 - val_loss: 182226.4375 - lr: 1.0000e-04\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 156759.5156 - val_loss: 182675.0625 - lr: 1.0000e-04\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 156791.6094 - val_loss: 181721.5000 - lr: 1.0000e-04\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 156803.6562 - val_loss: 182224.3125 - lr: 1.0000e-04\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 156466.9688 - val_loss: 181589.5312 - lr: 1.0000e-04\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 156408.6875 - val_loss: 182082.5938 - lr: 1.0000e-04\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 156308.2969 - val_loss: 181603.6406 - lr: 1.0000e-04\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 156077.6250 - val_loss: 181903.3438 - lr: 1.0000e-04\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 155998.4062 - val_loss: 181264.7812 - lr: 1.0000e-04\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 156116.6562 - val_loss: 182314.6562 - lr: 1.0000e-04\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 156198.7031 - val_loss: 181007.5625 - lr: 1.0000e-04\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 156254.7031 - val_loss: 182120.1875 - lr: 1.0000e-04\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 156281.2344 - val_loss: 180694.5312 - lr: 1.0000e-04\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 156027.6562 - val_loss: 181065.6250 - lr: 1.0000e-04\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 155871.2344 - val_loss: 180554.0312 - lr: 1.0000e-04\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 155766.2500 - val_loss: 180545.1406 - lr: 1.0000e-04\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 155589.9062 - val_loss: 181053.7344 - lr: 1.0000e-04\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 155401.9531 - val_loss: 180067.8438 - lr: 1.0000e-04\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 155324.3750 - val_loss: 181386.3750 - lr: 1.0000e-04\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 155138.6875 - val_loss: 180332.0000 - lr: 1.0000e-04\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 156930.2656 - val_loss: 181255.3281 - lr: 1.0000e-04\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 155735.3281 - val_loss: 180506.8125 - lr: 1.0000e-04\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 155460.7969 - val_loss: 179598.4375 - lr: 1.0000e-04\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 154666.7969 - val_loss: 181708.4531 - lr: 1.0000e-04\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 155250.6875 - val_loss: 179545.8906 - lr: 1.0000e-04\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 155445.1406 - val_loss: 180587.4531 - lr: 1.0000e-04\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 155586.4375 - val_loss: 179440.0469 - lr: 1.0000e-04\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 154712.0781 - val_loss: 179090.1875 - lr: 1.0000e-04\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 154264.9219 - val_loss: 181291.0469 - lr: 1.0000e-04\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 154876.9531 - val_loss: 178966.4219 - lr: 1.0000e-04\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 154774.4531 - val_loss: 179688.5938 - lr: 1.0000e-04\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 154165.2500 - val_loss: 178839.5312 - lr: 1.0000e-04\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 153629.0625 - val_loss: 178497.4688 - lr: 1.0000e-04\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 153841.0938 - val_loss: 179395.7344 - lr: 1.0000e-04\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 153446.7500 - val_loss: 178317.1875 - lr: 1.0000e-04\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 153549.0781 - val_loss: 179237.1562 - lr: 1.0000e-04\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 153413.4375 - val_loss: 178536.7812 - lr: 1.0000e-04\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 152963.4688 - val_loss: 178424.7344 - lr: 1.0000e-04\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 152848.8906 - val_loss: 178577.2188 - lr: 1.0000e-04\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 152754.4688 - val_loss: 178436.6406 - lr: 1.0000e-04\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 152621.5938 - val_loss: 178150.7344 - lr: 1.0000e-04\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 152548.1406 - val_loss: 178465.7969 - lr: 1.0000e-04\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 152541.7500 - val_loss: 178179.7188 - lr: 1.0000e-04\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 152368.0000 - val_loss: 178192.5469 - lr: 1.0000e-04\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 152343.7188 - val_loss: 177954.1094 - lr: 1.0000e-04\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 152129.6406 - val_loss: 177682.5781 - lr: 1.0000e-04\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 152000.9688 - val_loss: 177561.9531 - lr: 1.0000e-04\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 151933.5938 - val_loss: 178043.6250 - lr: 1.0000e-04\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 151980.0469 - val_loss: 177163.4375 - lr: 1.0000e-04\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 151986.2344 - val_loss: 177882.2344 - lr: 1.0000e-04\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 151800.2344 - val_loss: 177234.5156 - lr: 1.0000e-04\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 151522.6250 - val_loss: 177242.7500 - lr: 1.0000e-04\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 151382.6406 - val_loss: 177245.7656 - lr: 1.0000e-04\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 151296.3906 - val_loss: 177146.6250 - lr: 1.0000e-04\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 151250.5000 - val_loss: 177225.5781 - lr: 1.0000e-04\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 151205.4219 - val_loss: 176864.9531 - lr: 1.0000e-04\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 151105.6875 - val_loss: 176433.5938 - lr: 1.0000e-04\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 151196.1406 - val_loss: 177283.3906 - lr: 1.0000e-04\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 151143.2656 - val_loss: 176249.3125 - lr: 1.0000e-04\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 151002.9219 - val_loss: 176913.3125 - lr: 1.0000e-04\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 150810.9688 - val_loss: 176147.4844 - lr: 1.0000e-04\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 150668.2188 - val_loss: 176446.3438 - lr: 1.0000e-04\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 150534.7812 - val_loss: 176049.3906 - lr: 1.0000e-04\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 150585.9219 - val_loss: 176282.0312 - lr: 1.0000e-04\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 150302.3594 - val_loss: 176067.7812 - lr: 1.0000e-04\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 150287.7812 - val_loss: 175994.8594 - lr: 1.0000e-04\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 150197.9219 - val_loss: 175790.5938 - lr: 1.0000e-04\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 149957.7031 - val_loss: 175663.0781 - lr: 1.0000e-04\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 150136.0625 - val_loss: 175576.0312 - lr: 1.0000e-04\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 149769.5625 - val_loss: 175603.4062 - lr: 1.0000e-04\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 149618.1250 - val_loss: 175869.9531 - lr: 1.0000e-04\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 149645.3438 - val_loss: 175298.4062 - lr: 1.0000e-04\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 149564.6719 - val_loss: 175276.0312 - lr: 1.0000e-04\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 149448.4219 - val_loss: 175952.6719 - lr: 1.0000e-04\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 149558.4688 - val_loss: 174931.2969 - lr: 1.0000e-04\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 149693.4688 - val_loss: 175775.1719 - lr: 1.0000e-04\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 149410.5000 - val_loss: 174744.7656 - lr: 1.0000e-04\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 149401.1406 - val_loss: 175393.9531 - lr: 1.0000e-04\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 149080.1875 - val_loss: 174627.4062 - lr: 1.0000e-04\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 148861.7969 - val_loss: 174826.5469 - lr: 1.0000e-04\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 148712.9219 - val_loss: 174469.0312 - lr: 1.0000e-04\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 148586.1562 - val_loss: 174381.2500 - lr: 1.0000e-04\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 148493.5625 - val_loss: 174400.9219 - lr: 1.0000e-04\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 148513.3750 - val_loss: 174651.4531 - lr: 1.0000e-04\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 148439.3438 - val_loss: 173911.2656 - lr: 1.0000e-04\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 148518.9688 - val_loss: 175095.5469 - lr: 1.0000e-04\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 148659.5781 - val_loss: 173813.1562 - lr: 1.0000e-04\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 148185.0938 - val_loss: 174223.1094 - lr: 1.0000e-04\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 147965.0781 - val_loss: 173634.4062 - lr: 1.0000e-04\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 147990.7188 - val_loss: 173616.5156 - lr: 1.0000e-04\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 147842.4688 - val_loss: 174541.4688 - lr: 1.0000e-04\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 148103.8438 - val_loss: 173323.0469 - lr: 1.0000e-04\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 147913.1719 - val_loss: 174281.9688 - lr: 1.0000e-04\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 147862.2344 - val_loss: 173199.7500 - lr: 1.0000e-04\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 147771.6250 - val_loss: 174005.6250 - lr: 1.0000e-04\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 147594.5312 - val_loss: 173106.2812 - lr: 1.0000e-04\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 147353.7344 - val_loss: 173322.2344 - lr: 1.0000e-04\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 147144.5312 - val_loss: 173203.7656 - lr: 1.0000e-04\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 147257.2344 - val_loss: 173394.1719 - lr: 1.0000e-04\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 147049.6875 - val_loss: 173077.2500 - lr: 1.0000e-04\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 146928.5156 - val_loss: 173168.7031 - lr: 1.0000e-04\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 146771.8125 - val_loss: 172972.0469 - lr: 1.0000e-04\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 146703.3438 - val_loss: 173280.9531 - lr: 1.0000e-04\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 146692.2500 - val_loss: 172537.7656 - lr: 1.0000e-04\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 146775.2344 - val_loss: 173424.2812 - lr: 1.0000e-04\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 146713.9219 - val_loss: 172269.2500 - lr: 1.0000e-04\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 146614.6094 - val_loss: 172864.5469 - lr: 1.0000e-04\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 146356.4531 - val_loss: 172146.2812 - lr: 1.0000e-04\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 146130.9844 - val_loss: 172629.3438 - lr: 1.0000e-04\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 146141.2500 - val_loss: 172008.0625 - lr: 1.0000e-04\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 145975.3438 - val_loss: 172208.9531 - lr: 1.0000e-04\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 145856.8750 - val_loss: 172054.8750 - lr: 1.0000e-04\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 145725.5938 - val_loss: 172115.7500 - lr: 1.0000e-04\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 145677.3438 - val_loss: 171917.5781 - lr: 1.0000e-04\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 145635.6562 - val_loss: 171607.9375 - lr: 1.0000e-04\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 145617.6094 - val_loss: 171946.5781 - lr: 1.0000e-04\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 145445.5781 - val_loss: 171466.6094 - lr: 1.0000e-04\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 145678.8594 - val_loss: 173087.7188 - lr: 1.0000e-04\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 146455.1719 - val_loss: 171332.3125 - lr: 1.0000e-04\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 145815.2812 - val_loss: 172078.2969 - lr: 1.0000e-04\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 145793.0156 - val_loss: 171158.3125 - lr: 1.0000e-04\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 145491.0625 - val_loss: 171491.5312 - lr: 1.0000e-04\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 145376.1094 - val_loss: 171110.2344 - lr: 1.0000e-04\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 145280.3125 - val_loss: 171282.1719 - lr: 1.0000e-04\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 145219.5000 - val_loss: 171239.4062 - lr: 1.0000e-04\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 144844.5156 - val_loss: 170718.8438 - lr: 1.0000e-04\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 144825.6562 - val_loss: 171702.0781 - lr: 1.0000e-04\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 144877.2812 - val_loss: 170513.5625 - lr: 1.0000e-04\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 144695.5781 - val_loss: 171423.7812 - lr: 1.0000e-04\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 144748.7969 - val_loss: 170328.6406 - lr: 1.0000e-04\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 144287.5312 - val_loss: 171202.2031 - lr: 1.0000e-04\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 144499.0781 - val_loss: 170141.1562 - lr: 1.0000e-04\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 144425.1875 - val_loss: 171272.6094 - lr: 1.0000e-04\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 144602.2344 - val_loss: 170048.7188 - lr: 1.0000e-04\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 144006.8750 - val_loss: 170259.1094 - lr: 1.0000e-04\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 143755.8750 - val_loss: 170352.5469 - lr: 1.0000e-04\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 143747.2031 - val_loss: 170087.7656 - lr: 1.0000e-04\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 143675.9375 - val_loss: 170042.8438 - lr: 1.0000e-04\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 143621.6875 - val_loss: 170239.4844 - lr: 1.0000e-04\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 143586.5312 - val_loss: 169738.6406 - lr: 1.0000e-04\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 143464.0000 - val_loss: 170050.5938 - lr: 1.0000e-04\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 143337.2188 - val_loss: 169512.7969 - lr: 1.0000e-04\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 143230.4062 - val_loss: 169670.4688 - lr: 1.0000e-04\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 143056.4531 - val_loss: 169401.7969 - lr: 1.0000e-04\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 143081.5312 - val_loss: 170393.5625 - lr: 1.0000e-04\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 143481.1562 - val_loss: 169183.7812 - lr: 1.0000e-04\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 143452.0625 - val_loss: 170406.0781 - lr: 1.0000e-04\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 143619.9844 - val_loss: 169020.2969 - lr: 1.0000e-04\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 142891.2188 - val_loss: 169332.0938 - lr: 1.0000e-04\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 142825.0938 - val_loss: 168884.0000 - lr: 1.0000e-04\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 142735.7812 - val_loss: 169221.0156 - lr: 1.0000e-04\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 142526.3750 - val_loss: 168894.7188 - lr: 1.0000e-04\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 142484.1719 - val_loss: 169041.7031 - lr: 1.0000e-04\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 142425.1406 - val_loss: 168643.4844 - lr: 1.0000e-04\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 142314.5000 - val_loss: 168922.4688 - lr: 1.0000e-04\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 142285.3281 - val_loss: 168486.8438 - lr: 1.0000e-04\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 142224.0938 - val_loss: 168988.7031 - lr: 1.0000e-04\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 142187.1719 - val_loss: 168365.4062 - lr: 1.0000e-04\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 142090.2969 - val_loss: 168514.5469 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train.values, np.array(y_train), epochs=1000, batch_size=int(0.50*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test))\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0jkxJM_nHUQ0"
      },
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss = history.history['loss']\n",
        "test_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e9QSzJCEJppM"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSBUlEQVR4nO3deVwV5f4H8M+cAxz2RZFNUUhxVzQVQs26Sa7XUjPN6020xWtpalS/NHNJcynTLNNcSltN07KszELSFiP3XVzKBVMBDVkEZTnz/P4AxnPYVDgzA4fP+/U6L+Y888yc7xm68rnPPDMjCSEEiIiIiOyEQe8CiIiIiGyJ4YaIiIjsCsMNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaoBhsxYgRCQkL0LoOIqFphuCFSgSRJt/Tatm2b3qVa2bZtGyRJwvr16/UupVoJCQm5pd/nBx98YJPPmz17Nr766qtb6nvmzBlIkoQ33njDJp9NZA8c9C6AyB59/PHHVu8/+ugjxMXFlWpv0aJFlT5nxYoVkGW5Svugm1u4cCGuXr2qvN+0aRM+++wzvPnmm/D19VXaO3fubJPPmz17NgYNGoT+/fvbZH9EtQ3DDZEK/vvf/1q9/+OPPxAXF1eqvaScnBy4urre8uc4OjpWqj66PSVDRnJyMj777DP079+fpwWJqiGeliLSyb333ovWrVtjz5496NatG1xdXfHSSy8BAL7++mv07dsXQUFBMJlMaNy4MWbOnAmz2Wy1j5JzbixPUSxfvhyNGzeGyWRCp06dsGvXLpvVfurUKTz88MOoU6cOXF1dcdddd+G7774r1W/RokVo1aoVXF1d4ePjg44dO2L16tXK+qysLEyYMAEhISEwmUzw8/PD/fffj71795b72evXr4ckSfj5559LrVu2bBkkScLhw4cBFIaQkSNHokGDBjCZTAgMDMSDDz6IM2fOVP0glOGTTz5Bhw4d4OLigjp16uCRRx7BuXPnrPqcPHkSDz30EAICAuDs7IwGDRrgkUceQUZGBoDCU5rZ2dn48MMPldNdI0aMqHJtqampePzxx+Hv7w9nZ2eEh4fjww8/LNVvzZo16NChAzw8PODp6Yk2bdrgrbfeUtbn5+fjlVdeQVhYGJydnVG3bl107doVcXFxVa6RyFY4ckOko3/++Qe9e/fGI488gv/+97/w9/cHAHzwwQdwd3dHbGws3N3d8dNPP2Hq1KnIzMzEvHnzbrrf1atXIysrC//73/8gSRJef/11DBw4EKdOnaryaE9KSgo6d+6MnJwcjBs3DnXr1sWHH36IBx54AOvXr8eAAQMAFJ4yGzduHAYNGoTx48fj+vXrOHjwIHbs2IH//Oc/AIDRo0dj/fr1GDt2LFq2bIl//vkHv/32GxITE3HnnXeW+fl9+/aFu7s7Pv/8c9xzzz1W69auXYtWrVqhdevWAICHHnoIR44cwTPPPIOQkBCkpqYiLi4OSUlJNh9xmTVrFqZMmYLBgwfjiSeewKVLl7Bo0SJ069YN+/btg7e3N/Ly8tCzZ0/k5ubimWeeQUBAAM6fP49vv/0W6enp8PLywscff4wnnngCERERGDVqFACgcePGVart2rVruPfee/Hnn39i7NixCA0Nxbp16zBixAikp6dj/PjxAIC4uDgMHToU3bt3x2uvvQYASExMxPbt25U+06dPx5w5c5QaMzMzsXv3buzduxf3339/leokshlBRKobM2aMKPk/t3vuuUcAEEuXLi3VPycnp1Tb//73P+Hq6iquX7+utMXExIhGjRop70+fPi0AiLp164q0tDSl/euvvxYAxDfffFNhnVu3bhUAxLp168rtM2HCBAFA/Prrr0pbVlaWCA0NFSEhIcJsNgshhHjwwQdFq1atKvw8Ly8vMWbMmAr7lGXo0KHCz89PFBQUKG0XL14UBoNBzJgxQwghxJUrVwQAMW/evNve/83MmzdPABCnT58WQghx5swZYTQaxaxZs6z6HTp0SDg4OCjt+/btu+nxFUIINzc3ERMTc0u1FP/OK/qeCxcuFADEJ598orTl5eWJqKgo4e7uLjIzM4UQQowfP154enpaHdeSwsPDRd++fW+pNiK98LQUkY5MJhNGjhxZqt3FxUVZzsrKwuXLl3H33XcjJycHx44du+l+hwwZAh8fH+X93XffDaDwdFJVbdq0CREREejatavS5u7ujlGjRuHMmTM4evQoAMDb2xt///13hafDvL29sWPHDly4cOG2ahgyZAhSU1OtrjZbv349ZFnGkCFDABQeQycnJ2zbtg1Xrly5rf3fri+//BKyLGPw4MG4fPmy8goICEBYWBi2bt0KAPDy8gIA/PDDD8jJyVG1JkubNm1CQEAAhg4dqrQ5Ojpi3LhxuHr1qnKKz9vbG9nZ2RWeYvL29saRI0dw8uRJ1esmqqxaHW5++eUX9OvXD0FBQZAk6ZYvvSw2ffr0Mi8HdXNzU6dgsjv169eHk5NTqfYjR45gwIAB8PLygqenJ+rVq6dMRi6em1GRhg0bWr0vDjq2+CN/9uxZNGvWrFR78ZVfZ8+eBQC8+OKLcHd3R0REBMLCwjBmzBhs377dapvXX38dhw8fRnBwMCIiIjB9+vRbCmC9evWCl5cX1q5dq7StXbsW7dq1Q9OmTQEUBsfXXnsN33//Pfz9/dGtWze8/vrrSE5OrvR3L8/JkychhEBYWBjq1atn9UpMTERqaioAIDQ0FLGxsXjvvffg6+uLnj17YvHixbf0O62Ks2fPIiwsDAaD9T/5JX9nTz/9NJo2bYrevXujQYMGeOyxx7B582arbWbMmIH09HQ0bdoUbdq0wQsvvICDBw+qWj/R7arV4SY7Oxvh4eFYvHhxpbZ//vnncfHiRatXy5Yt8fDDD9u4UrJXliM0xdLT03HPPffgwIEDmDFjBr755hvExcUpcyBu5dJvo9FYZrsQomoF34YWLVrg+PHjWLNmDbp27YovvvgCXbt2xbRp05Q+gwcPxqlTp7Bo0SIEBQVh3rx5aNWqFb7//vsK920ymdC/f39s2LABBQUFOH/+PLZv366M2hSbMGECTpw4gTlz5sDZ2RlTpkxBixYtsG/fPpt+V1mWIUkSNm/ejLi4uFKvZcuWKX3nz5+PgwcP4qWXXsK1a9cwbtw4tGrVCn///bdNa6oMPz8/7N+/Hxs3bsQDDzyArVu3onfv3oiJiVH6dOvWDX/99RdWrlyJ1q1b47333sOdd96J9957T8fKiUrQ+7xYdQFAbNiwwart+vXr4rnnnhNBQUHC1dVVREREiK1bt5a7j/379wsA4pdfflG3WKpxyptzU9aclA0bNggA4ueff7ZqX758uQBg9d9geXNuypp/AUBMmzatwjpvZc5N06ZNRURERKn2uXPnCgDi0KFDZW6Xm5sr+vbtK4xGo7h27VqZfVJSUkT9+vVFly5dKqxTCCE2bdokAIjNmzeLN998UwAQp06dqnCbEydOCFdXVzFs2LCb7r8iJefcvP766wKAOH78+G3va/v27QKAmDx5stLm7u5u0zk3PXr0EAEBAcp8qGJr1qypcC6W2WwW//vf/wQAcfLkyTL7ZGVlifbt24v69evfUr1EWqjVIzc3M3bsWCQkJGDNmjU4ePAgHn74YfTq1avcc83vvfcemjZtqsxvIKqM4lEXYTHKkpeXhyVLluhVkpU+ffpg586dSEhIUNqys7OxfPlyhISEoGXLlgAKrwSz5OTkhJYtW0IIgfz8fJjN5lKnY/z8/BAUFITc3Nyb1hEdHY06depg7dq1WLt2LSIiIhAaGqqsz8nJwfXr1622ady4MTw8PKz2f/HiRRw7dgz5+fm3fhBKGDhwIIxGI1555ZVSo2NCCOVYZGZmoqCgwGp9mzZtYDAYrGpyc3NDenp6pespqU+fPkhOTrY6jVdQUIBFixbB3d1dueqs5O/MYDCgbdu2AKDUV7KPu7s7mjRpcku/MyKt8FLwciQlJWHVqlVISkpCUFAQgMLTUJs3b8aqVaswe/Zsq/7Xr1/Hp59+iokTJ+pRLtmRzp07w8fHBzExMRg3bhwkScLHH3+s6SmlL774osyJyzExMZg4cSI+++wz9O7dG+PGjUOdOnXw4Ycf4vTp0/jiiy+UeR09evRAQEAAunTpAn9/fyQmJuKdd95B37594eHhgfT0dDRo0ACDBg1CeHg43N3dsWXLFuzatQvz58+/aY2Ojo4YOHAg1qxZg+zs7FKPHzhx4gS6d++OwYMHo2XLlnBwcMCGDRuQkpKCRx55ROk3adIkpf7KXh7euHFjvPrqq5g0aRLOnDmD/v37w8PDA6dPn8aGDRswatQoPP/88/jpp58wduxYPPzww2jatCkKCgrw8ccfw2g04qGHHlL216FDB2zZsgULFixAUFAQQkNDERkZWWEN8fHxpcIcUHgDwlGjRmHZsmUYMWIE9uzZg5CQEKxfvx7bt2/HwoUL4eHhAQB44oknkJaWhvvuuw8NGjTA2bNnsWjRIrRr106Zn9OyZUvce++96NChA+rUqYPdu3crl/MTVRu6jhtVIyhxWurbb78VAISbm5vVy8HBQQwePLjU9qtXrxYODg4iOTlZw6qpprid01JCFJ6quOuuu4SLi4sICgoS//d//yd++OEHzU5Llfcqvvz7r7/+EoMGDRLe3t7C2dlZREREiG+//dZqX8uWLRPdunUTdevWFSaTSTRu3Fi88MILIiMjQwhReJrqhRdeEOHh4cLDw0O4ubmJ8PBwsWTJkgprtBQXFycACEmSxLlz56zWXb58WYwZM0Y0b95cuLm5CS8vLxEZGSk+//xzq34xMTFWp5huRcnTUsW++OIL0bVrV+Xfi+bNm4sxY8Yop6tOnTolHnvsMdG4cWPh7Ows6tSpI/71r3+JLVu2WO3n2LFjolu3bsLFxUUAqPAUVfHvvLzXxx9/LIQoPOU3cuRI4evrK5ycnESbNm3EqlWrrPa1fv160aNHD+Hn5yecnJxEw4YNxf/+9z9x8eJFpc+rr74qIiIihLe3t3BxcRHNmzcXs2bNEnl5ebd8/IjUJgmh4f8drMYkScKGDRuU26yvXbsWw4YNw5EjR0pNznR3d0dAQIBVW/fu3eHp6YkNGzZoVTIRERGVgaelytG+fXuYzWakpqbedA7N6dOnsXXrVmzcuFGj6oiIiKg8tTrcXL16FX/++afy/vTp09i/fz/q1KmDpk2bYtiwYRg+fDjmz5+P9u3b49KlS4iPj0fbtm3Rt29fZbuVK1ciMDAQvXv31uNrEBERkYVafVpq27Zt+Ne//lWqPSYmBh988AHy8/Px6quv4qOPPsL58+fh6+uLu+66C6+88gratGkDoPD+Fo0aNcLw4cMxa9Ysrb8CERERlVCrww0RERHZH97nhoiIiOwKww0RERHZlVo3oViWZVy4cAEeHh6QJEnvcoiIiOgWCCGQlZWFoKCgUg+BLanWhZsLFy4gODhY7zKIiIioEs6dO4cGDRpU2KfWhZvi24yfO3cOnp6eOldDREREtyIzMxPBwcHK3/GK1LpwU3wqytPTk+GGiIiohrmVKSWcUExERER2heGGiIiI7ArDDREREdmVWjfnhoiI7IvZbEZ+fr7eZZANODk53fQy71vBcENERDWSEALJyclIT0/XuxSyEYPBgNDQUDg5OVVpPww3RERUIxUHGz8/P7i6uvLGrDVc8U12L168iIYNG1bp98lwQ0RENY7ZbFaCTd26dfUuh2ykXr16uHDhAgoKCuDo6Fjp/XBCMRER1TjFc2xcXV11roRsqfh0lNlsrtJ+GG6IiKjG4qko+2Kr3yfDDREREdkVhhsiIqIaLiQkBAsXLtS7jGqD4YaIiEgjkiRV+Jo+fXql9rtr1y6MGjWqSrXde++9mDBhQpX2UV3waikbuZ6Xj+T0HHi6uaCOW9WuzyciIvt08eJFZXnt2rWYOnUqjh8/rrS5u7sry0IImM1mODjc/E91vXr1bFtoDceRGxs5d3QnQpY0hPn1Jnhr0RvILajaTG8iIrI/AQEBysvLywuSJCnvjx07Bg8PD3z//ffo0KEDTCYTfvvtN/z111948MEH4e/vD3d3d3Tq1Albtmyx2m/J01KSJOG9997DgAED4OrqirCwMGzcuLFKtX/xxRdo1aoVTCYTQkJCMH/+fKv1S5YsQVhYGJydneHv749BgwYp69avX482bdrAxcUFdevWRXR0NLKzs6tUT0UYbmxEvpYBAKgnZeDRy2/ip0NJOldERFS7CCGQk1egy0sIYbPvMXHiRMydOxeJiYlo27Ytrl69ij59+iA+Ph779u1Dr1690K9fPyQlVfx35pVXXsHgwYNx8OBB9OnTB8OGDUNaWlqlatqzZw8GDx6MRx55BIcOHcL06dMxZcoUfPDBBwCA3bt3Y9y4cZgxYwaOHz+OzZs3o1u3bgAKR6uGDh2Kxx57DImJidi2bRsGDhxo02NWEk9L2UizyJ5Am5PIebMD6pgzcfrAL0D7UL3LIiKqNa7lm9Fy6g+6fPbRGT3h6mSbP6kzZszA/fffr7yvU6cOwsPDlfczZ87Ehg0bsHHjRowdO7bc/YwYMQJDhw4FAMyePRtvv/02du7ciV69et12TQsWLED37t0xZcoUAEDTpk1x9OhRzJs3DyNGjEBSUhLc3Nzw73//Gx4eHmjUqBHat28PoDDcFBQUYODAgWjUqBEAoE2bNrddw+3gyI2tGIyAux+yfVoAAOSM8zoXRERENVHHjh2t3l+9ehXPP/88WrRoAW9vb7i7uyMxMfGmIzdt27ZVlt3c3ODp6YnU1NRK1ZSYmIguXbpYtXXp0gUnT56E2WzG/fffj0aNGuGOO+7Ao48+ik8//RQ5OTkAgPDwcHTv3h1t2rTBww8/jBUrVuDKlSuVquNWceTGxmT3QOAy4HwtRe9SiIhqFRdHI47O6KnbZ9uKm5ub1fvnn38ecXFxeOONN9CkSRO4uLhg0KBByMvLq3A/JR9fIEkSZFm2WZ2WPDw8sHfvXmzbtg0//vgjpk6diunTp2PXrl3w9vZGXFwcfv/9d/z4449YtGgRJk+ejB07diA0VJ0zHAw3Nmbwrg8A8MhjuCEi0pIkSTY7NVSdbN++HSNGjMCAAQMAFI7knDlzRtMaWrRoge3bt5eqq2nTpjAaC4Odg4MDoqOjER0djWnTpsHb2xs//fQTBg4cCEmS0KVLF3Tp0gVTp05Fo0aNsGHDBsTGxqpSr/39V6AzJ58gAIBnQRqEELw1OBERVUlYWBi+/PJL9OvXD5IkYcqUKaqNwFy6dAn79++3agsMDMRzzz2HTp06YebMmRgyZAgSEhLwzjvvYMmSJQCAb7/9FqdOnUK3bt3g4+ODTZs2QZZlNGvWDDt27EB8fDx69OgBPz8/7NixA5cuXUKLFi1U+Q4Aw43Nubp5AgBMIheZ1wrg5Vr5p5oSEREtWLAAjz32GDp37gxfX1+8+OKLyMzMVOWzVq9ejdWrV1u1zZw5Ey+//DI+//xzTJ06FTNnzkRgYCBmzJiBESNGAAC8vb3x5ZdfYvr06bh+/TrCwsLw2WefoVWrVkhMTMQvv/yChQsXIjMzE40aNcL8+fPRu3dvVb4DAEhCzWuxqqHMzEx4eXkhIyMDnp6etv+AQ+uBLx7HdnMrNHx2C4Lr8Im1RES2dv36dZw+fRqhoaFwdnbWuxyykYp+r7fz95tXS9maQ+EvwyTlI7dAnWFDIiIiKh/Dja0VhRtn5CHfzHBDRESkNYYbW3MsGrlBPvI4ckNERKQ5hhtb48gNERGRrhhubM1izg1HboiIiLTHcGNrFiM3eRy5ISIi0hzDja1xzg0REZGuGG5szeq0VIHOxRAREdU+DDe25nDjpkPm/Os6FkJERFQ7MdzYmkW4kXOv6VgIERFR7cRwY2tGB5iLDitHboiIyJIkSRW+pk+fXqV9f/XVVzbrV5PxwZkqMEuOMIpcmPNz9S6FiIiqkYsXLyrLa9euxdSpU3H8+HGlzd3dXY+y7A5HblQgS4WHtYATiomIyEJAQIDy8vLygiRJVm1r1qxBixYt4OzsjObNm2PJkiXKtnl5eRg7diwCAwPh7OyMRo0aYc6cOQCAkJAQAMCAAQMgSZLy/nbJsowZM2agQYMGMJlMaNeuHTZv3nxLNQghMH36dDRs2BAmkwlBQUEYN25c5Q5UFXHkRgUCRgCAmeGGiEg7QgD5Ofp8tqMrIElV2sWnn36KqVOn4p133kH79u2xb98+PPnkk3Bzc0NMTAzefvttbNy4EZ9//jkaNmyIc+fO4dy5cwCAXbt2wc/PD6tWrUKvXr1gNBorVcNbb72F+fPnY9myZWjfvj1WrlyJBx54AEeOHEFYWFiFNXzxxRd48803sWbNGrRq1QrJyck4cOBAlY5JZTHcqEBw5IaISHv5OcDsIH0++6ULgJNblXYxbdo0zJ8/HwMHDgQAhIaG4ujRo1i2bBliYmKQlJSEsLAwdO3aFZIkoVGjRsq29erVAwB4e3sjICCg0jW88cYbePHFF/HII48AAF577TVs3boVCxcuxOLFiyusISkpCQEBAYiOjoajoyMaNmyIiIiIStdSFTwtpQIhFY3cmBluiIjo5rKzs/HXX3/h8ccfh7u7u/J69dVX8ddffwEARowYgf3796NZs2YYN24cfvzxR5vWkJmZiQsXLqBLly5W7V26dEFiYuJNa3j44Ydx7do13HHHHXjyySexYcMG3f5Pvq4jN7/88gvmzZuHPXv24OLFi9iwYQP69+9f4Tbbtm1DbGwsjhw5guDgYLz88ssYMWKEJvXeKo7cEBHpwNG1cARFr8+ugqtXrwIAVqxYgcjISKt1xaeY7rzzTpw+fRrff/89tmzZgsGDByM6Ohrr16+v0mffjopqCA4OxvHjx7FlyxbExcXh6aefxrx58/Dzzz/D0dFRsxoBncNNdnY2wsPD8dhjjynDcBU5ffo0+vbti9GjR+PTTz9FfHw8nnjiCQQGBqJnz54aVHxrikduIMz6FkJEVJtIUpVPDenF398fQUFBOHXqFIYNG1ZuP09PTwwZMgRDhgzBoEGD0KtXL6SlpaFOnTpwdHSE2Vz5vzuenp4ICgrC9u3bcc899yjt27dvtzq9VFENLi4u6NevH/r164cxY8agefPmOHToEO68885K11UZuoab3r17o3fv3rfcf+nSpQgNDcX8+fMBAC1atMBvv/2GN998s3qFGxROKhMyww0REd2aV155BePGjYOXlxd69eqF3Nxc7N69G1euXEFsbCwWLFiAwMBAtG/fHgaDAevWrUNAQAC8vb0BFF4xFR8fjy5dusBkMsHHx6fczzp9+jT2799v1RYWFoYXXngB06ZNQ+PGjdGuXTusWrUK+/fvx6effgoAFdbwwQcfwGw2IzIyEq6urvjkk0/g4uJiNS9HKzVqQnFCQgKio6Ot2nr27IkJEyaUu01ubi5yc2/cbyYzM1Ot8hTKyA3DDRER3aInnngCrq6umDdvHl544QW4ubmhTZs2yt84Dw8PvP766zh58iSMRiM6deqETZs2wWAonAoxf/58xMbGYsWKFahfvz7OnDlT7mfFxsaWavv1118xbtw4ZGRk4LnnnkNqaipatmyJjRs3Iiws7KY1eHt7Y+7cuYiNjYXZbEabNm3wzTffoG7dujY/VjcjCSGE5p9aBkmSbjrnpmnTphg5ciQmTZqktG3atAl9+/ZFTk4OXFxcSm0zffp0vPLKK6XaMzIy4OnpaZPaS0qf2wre1//GkjuW4Onh5Q8vEhFR5Vy/fh2nT59GaGgonJ2db74B1QgV/V4zMzPh5eV1S3+/7f5qqUmTJiEjI0N5FV+PrybOuSEiItJPjTotFRAQgJSUFKu2lJQUeHp6ljlqAwAmkwkmk0mL8hTFV0tBljX9XCIiIqphIzdRUVGIj4+3aouLi0NUVJROFZWjaORG4sgNERGR5nQNN1evXsX+/fuVGdvFs7eTkpIAFJ5SGj58uNJ/9OjROHXqFP7v//4Px44dw5IlS/D555/j2Wef1aP8cikjNww3REREmtM13OzevRvt27dH+/btARTO3m7fvj2mTp0KoPDpqcVBByi8FfV3332HuLg4hIeHY/78+Xjvvfeq1WXggOXVUjwtRUSkpmpyTQzZiK1+n7rOubn33nsr/CIffPBBmdvs27dPxapsoPjhaRy5ISJSRfEdb8u7UpZqpry8PACo9IM/i9WoCcU1heCcGyIiVRmNRnh7eyM1NRUA4OrqCqmKT+UmfcmyjEuXLsHV1RUODlWLJww3KuBN/IiI1Ff89OvigEM1n8FgQMOGDascVBlu1KBMKOacGyIitUiShMDAQPj5+SE/P1/vcsgGnJyclDsuVwXDjQp4WoqISDtGo7HKczTIvtSo+9zUGModijlyQ0REpDWGGxWIoiE1jtwQERFpj+FGDRy5ISIi0g3DjRo454aIiEg3DDcqEEWXsEkcuSEiItIcw40aDLzPDRERkV4YbtSgnJbiyA0REZHWGG7UUBxuwJEbIiIirTHcqICXghMREemH4UYFknIpuG0e3U5ERES3juFGDQZeCk5ERKQXhhsVCE4oJiIi0g3DjQqkoqeCGzhyQ0REpDmGGzUYOHJDRESkF4YbNfBScCIiIt0w3KiBIzdERES6YbhRgcRwQ0REpBuGGzVwQjEREZFuGG7UUDxyA47cEBERaY3hRg08LUVERKQbhhsVFN/nhuGGiIhIeww3KigONwCfLUVERKQ1hhsVSJJUtMRwQ0REpDWGGxUo4YZPBSciItIcw40aOHJDRESkG4YbFShzbjhyQ0REpDmGGxUoAzccuSEiItIcw40KOHJDRESkH4YbFfBqKSIiIv0w3KhAMnDkhoiISC8MNypQ7lDMkRsiIiLNMdyogPe5ISIi0g/DjQo454aIiEg/DDcqYLghIiLSD8ONCm7MuQFkmQGHiIhISww3KigeuZEgIHPeDRERkaYYbtRgFW50roWIiKiWYbhRwY2RG0Bw3g0REZGmGG7UYHGfG56VIiIi0hbDjQos59wQERGRthhu1GARbjhyQ0REpC2GGxVYjtxwzg0REZG2GG5UceM+Nxy5ISIi0hbDjQqsR26IiIhISww3arC8FJxDN0RERJpiuFEDR26IiIh0w3CjAon3uSEiItKN7uFm8eLFCAkJgbOzMyIjI7Fz584K+y9cuBDNmjWDi4sLgoOD8eyzz+L69esaVXuLLE5LceiGiIhIW7qGm7Vr1yI2NhbTpk3D3r17ER4ejp49eyI1NbXM/qtXr8bEiRMxbdo0JCYm4v3338fatWvx0ksvaVx5xYonFIOXghMREWlO13CzYMECPPnkkxg5ciRatmyJpUuXwtXVFStXriyz/++//44uXbrgP//5D0JCQtCjRw8MHTr0pqM9WpN4Ez8iIiLd6BZu8vLysGfPHkRHR98oxmBAdHQ0EhISytymc+fO2LNnjxJmTp06hU2bNqFPnz6a1HzrCsONgeM2REREmnPQ64MvX74Ms9kMf39/q3Z/f38cO3aszG3+85//4PLly+jatSuEECgoKMDo0aMrPC2Vm5uL3Nxc5X1mZqZtvkAFrEduGG+IiIi0pPuE4tuxbds2zJ49G0uWLMHevXvx5Zdf4rvvvsPMmTPL3WbOnDnw8vJSXsHBwarXeeNqKc4nJiIi0ppuIze+vr4wGo1ISUmxak9JSUFAQECZ20yZMgWPPvoonnjiCQBAmzZtkJ2djVGjRmHy5MkwGEpntUmTJiE2NlZ5n5mZqX7A4ZwbIiIi3eg2cuPk5IQOHTogPj5eaZNlGfHx8YiKiipzm5ycnFIBxmg0Aij/TsAmkwmenp5WL/XxwZlERER60W3kBgBiY2MRExODjh07IiIiAgsXLkR2djZGjhwJABg+fDjq16+POXPmAAD69euHBQsWoH379oiMjMSff/6JKVOmoF+/fkrIqRYkiwDGbENERKQpXcPNkCFDcOnSJUydOhXJyclo164dNm/erEwyTkpKshqpefnllyFJEl5++WWcP38e9erVQ79+/TBr1iy9vkLZ+PgFIiIi3Uiill3Ok5mZCS8vL2RkZKh3iurgOuDLJ/CbuRWaPP8TAryc1fkcIiKiWuJ2/n7XqKulagzLp4Jz7IaIiEhTDDcq4tVSRERE2mO4UUPRyI1B4rgNERGR1hhuVME7FBMREemF4UYNylPBwdNSREREGmO4UcWNkRsiIiLSFsONGpRnS3FCMRERkdYYbtTAS8GJiIh0w3CjCj44k4iISC8MN2rg4xeIiIh0w3CjCovTUhy6ISIi0hTDjRqUkRuZIzdEREQaY7hRheXIjb6VEBER1TYMN2qQLO9zw3RDRESkJYYbVfBqKSIiIr0w3KhBuYkfx22IiIi0xnCjBqn4B0duiIiItMZwowreoZiIiEgvDDdqkDjnhoiISC8MN6ooOi/FcENERKQ5hhs18MGZREREumG4UUVhuDFA5sgNERGRxhhu1GAxckNERETaYrhRBScUExER6YXhRg3KTfwE59wQERFpjOFGDdKNE1IcuSEiItIWw40qLE5L6VwJERFRbcNwowarm/gx3hAREWmJ4UYVlve5ISIiIi0x3KiBj18gIiLSDcONKm6EGyIiItIWw40aikZuDJIAT0wRERFpi+FGFbwUnIiISC8MN2qQeCk4ERGRXhhu1MAJxURERLphuFGFxaXgTDdERESaYrhRA09LERER6YbhRhU8LUVERKQXhhs1SJZ3KGa6ISIi0hLDjSosbuLHbENERKQphhs1SMX3ueG4DRERkdYYblRRdIdizrkhIiLSHMONGqTCw1p4tRTTDRERkZYYbtRgOaGY2YaIiEhTDDeq4H1uiIiI9MJwowarxy8w3hAREWmJ4UYVlve5ISIiIi0x3KjB4lJwphsiIiJtMdyoiHcoJiIi0h7DjRokPluKiIhILww3qmC4ISIi0gvDjRqKbuJn4EkpIiIizekebhYvXoyQkBA4OzsjMjISO3furLB/eno6xowZg8DAQJhMJjRt2hSbNm3SqNpbxEvBiYiIdOOg54evXbsWsbGxWLp0KSIjI7Fw4UL07NkTx48fh5+fX6n+eXl5uP/+++Hn54f169ejfv36OHv2LLy9vbUvvkK8FJyIiEgvuoabBQsW4Mknn8TIkSMBAEuXLsV3332HlStXYuLEiaX6r1y5Emlpafj999/h6OgIAAgJCdGy5Ftj+VRwphsiIiJN6XZaKi8vD3v27EF0dPSNYgwGREdHIyEhocxtNm7ciKioKIwZMwb+/v5o3bo1Zs+eDbPZXO7n5ObmIjMz0+qlvhunpTh2Q0REpC3dws3ly5dhNpvh7+9v1e7v74/k5OQytzl16hTWr18Ps9mMTZs2YcqUKZg/fz5effXVcj9nzpw58PLyUl7BwcE2/R5l4oMziYiIdKP7hOLbIcsy/Pz8sHz5cnTo0AFDhgzB5MmTsXTp0nK3mTRpEjIyMpTXuXPnNKiUD84kIiLSi25zbnx9fWE0GpGSkmLVnpKSgoCAgDK3CQwMhKOjI4xGo9LWokULJCcnIy8vD05OTqW2MZlMMJlMti3+ZngTPyIiIt1UauTm3Llz+Pvvv5X3O3fuxIQJE7B8+fJb3oeTkxM6dOiA+Ph4pU2WZcTHxyMqKqrMbbp06YI///wTsiwrbSdOnEBgYGCZwUY/lldLMd0QERFpqVLh5j//+Q+2bt0KAEhOTsb999+PnTt3YvLkyZgxY8Yt7yc2NhYrVqzAhx9+iMTERDz11FPIzs5Wrp4aPnw4Jk2apPR/6qmnkJaWhvHjx+PEiRP47rvvMHv2bIwZM6YyX0M9xTfxkzhyQ0REpLVKnZY6fPgwIiIiAACff/45Wrduje3bt+PHH3/E6NGjMXXq1Fvaz5AhQ3Dp0iVMnToVycnJaNeuHTZv3qxMMk5KSoLBcCN/BQcH44cffsCzzz6Ltm3bon79+hg/fjxefPHFynwN9SiXgoM38SMiItJYpcJNfn6+Mo9ly5YteOCBBwAAzZs3x8WLF29rX2PHjsXYsWPLXLdt27ZSbVFRUfjjjz9ur2DNWYYbuYJ+REREZGuVOi3VqlUrLF26FL/++ivi4uLQq1cvAMCFCxdQt25dmxZYI1mM3PA+N0RERNqqVLh57bXXsGzZMtx7770YOnQowsPDARTeZK/4dBUVkRluiIiItFSp01L33nsvLl++jMzMTPj4+Cjto0aNgqurq82Kq7Es59yAp6WIiIi0VKmRm2vXriE3N1cJNmfPnsXChQvLfeBlrSNZHFaO3BAREWmqUuHmwQcfxEcffQQASE9PR2RkJObPn4/+/fvj3XfftWmBNZJFuOGEYiIiIm1VKtzs3bsXd999NwBg/fr18Pf3x9mzZ/HRRx/h7bfftmmBNZJ04w7KEOU/1JOIiIhsr1LhJicnBx4eHgCAH3/8EQMHDoTBYMBdd92Fs2fP2rTAGslgEW5khhsiIiItVSrcNGnSBF999RXOnTuHH374AT169AAApKamwtPT06YF1kgWIzcST0sRERFpqlLhZurUqXj++ecREhKCiIgI5VlQP/74I9q3b2/TAmski5EbiSM3REREmqrUpeCDBg1C165dcfHiReUeNwDQvXt3DBgwwGbF1ViSBBkSDBCcc0NERKSxSoUbAAgICEBAQIDydPAGDRrwBn4WZBhggJnhhoiISGOVOi0lyzJmzJgBLy8vNGrUCI0aNYK3tzdmzpwJWeYcEwAQxZeDc84NERGRpio1cjN58mS8//77mDt3Lrp06QIA+O233zB9+nRcv34ds2bNsmmRNZFcnBsZ9oiIiDRVqXDz4Ycf4r333lOeBg4Abdu2Rf369fH0008z3AAQxeGGp6WIiIg0VanTUmlpaWjevHmp9ubNmyMtLa3KRdkDWWK4ISIi0kOlwk14eDjeeeedUu3vvPMO2rZtW+Wi7IFyWopzboiIiDRVqdNSr7/+Ovr27YstW7Yo97hJSEjAuXPnsGnTJpsWWFPJKLzXjUEu0LkSIiKi2qVSIzf33HMPTpw4gQEDBiA9PR3p6ekYOHAgjhw5go8//tjWNdZIvFqKiIhIH5W+z01QUFCpicMHDhzA+++/j+XLl1e5sJpOZrghIiLSRaVGbujmRNFpKfC0FBERkaYYblQiQwLAB2cSERFpjeFGJZxzQ0REpI/bmnMzcODACtenp6dXpRa7Uny1FMMNERGRtm4r3Hh5ed10/fDhw6tUkL0oHrmReBM/IiIiTd1WuFm1apVaddgdmeGGiIhIF5xzo5LiZ0tdy83TuRIiIqLaheFGJbly4dVS3+z/W+dKiIiIaheGG5Vk5RZOJDaAE4qJiIi0xHCjEnPRoTUy3BAREWmK4UYlxU8F58gNERGRthhuVGJWwo3QuRIiIqLaheFGJbLgaSkiIiI9MNyoxFz0bCkDZMgyR2+IiIi0wnCjkrCAwrs5GyGjgOGGiIhIMww3Kqnr4QoAMEoyzAw3REREmmG4UYlkKHxwpgEyzILhhoiISCsMNyopDjdGyDCbGW6IiIi0wnCjEslw42qpAplXTBEREWmF4UYlPC1FRESkD4YbtUgWp6U4oZiIiEgzDDdqUUZuBAo454aIiEgzDDdqkSxOS3HkhoiISDMMN2qxvFqKc26IiIg0w3CjFufCOxQHSGkcuSEiItIQw41aGt4FAIgyHOWcGyIiIg0x3KilXgsAQDPD3/A6/KHOxRAREdUeDDdqKZpzAwD1f39Zx0KIiIhqF4YbtUg8tERERHrgX2C1WIzcAMA/V3N1KoSIiKh2YbhRi2Qdbpb+/JdOhRAREdUuDDdqKTFyk88rpoiIiDRRLcLN4sWLERISAmdnZ0RGRmLnzp23tN2aNWsgSRL69++vboGVUWLkhoiIiLShe7hZu3YtYmNjMW3aNOzduxfh4eHo2bMnUlNTK9zuzJkzeP7553H33XdrVOltKjFyA9msTx1ERES1jO7hZsGCBXjyyScxcuRItGzZEkuXLoWrqytWrlxZ7jZmsxnDhg3DK6+8gjvuuEPDam9DiaulDCJfp0KIiIhqF13DTV5eHvbs2YPo6GilzWAwIDo6GgkJCeVuN2PGDPj5+eHxxx/XoszKMThYvTWaebUUERGRFhxu3kU9ly9fhtlshr+/v1W7v78/jh07VuY2v/32G95//33s37//lj4jNzcXubk3gkVmZmal670tJU5LGeQ8bT6XiIioltP9tNTtyMrKwqOPPooVK1bA19f3lraZM2cOvLy8lFdwcLDKVRYpMaHYyNNSREREmtB15MbX1xdGoxEpKSlW7SkpKQgICCjV/6+//sKZM2fQr18/pU2WZQCAg4MDjh8/jsaNG1ttM2nSJMTGxirvMzMztQk4JUZujGaO3BAREWlB13Dj5OSEDh06ID4+XrmcW5ZlxMfHY+zYsaX6N2/eHIcOHbJqe/nll5GVlYW33nqrzNBiMplgMplUqb9CJSYUOwjOuSEiItKCruEGAGJjYxETE4OOHTsiIiICCxcuRHZ2NkaOHAkAGD58OOrXr485c+bA2dkZrVu3ttre29sbAEq1606SrN4aZZ6WIiIi0oLu4WbIkCG4dOkSpk6diuTkZLRr1w6bN29WJhknJSXBYKhRU4PKxHBDRESkDUkIUaueC5CZmQkvLy9kZGTA09NT3Q+b7qUsLg9ZgFEjqvGl60RERNXY7fz9rvlDIjUER26IiIi0wXCjFSHrXQEREVGtwHCjEUnw2VJERERaYLjRiIHhhoiISBMMNxoRfCo4ERGRJhhutCIX6F0BERFRrcBwoxHZzJEbIiIiLTDcaEVw5IaIiEgLDDcaEWaGGyIiIi0w3GhEyLzPDRERkRYYbrTCCcVERESaYLjRyIUrV/HHqX/0LoOIiMjuMdxoZJrjx3hkeYLeZRAREdk9hhsN3WvYr3cJREREdo/hRkN1kKV3CURERHaP4YaIiIjsCsONhiS9CyAiIqoFGG40JElC7xKIiIjsHsMNERER2RWGGw1J4MgNERGR2hhuiIiIyK4w3KipRT+rtxy5ISIiUh/DjZoe/ggFofcpbx1h1rEYIiKi2oHhRk0GA+ARoLx1Qr6OxRAREdUODDcqM0BWlh3BJ4MTERGpjeFGZZJFuHnc4XsgJ03HaoiIiOwfw43KJHFjErG/lA5sGK1fMURERLUAw43a5BKTiE/+oE8dREREtQTDjdqEfPM+REREZDMMN2orGW4cnPWpg4iIqJZguFFbiXBTYGS4ISIiUhPDjdpKhJvL13nIiYiI1MS/tGorEW5yhBPyzZyHQ0REpBaGG7UFtLF6ew0mXM/nYxiIiIjUwnCjtrufg7hnInKFAwAgXbgjt4AjN0RERGphuFGbowukf03Cxe6LCt9KBRy5ISIiUhHDjUZC/H0AFD48kyM3RERE6mG40YrRCQDgBDN2nebzpYiIiNTCcKOVonDT0nAWL315QOdiiIiI7BfDjVYcTMriSOP3OhZCRERk3xhutGJ0VBaHG+MgLJ4WTkRERLbDcKMV442Rm3w4cFIxERGRShhutFI05wYoDDfZuQU6FkNERGS/GG60IknKYh4ckJPHe90QERGpgeFGK05uyqIAkJ3HkRsiIiI1MNxoxSMARxsMAQB4IgfZuRy5ISIiUgPDjYZaDpwEALjDkAyXv3g5OBERkRoYbrTkE6IstvzlKf3qICIismMMN1qSJFw03aF3FURERHaN4UZjzkPeAwD8IzxwlZeDExER2RzDjcZ86voDANxxDceTs3SuhoiIyP4w3GjN5FH4QyrApSuZOhdDRERkf6pFuFm8eDFCQkLg7OyMyMhI7Ny5s9y+K1aswN133w0fHx/4+PggOjq6wv7VjpO7spie/o+OhRAREdkn3cPN2rVrERsbi2nTpmHv3r0IDw9Hz549kZqaWmb/bdu2YejQodi6dSsSEhIQHByMHj164Pz58xpXXkkGI/KlwkcxSKlHdS6GiIjI/khC58dTR0ZGolOnTnjnnXcAALIsIzg4GM888wwmTpx40+3NZjN8fHzwzjvvYPjw4Tftn5mZCS8vL2RkZMDT07PK9VfKdC8AwAVRB75T/oKTg+4Zk4iIqFq7nb/fuv5VzcvLw549exAdHa20GQwGREdHIyEh4Zb2kZOTg/z8fNSpU6fM9bm5ucjMzLR6VRdBUhpOpnJSMRERkS3pGm4uX74Ms9kMf39/q3Z/f38kJyff0j5efPFFBAUFWQUkS3PmzIGXl5fyCg4OrnLdVZXXb4myfOVKmo6VEBER2Z8afT5k7ty5WLNmDTZs2ABnZ+cy+0yaNAkZGRnK69y5cxpXWZpTk3uV5fo7Z+lXCBERkR1y0PPDfX19YTQakZKSYtWekpKCgICACrd94403MHfuXGzZsgVt27Ytt5/JZILJZLJJvTbjVk9ZDD27DsB7+tVCRERkZ3QduXFyckKHDh0QHx+vtMmyjPj4eERFRZW73euvv46ZM2di8+bN6Nixoxal2paDk7L4j/BAek6ejsUQERHZF91PS8XGxmLFihX48MMPkZiYiKeeegrZ2dkYOXIkAGD48OGYNGmS0v+1117DlClTsHLlSoSEhCA5ORnJycm4evWqXl+hUhKilgIAcuGIv69c07kaIiIi+6HraSkAGDJkCC5duoSpU6ciOTkZ7dq1w+bNm5VJxklJSTAYbmSwd999F3l5eRg0aJDVfqZNm4bp06drWXqVREbeDSQA/riCQ/9konV9L71LIiIisgu63+dGa9XiPjcAYC5A9qxGcJOvYlzeWLw9mxOLiYiIylNj7nNTqxkdkBjQHwBwl+EIsvmEcCIiIptguNFRh6j7AABdDEdw9p8cnashIiKyDww3OpL8WwIAGhlSkb7va52rISIisg8MN3qq1xwZjn4AgPNHftW5GCIiIvvAcKMnSUJB5NMAAPerZ1BglnUuiIiIqOZjuNGZT3Dhqak7cB5n0zjvhoiIqKoYbnRmCGoHAAiTzmPv8dP6FkNERGQHGG705uGPK66hMEgCf+7eonc1RERENR7DTTVgqN8eAOB+JRG17J6KRERENsdwUw24NQwHADSRTyE587rO1RAREdVsDDfVgENIFwDAfYb92Hn4hM7VEBER1WwMN9VBg45Ic2kEk5SPc4e3610NERFRjcZwUx1IEmTfFoXL//ylby1EREQ1HMNNNeES2BQA4H3tDK7nm3WuhoiIqOZiuKkmXOu3AgC0lM5g/7l0fYshIiKqwRhuqgkpOBIA0Fo6jZ3H/9a5GiIiopqL4aa68AnBNZMvnCQzMk7t1LsaIiKiGovhprqQJOQFdQIAeKTugSzzZn5ERESVwXBTjbg36QoAaCMfw6nLV3WuhoiIqGZiuKlGjI2iAAAdDCew72yaztUQERHVTAw31UlgW+QbTPCWsvH3n4f0roaIiKhGYripToyOyKrTBgAgJ3FSMRERUWUw3FQzppDCS8KDrh7E1dwCnashIiKqeRhuqhm3xoXzbtpLf+IAb+ZHRER02xhuqpvguwAAzQ3ncPAEnzNFRER0uxhuqhv3erjiUficqevH43UuhoiIqOZhuKmGjE3uAwA0SNuBbM67ISIiui0MN9WQZ6v7AQD3Gfbg9+MXdK6GiIioZmG4qY5C70WmYz3UlbLw9+9r9K6GiIioRmG4qY6MDrjW9lEAQOTFT5GRk6tzQURERDUHw0015XffGGTDFS2lM9jx9TK9yyEiIqoxGG6qKcnNF2dbPAkAaH38LWSlX9a5IiIiopqB4aYaa9b/RaRI9RCEy8hcORA4mwAIoXdZRERE1RrDTTVmNLnhxL1LkSNMqJ95AFjVC/KSu4Bd7wHZ/+hdHhERUbUkCVG7hgIyMzPh5eWFjIwMeHp66l3OTcmywIvL1qHT+U/wb+MfcJUKJxcLyQiE3gOp9UCgeV/AtY7OlRIREanndv5+M9zUAFdzC7Ds57/w7c5juO/aDxhg3I7WhjPKeiE5AI3/BanFv4GmvQEPf/2KJSIiUgHDTQVqYrgpVmCW8cepNHy9/zwSD+/FPQW/49/GP9DCkGTVT9TvCKlZb6BZH8CvBSBJOlVMRERkGww3FajJ4cbS9Xwzth1Pxdf7L+DMsX3oLv5AtHEP2hlOWfUTPiGQmvUBmvUGGkYBRkedKiYiIqo8hpsK2Eu4sZR5PR8/HE7GD0dScPzkcXQVexBt2IuuhsMwSflKP2HygtS0R+GITuP7ABdv/YomIiK6DQw3FbDHcGMpJ68Av5y4jB+PJuP3o2cRnrcP0YY9uM+4D3WlLKWfkAyQGkYVTkYODAfqNgHc/XkKi4iIqiWGmwrYe7ixVGCWsfvsFfx0LBU/Hb0Ar38O4H5j4ahOE0PpB3IKJ3dIdUKBOncAPqFA3caFy3UaAx4BDD5ERKQbhpsK1KZwU9Lpy9mIT0xBfGIqzp85ju7SLtxtOIQ7pIsIllJhlMr/T0E4uhUGH5+Qwpd3I4vlhoCjs0bfgoiIaiOGmwrU5nBjKeNaPn45cQlbj6Xi8IUM/H05A4FyMhpJKWgkpSBESkaIlIJQ6SLqS5crDD4AAI/A0qHHpxHgVg8wOgEOzoCDE2A0AQ4mwGDU4FsSEZG9YLipAMNN2QrMMpLScnD6cjbO/JODM5ezceafbJy+nI1L6ZlogFQES6loKKUiWLqEhspyKtyl67f/gZKxROAp/llWW9GrzDanomXnG8ulwlSJfTo4W+/L6MhTbkRE1dzt/P120KgmquYcjAbcUc8dd9RzL7Uut8CMc2k5OH25MPQkpeXg17QcnEvLwd9XsuFuzrQKPcHSjSDkLWXDCflwQgEMlqM/wgzkZxe+dCYgQbIMT6WCkmVgKlo2OhWGopLLDqay25Xlm6xX9m/RzlEuIqLbwnBDN2VyMKKJnwea+HmUWmeWBS6kX0NSWg7O/pODs2nZ+OWfwuXz6ddwLd+MvAIZgIAjzEVBpzDsOEn5MCEfJhQobSYpr3BdiT5Oxf2U92X3KdxHyT75cJIKrPo4SmblO0gQQMH1wleuhgf2VkkGiwBUQbAyOhWNRlWwvsx9lLV9efuoIJwZ+Kg6IqoeGG6oSowGCcF1XBFcxxVdmpTdRwiBfLNAnllGXoHFy2xGrtV76+Xy1uUULedarTOX6pdbxj6Ll2X5RtBSwpVVACp8X7j+RrByQgEci17FwarwvVlpc0QBHKXCnyaL/o5SQantS7Y5ogBOFsGr8ADKN8JXNSYkI+BggmTTkSvL8ORQ+DI63lgu9TKWfm/Vv+T6sl4MaUQ1HcMNqU6SJDg5SHByMAAmvaspZJYF8s0lA5KM3OKQVByQSgWy0gEsq+DGtvnmkvu78T7fYlvLsJdvLn4Vn7a7McpVMggVthfcWCdZrC8OWCVCmCPMcJIsQ1W+EqIcS4Qtp1L7LD+sOUiy1TGVhBnIzwHySx/vmkRAKjccSeUFKENFAepmAav4vWMZ642F89MMhqKfxhI/LdoNjoUjbwaHsvtIhhLbl/G+3HXFbQx+VDMw3FCtZDRIMBqMcHasPvNZLEe48otCT15R6LEMTfkFN9pyrcKRjDyzQL5Vv8K2TKsgJVAgyygo2kdBUdArKGovXp9fIJBf1K/ALCNfLvxZYC5sl81mSHLpAFZqdArmovb8EqNbZotQdSOsOaFE6CoKa0bIcIAZRshwLH4vmS3azXCADKNlH+nGNtY/zaVHyIpIEICcX/iiUoRkLBylkwwQlsGn5PtSQcwISQlIEiRJUsKXZNmnxD5vvCSLEHabL4OxcPsy1xtv7L/M7QzlrC9Zi1TOdkUvIQMFuYCjK2B0AFB0EYMkFS6X3I/ShhvrlLaSfYrbbrYvy/dS+evLbKtZF10w3BBVE9VxhOtmhBAokIUSeIoDU6mwZC47KClBynyjX/E218wysiyCV3nbl/wss3wjvBXIxe8FzCXbzGYI2VwY0kQBhFwAmAsAuTD8OErFganscORQFJxKBivlp1Ry2xJ9itY7WLVb9C/avwFyUZusLBf/NEqyxfrC0T5jiT4GSShtUvF2kGGAKLPvzUjCXDhKBwBl50OyUwLWgUhIFiN5lsEKEgoC74TTY9/oVCnDDRFVgSRJcDRKcDQCLqg+o2BVJRcFIrkovJmLwpNZFAcji3Wl3heGKKVv0faW72WLn2ZxYzmvaH/Ffa1eJdpkceOnLANmcWN/1utRqr24vxCF681y0bIsIGQzIMyQhAxRFGQkIUPIN5ZRtCyEUMKOsq7oZ+GrqB3iRiBD8elMUW7QMhQFrcLtRFFb6Z+SVZvFsiSX2lYq+ozitnLXSwJSiX0W9zUqfctZr3zujfWSxf5z4QQT8uCIwmMiICnbShbfRwKUn1KJ41AYIW70sdzWcrviuiz3f9P7ld2EBAEIUTgKBWXsqUynL6SiWZU+rWqqRbhZvHgx5s2bh+TkZISHh2PRokWIiIgot/+6deswZcoUnDlzBmFhYXjttdfQp08fDSsmIntmMEhwMtSsYfjqTAgBIVAYuCyWrYJVyeXisFW8XBTGzHLxtoUhTVkW1kFO+TzZelkWhfWYhcVycQgsDprC8jNKvL9ZzUWfbZaLwoZBsgiVNz5XVgLojXrMsoAoOl6yDAjcqNHymAkUbi9wo10U5w6LbYr7Wm0vF4UTIQAU/hRF7yXcWIblT9x4L4raCoOOGbIoimlKuwwIGXf418O7Ov43p3u4Wbt2LWJjY7F06VJERkZi4cKF6NmzJ44fPw4/P79S/X///XcMHToUc+bMwb///W+sXr0a/fv3x969e9G6dWsdvgEREVVEkqTCKTOQ9P+jQ7WC7ncojoyMRKdOnfDOO+8AAGRZRnBwMJ555hlMnDixVP8hQ4YgOzsb3377rdJ21113oV27dli6dOlNP493KCYiIqp5bufvt67X9eXl5WHPnj2Ijo5W2gwGA6Kjo5GQkFDmNgkJCVb9AaBnz57l9s/NzUVmZqbVi4iIiOyXruHm8uXLMJvN8Pf3t2r39/dHcnJymdskJyffVv85c+bAy8tLeQUHB9umeCIiIqqW7P6OTJMmTUJGRobyOnfunN4lERERkYp0ndvl6+sLo9GIlJQUq/aUlBQEBASUuU1AQMBt9TeZTDCZashNQ4iIiKjKdB25cXJyQocOHRAfH6+0ybKM+Ph4REVFlblNVFSUVX8AiIuLK7c/ERER1S66X5UXGxuLmJgYdOzYEREREVi4cCGys7MxcuRIAMDw4cNRv359zJkzBwAwfvx43HPPPZg/fz769u2LNWvWYPfu3Vi+fLmeX4OIiIiqCd3DzZAhQ3Dp0iVMnToVycnJaNeuHTZv3qxMGk5KSoLB4mFtnTt3xurVq/Hyyy/jpZdeQlhYGL766ive44aIiIgAVIP73GiN97khIiKqeWrMfW6IiIiIbI3hhoiIiOwKww0RERHZFYYbIiIisisMN0RERGRXdL8UXGvFF4fxAZpEREQ1R/Hf7Vu5yLvWhZusrCwA4AM0iYiIaqCsrCx4eXlV2KfW3edGlmVcuHABHh4ekCTJZvvNzMxEcHAwzp07x/vnqIzHWhs8ztrgcdYGj7N21DrWQghkZWUhKCjI6ua+Zal1IzcGgwENGjRQbf+enp78H45GeKy1weOsDR5nbfA4a0eNY32zEZtinFBMREREdoXhhoiIiOwKw42NmEwmTJs2DSaTSe9S7B6PtTZ4nLXB46wNHmftVIdjXesmFBMREZF948gNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3NjI4sWLERISAmdnZ0RGRmLnzp16l1SjzJkzB506dYKHhwf8/PzQv39/HD9+3KrP9evXMWbMGNStWxfu7u546KGHkJKSYtUnKSkJffv2haurK/z8/PDCCy+goKBAy69SY8ydOxeSJGHChAlKG4+x7Zw/fx7//e9/UbduXbi4uKBNmzbYvXu3sl4IgalTpyIwMBAuLi6Ijo7GyZMnrfaRlpaGYcOGwdPTE97e3nj88cdx9epVrb9KtWU2mzFlyhSEhobCxcUFjRs3xsyZM62ePcTjXDm//PIL+vXrh6CgIEiShK+++spqva2O68GDB3H33XfD2dkZwcHBeP31123zBQRV2Zo1a4STk5NYuXKlOHLkiHjyySeFt7e3SElJ0bu0GqNnz55i1apV4vDhw2L//v2iT58+omHDhuLq1atKn9GjR4vg4GARHx8vdu/eLe666y7RuXNnZX1BQYFo3bq1iI6OFvv27RObNm0Svr6+YtKkSXp8pWpt586dIiQkRLRt21aMHz9eaecxto20tDTRqFEjMWLECLFjxw5x6tQp8cMPP4g///xT6TN37lzh5eUlvvrqK3HgwAHxwAMPiNDQUHHt2jWlT69evUR4eLj4448/xK+//iqaNGkihg4dqsdXqpZmzZol6tatK7799ltx+vRpsW7dOuHu7i7eeustpQ+Pc+Vs2rRJTJ48WXz55ZcCgNiwYYPVelsc14yMDOHv7y+GDRsmDh8+LD777DPh4uIili1bVuX6GW5sICIiQowZM0Z5bzabRVBQkJgzZ46OVdVsqampAoD4+eefhRBCpKenC0dHR7Fu3TqlT2JiogAgEhIShBCF/2M0GAwiOTlZ6fPuu+8KT09PkZubq+0XqMaysrJEWFiYiIuLE/fcc48SbniMbefFF18UXbt2LXe9LMsiICBAzJs3T2lLT08XJpNJfPbZZ0IIIY4ePSoAiF27dil9vv/+eyFJkjh//rx6xdcgffv2FY899phV28CBA8WwYcOEEDzOtlIy3NjquC5ZskT4+PhY/dvx4osvimbNmlW5Zp6WqqK8vDzs2bMH0dHRSpvBYEB0dDQSEhJ0rKxmy8jIAADUqVMHALBnzx7k5+dbHefmzZujYcOGynFOSEhAmzZt4O/vr/Tp2bMnMjMzceTIEQ2rr97GjBmDvn37Wh1LgMfYljZu3IiOHTvi4Ycfhp+fH9q3b48VK1Yo60+fPo3k5GSrY+3l5YXIyEirY+3t7Y2OHTsqfaKjo2EwGLBjxw7tvkw11rlzZ8THx+PEiRMAgAMHDuC3335D7969AfA4q8VWxzUhIQHdunWDk5OT0qdnz544fvw4rly5UqUaa92DM23t8uXLMJvNVv/YA4C/vz+OHTumU1U1myzLmDBhArp06YLWrVsDAJKTk+Hk5ARvb2+rvv7+/khOTlb6lPV7KF5HwJo1a7B3717s2rWr1DoeY9s5deoU3n33XcTGxuKll17Crl27MG7cODg5OSEmJkY5VmUdS8tj7efnZ7XewcEBderU4bEuMnHiRGRmZqJ58+YwGo0wm82YNWsWhg0bBgA8ziqx1XFNTk5GaGhoqX0Ur/Px8al0jQw3VO2MGTMGhw8fxm+//aZ3KXbl3LlzGD9+POLi4uDs7Kx3OXZNlmV07NgRs2fPBgC0b98ehw8fxtKlSxETE6Nzdfbj888/x6efforVq1ejVatW2L9/PyZMmICgoCAe51qOp6WqyNfXF0ajsdQVJSkpKQgICNCpqppr7Nix+Pbbb7F161Y0aNBAaQ8ICEBeXh7S09Ot+lse54CAgDJ/D8Xrars9e/YgNTUVd955JxwcHODg4ICff/4Zb7/9NhwcHODv789jbCOBgYFo2bKlVVuLFi2QlJQE4MaxqujfjYCAAKSmplqtLygoQFpaGo91kRdeeAETJ07EI488gjZt2uDRRx/Fs88+izlz5gDgcVaLrY6rmv+eMNxUkZOTEzp06ID4+HilTZZlxMfHIyoqSsfKahYhBMaOHYsNGzbgp59+KjVU2aFDBzg6Olod5+PHjyMpKUk5zlFRUTh06JDV/6Di4uLg6elZ6g9NbdS9e3ccOnQI+/fvV14dO3bEsGHDlGUeY9vo0qVLqVsZnDhxAo0aNQIAhIaGIiAgwOpYZ2ZmYseOHVbHOj09HXv27FH6/PTTT5BlGZGRkRp8i+ovJycHBoP1nzGj0QhZlgHwOKvFVsc1KioKv/zyC/Lz85U+cXFxaNasWZVOSQHgpeC2sGbNGmEymcQHH3wgjh49KkaNGiW8vb2triihij311FPCy8tLbNu2TVy8eFF55eTkKH1Gjx4tGjZsKH766Sexe/duERUVJaKiopT1xZcp9+jRQ+zfv19s3rxZ1KtXj5cpV8DyaikheIxtZefOncLBwUHMmjVLnDx5Unz66afC1dVVfPLJJ0qfuXPnCm9vb/H111+LgwcPigcffLDMS2nbt28vduzYIX777TcRFhZW6y9RthQTEyPq16+vXAr+5ZdfCl9fX/F///d/Sh8e58rJysoS+/btE/v27RMAxIIFC8S+ffvE2bNnhRC2Oa7p6enC399fPProo+Lw4cNizZo1wtXVlZeCVyeLFi0SDRs2FE5OTiIiIkL88ccfepdUowAo87Vq1Sqlz7Vr18TTTz8tfHx8hKurqxgwYIC4ePGi1X7OnDkjevfuLVxcXISvr6947rnnRH5+vsbfpuYoGW54jG3nm2++Ea1btxYmk0k0b95cLF++3Gq9LMtiypQpwt/fX5hMJtG9e3dx/Phxqz7//POPGDp0qHB3dxeenp5i5MiRIisrS8uvUa1lZmaK8ePHi4YNGwpnZ2dxxx13iMmTJ1tdWszjXDlbt24t89/kmJgYIYTtjuuBAwdE165dhclkEvXr1xdz5861Sf2SEBa3ciQiIiKq4TjnhoiIiOwKww0RERHZFYYbIiIisisMN0RERGRXGG6IiIjIrjDcEBERkV1huCEiIiK7wnBDRLWSJEn46quv9C6DiFTAcENEmhsxYgQkSSr16tWrl96lEZEdcNC7ACKqnXr16oVVq1ZZtZlMJp2qISJ7wpEbItKFyWRCQECA1av4ScCSJOHdd99F79694eLigjvuuAPr16+32v7QoUO477774OLigrp162LUqFG4evWqVZ+VK1eiVatWMJlMCAwMxNixY63WX758GQMGDICrqyvCwsKwceNGZd2VK1cwbNgw1KtXDy4uLggLCysVxoioemK4IaJqacqUKXjooYdw4MABDBs2DI888ggSExMBANnZ2ejZsyd8fHywa9curFu3Dlu2bLEKL++++y7GjBmDUaNG4dChQ9i4cSOaNGli9RmvvPIKBg8ejIMHD6JPnz4YNmwY0tLSlM8/evQovv/+eyQmJuLdd9+Fr6+vdgeAiCrPJo/fJCK6DTExMcJoNAo3Nzer16xZs4QQhU+JHz16tNU2kZGR4qmnnhJCCLF8+XLh4+Mjrl69qqz/7rvvhMFgEMnJyUIIIYKCgsTkyZPLrQGAePnll5X3V69eFQDE999/L4QQol+/fmLkyJG2+cJEpCnOuSEiXfzrX//Cu+++a9VWp04dZTkqKspqXVRUFPbv3w8ASExMRHh4ONzc3JT1Xbp0gSzLOH78OCRJwoULF9C9e/cKa2jbtq2y7ObmBk9PT6SmpgIAnnrqKTz00EPYu3cvevTogf79+6Nz586V+q5EpC2GGyLShZubW6nTRLbi4uJyS/0cHR2t3kuSBFmWAQC9e/fG2bNnsWnTJsTFxaF79+4YM2YM3njjDZvXS0S2xTk3RFQt/fHHH6Xet2jRAgDQokULHDhwANnZ2cr67du3w2AwoFmzZvDw8EBISAji4+OrVEO9evUQExODTz75BAsXLsTy5curtD8i0gZHbohIF7m5uUhOTrZqc3BwUCbtrlu3Dh07dkTXrl3x6aefYufOnXj//fcBAMOGDcO0adMQExOD6dOn49KlS3jmmWfw6KOPwt/fHwAwffp0jB49Gn5+fujduzeysrKwfft2PPPMM7dU39SpU9GhQwe0atUKubm5+Pbbb5VwRUTVG8MNEeli8+bNCAwMtGpr1qwZjh07BqDwSqY1a9bg6aefRmBgID777DO0bNkSAODq6ooffvgB48ePR6dOneDq6oqHHnoICxYsUPYVExOD69ev480338Tzzz8PX19fDBo06Jbrc3JywqRJk3DmzBm4uLjg7rvvxpo1a2zwzYlIbZIQQuhdBBGRJUmSsGHDBvTv31/vUoioBuKcGyIiIrIrDDdERERkVzjnhoiqHZ4tJ6Kq4MgNERER2RWGGyIiIrIrDDdERERkVxhuiIiIyK4w3BAREZFdYbghIiIiu8JwQ0RERHaF4YaIiIjsCsMNERER2ZX/B5jffERfx5Q+AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, label='Train Loss')\n",
        "plt.plot(epochs, test_loss, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oZVN0NtEJ3rB"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotando o gráfico comparativo a partir da epoch 25\n",
        "epochs = range(20, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss[19:], label='Train Loss')\n",
        "plt.plot(epochs, test_loss[19:], label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdasOOxmKllh"
      },
      "source": [
        "### Modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tx8qxeUYKJ3Y"
      },
      "outputs": [],
      "source": [
        "# Crie o model2o sequencial\n",
        "model2 = tf.keras.models.Sequential() #Definimos que é um model2o de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a segunda camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a terceira camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quarta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(128, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model2.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model2.add(tf.keras.layers.Dense(1, activation='relu')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o model2o\n",
        "model2.compile(optimizer='adam', loss='mean_squared_error')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Fz7dWzj8KvU6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "2/2 [==============================] - 1s 174ms/step - loss: 133507405840384.0000 - val_loss: 132806730579968.0000 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 133506155937792.0000 - val_loss: 132797419225088.0000 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 133489269669888.0000 - val_loss: 132718406926336.0000 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 133365948743680.0000 - val_loss: 132281771491328.0000 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 132737566507008.0000 - val_loss: 130448776757248.0000 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 130251191484416.0000 - val_loss: 124092510371840.0000 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 121993739370496.0000 - val_loss: 105447252033536.0000 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 98861129400320.0000 - val_loss: 61825844510720.0000 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 50246084198400.0000 - val_loss: 15303737081856.0000 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 30696861073408.0000 - val_loss: 41938002640896.0000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 35090612617216.0000 - val_loss: 14097454202880.0000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 16013020102656.0000 - val_loss: 27066128924672.0000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 28493146488832.0000 - val_loss: 32896016449536.0000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 31578415693824.0000 - val_loss: 24969576710144.0000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 22137171607552.0000 - val_loss: 12688881090560.0000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 12357849841664.0000 - val_loss: 15488930283520.0000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 17748562280448.0000 - val_loss: 17283405578240.0000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 16235271028736.0000 - val_loss: 9752014749696.0000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 10088008908800.0000 - val_loss: 12475417231360.0000 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 12750273118208.0000 - val_loss: 13795316465664.0000 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 12932708564992.0000 - val_loss: 9969754701824.0000 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 9168993910784.0000 - val_loss: 7855080472576.0000 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 8440509890560.0000 - val_loss: 9451069243392.0000 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 9601255735296.0000 - val_loss: 7413775728640.0000 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 7288830033920.0000 - val_loss: 6901545304064.0000 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 6983049543680.0000 - val_loss: 7756125831168.0000 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 7451079344128.0000 - val_loss: 6610923028480.0000 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 6206421204992.0000 - val_loss: 5512533901312.0000 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 5663441289216.0000 - val_loss: 5810424905728.0000 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 5946655899648.0000 - val_loss: 5137038835712.0000 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 5136049504256.0000 - val_loss: 4878194704384.0000 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 4889553928192.0000 - val_loss: 5062714720256.0000 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 4904140668928.0000 - val_loss: 4470229958656.0000 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 4367487074304.0000 - val_loss: 4100195876864.0000 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 4224878641152.0000 - val_loss: 4034907865088.0000 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 4096185073664.0000 - val_loss: 3691825070080.0000 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3738583433216.0000 - val_loss: 3674832371712.0000 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3661586759680.0000 - val_loss: 3507544391680.0000 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3458266300416.0000 - val_loss: 3183428239360.0000 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 3239651835904.0000 - val_loss: 3055082274816.0000 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3127613063168.0000 - val_loss: 2869224538112.0000 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 2922731012096.0000 - val_loss: 2753218478080.0000 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 2779809579008.0000 - val_loss: 2638320500736.0000 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 2648080646144.0000 - val_loss: 2444366446592.0000 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 2483688046592.0000 - val_loss: 2305717436416.0000 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 2356285538304.0000 - val_loss: 2179722772480.0000 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 2215230832640.0000 - val_loss: 2077645602816.0000 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 2110856101888.0000 - val_loss: 1977660735488.0000 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1990936231936.0000 - val_loss: 1850388381696.0000 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1881741721600.0000 - val_loss: 1760604061696.0000 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1804409503744.0000 - val_loss: 1740341903360.0000 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1780454260736.0000 - val_loss: 1720435081216.0000 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1756581724160.0000 - val_loss: 1704403140608.0000 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1736794832896.0000 - val_loss: 1692216590336.0000 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1721216401408.0000 - val_loss: 1680080109568.0000 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1706134470656.0000 - val_loss: 1664420675584.0000 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1689058934784.0000 - val_loss: 1645936377856.0000 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1669914558464.0000 - val_loss: 1626851377152.0000 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1652940996608.0000 - val_loss: 1609324822528.0000 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1635753000960.0000 - val_loss: 1594278412288.0000 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1621113438208.0000 - val_loss: 1579786174464.0000 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1605719556096.0000 - val_loss: 1565202710528.0000 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1589328478208.0000 - val_loss: 1550955839488.0000 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1572855480320.0000 - val_loss: 1537380319232.0000 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1558135570432.0000 - val_loss: 1524787052544.0000 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1542961889280.0000 - val_loss: 1511679459328.0000 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1528222842880.0000 - val_loss: 1498272890880.0000 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1513601368064.0000 - val_loss: 1484384501760.0000 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1498833879040.0000 - val_loss: 1470451417088.0000 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1484525928448.0000 - val_loss: 1457112219648.0000 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1470637277184.0000 - val_loss: 1444275159040.0000 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1456903946240.0000 - val_loss: 1431818731520.0000 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1443155410944.0000 - val_loss: 1419620777984.0000 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1429399011328.0000 - val_loss: 1407788777472.0000 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1416201764864.0000 - val_loss: 1396038303744.0000 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1402831634432.0000 - val_loss: 1384400945152.0000 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1390248067072.0000 - val_loss: 1372769615872.0000 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1377268793344.0000 - val_loss: 1361104338944.0000 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1364537507840.0000 - val_loss: 1349677875200.0000 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1352262352896.0000 - val_loss: 1338548813824.0000 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1339967930368.0000 - val_loss: 1327641264128.0000 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1328026484736.0000 - val_loss: 1316869242880.0000 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1316030906368.0000 - val_loss: 1306388070400.0000 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1304201134080.0000 - val_loss: 1296183590912.0000 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1292857901056.0000 - val_loss: 1285950668800.0000 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1281529348096.0000 - val_loss: 1275694546944.0000 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1270056222720.0000 - val_loss: 1265578147840.0000 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1259084447744.0000 - val_loss: 1255689027584.0000 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1248297877504.0000 - val_loss: 1246000316416.0000 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1237670690816.0000 - val_loss: 1236498644992.0000 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1227027120128.0000 - val_loss: 1227103141888.0000 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1216666271744.0000 - val_loss: 1217867415552.0000 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1206547120128.0000 - val_loss: 1208764858368.0000 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1196352995328.0000 - val_loss: 1199763750912.0000 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1186651045888.0000 - val_loss: 1190898040832.0000 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1176709890048.0000 - val_loss: 1182191321088.0000 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1167202058240.0000 - val_loss: 1173614755840.0000 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1157791744000.0000 - val_loss: 1165165985792.0000 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1148406726656.0000 - val_loss: 1156863623168.0000 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1139074924544.0000 - val_loss: 1148696657920.0000 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1130954752000.0000 - val_loss: 1144634081280.0000 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1126472744960.0000 - val_loss: 1140603748352.0000 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1122048540672.0000 - val_loss: 1136586915840.0000 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1117615816704.0000 - val_loss: 1132595249152.0000 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1113229885440.0000 - val_loss: 1128633335808.0000 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1108877115392.0000 - val_loss: 1124717953024.0000 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 1104490004480.0000 - val_loss: 1120825114624.0000 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1100214829056.0000 - val_loss: 1116941975552.0000 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1095920386048.0000 - val_loss: 1113070501888.0000 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1091664347136.0000 - val_loss: 1109207678976.0000 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1087458050048.0000 - val_loss: 1105363861504.0000 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1083241529344.0000 - val_loss: 1101531054080.0000 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1079076454400.0000 - val_loss: 1097749364736.0000 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1074821726208.0000 - val_loss: 1093989040128.0000 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 1070786871296.0000 - val_loss: 1090246279168.0000 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 1066639425536.0000 - val_loss: 1086480973824.0000 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1062547750912.0000 - val_loss: 1082697121792.0000 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1058392244224.0000 - val_loss: 1078869360640.0000 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 1054372855808.0000 - val_loss: 1075077775360.0000 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1050346455040.0000 - val_loss: 1071346483200.0000 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1046263824384.0000 - val_loss: 1067647696896.0000 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1042351915008.0000 - val_loss: 1063970209792.0000 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 1038297989120.0000 - val_loss: 1060328046592.0000 - lr: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 1034352328704.0000 - val_loss: 1056697483264.0000 - lr: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 1030386810880.0000 - val_loss: 1053126230016.0000 - lr: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1026477195264.0000 - val_loss: 1049538789376.0000 - lr: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 1022583767040.0000 - val_loss: 1045956067328.0000 - lr: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1018676183040.0000 - val_loss: 1042343067648.0000 - lr: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1014833545216.0000 - val_loss: 1038652342272.0000 - lr: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 1010913771520.0000 - val_loss: 1034983243776.0000 - lr: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 1007044395008.0000 - val_loss: 1031362772992.0000 - lr: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 1003251892224.0000 - val_loss: 1027808755712.0000 - lr: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 999388676096.0000 - val_loss: 1024315621376.0000 - lr: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 995580575744.0000 - val_loss: 1020819931136.0000 - lr: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 991808192512.0000 - val_loss: 1017298354176.0000 - lr: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 988041641984.0000 - val_loss: 1013785821184.0000 - lr: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 984310153216.0000 - val_loss: 1010292948992.0000 - lr: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 980550615040.0000 - val_loss: 1006749351936.0000 - lr: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 976811655168.0000 - val_loss: 1003170103296.0000 - lr: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 973114703872.0000 - val_loss: 999646494720.0000 - lr: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 969418276864.0000 - val_loss: 996073275392.0000 - lr: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 965700026368.0000 - val_loss: 992578502656.0000 - lr: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 962015461376.0000 - val_loss: 989083992064.0000 - lr: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 958381162496.0000 - val_loss: 985613533184.0000 - lr: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 954720387072.0000 - val_loss: 982216474624.0000 - lr: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 951086546944.0000 - val_loss: 978839076864.0000 - lr: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 947472891904.0000 - val_loss: 975444115456.0000 - lr: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 943889383424.0000 - val_loss: 972072157184.0000 - lr: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 940340281344.0000 - val_loss: 968688533504.0000 - lr: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 936701394944.0000 - val_loss: 965263491072.0000 - lr: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 933708431360.0000 - val_loss: 964578050048.0000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 932987207680.0000 - val_loss: 963909844992.0000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 932279943168.0000 - val_loss: 963235479552.0000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 931560554496.0000 - val_loss: 962557771776.0000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 930865938432.0000 - val_loss: 961878687744.0000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 930141241344.0000 - val_loss: 961188724736.0000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 929440858112.0000 - val_loss: 960505839616.0000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 928712949760.0000 - val_loss: 959835799552.0000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 928001622016.0000 - val_loss: 959164645376.0000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 927308447744.0000 - val_loss: 958488772608.0000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 926558781440.0000 - val_loss: 957836886016.0000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 925856169984.0000 - val_loss: 957182574592.0000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 925152706560.0000 - val_loss: 956510502912.0000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 924406513664.0000 - val_loss: 955817590784.0000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 923688173568.0000 - val_loss: 955134050304.0000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 922958692352.0000 - val_loss: 954439172096.0000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 922240090112.0000 - val_loss: 953744359424.0000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 921503793152.0000 - val_loss: 953039585280.0000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 920770117632.0000 - val_loss: 952328585216.0000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 920043061248.0000 - val_loss: 951616471040.0000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 919305388032.0000 - val_loss: 950899113984.0000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 918582394880.0000 - val_loss: 950173499392.0000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 917847146496.0000 - val_loss: 949452996608.0000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 917115371520.0000 - val_loss: 948744028160.0000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 916368850944.0000 - val_loss: 948041285632.0000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 915636682752.0000 - val_loss: 947339198464.0000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 914886295552.0000 - val_loss: 946644320256.0000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 914145542144.0000 - val_loss: 945946034176.0000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 913402167296.0000 - val_loss: 945250500608.0000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 912658268160.0000 - val_loss: 944556474368.0000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 911915286528.0000 - val_loss: 943856353280.0000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 911166275584.0000 - val_loss: 943162851328.0000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 910418051072.0000 - val_loss: 942463123456.0000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 909677297664.0000 - val_loss: 941759987712.0000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 908926582784.0000 - val_loss: 941056524288.0000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 908170035200.0000 - val_loss: 940338118656.0000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 907430330368.0000 - val_loss: 939616960512.0000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 906669850624.0000 - val_loss: 938893901824.0000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 905917431808.0000 - val_loss: 938163830784.0000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 905158000640.0000 - val_loss: 937415540736.0000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 904395358208.0000 - val_loss: 936657485824.0000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 903641104384.0000 - val_loss: 935897923584.0000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 902881542144.0000 - val_loss: 935148847104.0000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 902126239744.0000 - val_loss: 934404161536.0000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 901381160960.0000 - val_loss: 933657903104.0000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 900608884736.0000 - val_loss: 932929994752.0000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 899841458176.0000 - val_loss: 932201955328.0000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 899081764864.0000 - val_loss: 931473588224.0000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 898304770048.0000 - val_loss: 930739126272.0000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 897538129920.0000 - val_loss: 930004336640.0000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 896774701056.0000 - val_loss: 929279508480.0000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 896001310720.0000 - val_loss: 928559333376.0000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 895233490944.0000 - val_loss: 927846367232.0000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 894465081344.0000 - val_loss: 927133794304.0000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 893711679488.0000 - val_loss: 926414143488.0000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 892921446400.0000 - val_loss: 925667295232.0000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 892146876416.0000 - val_loss: 924918743040.0000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 891377942528.0000 - val_loss: 924161802240.0000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 890602192896.0000 - val_loss: 923399290880.0000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 889830834176.0000 - val_loss: 922640973824.0000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 889048399872.0000 - val_loss: 921891110912.0000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 888275468288.0000 - val_loss: 921138757632.0000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 887495131136.0000 - val_loss: 920395841536.0000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 886717546496.0000 - val_loss: 919641653248.0000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 885936619520.0000 - val_loss: 918878945280.0000 - lr: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 885154775040.0000 - val_loss: 918115647488.0000 - lr: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 884379615232.0000 - val_loss: 917354119168.0000 - lr: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 883591544832.0000 - val_loss: 916608712704.0000 - lr: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 882820644864.0000 - val_loss: 915863568384.0000 - lr: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 882019205120.0000 - val_loss: 915106693120.0000 - lr: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 881246666752.0000 - val_loss: 914333433856.0000 - lr: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 880465346560.0000 - val_loss: 913562140672.0000 - lr: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 879664627712.0000 - val_loss: 912805920768.0000 - lr: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 878891106304.0000 - val_loss: 912052322304.0000 - lr: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 878108213248.0000 - val_loss: 911313731584.0000 - lr: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 877302513664.0000 - val_loss: 910558429184.0000 - lr: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 876520407040.0000 - val_loss: 909792313344.0000 - lr: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 875732860928.0000 - val_loss: 909027704832.0000 - lr: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 874937712640.0000 - val_loss: 908253921280.0000 - lr: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 874147545088.0000 - val_loss: 907477581824.0000 - lr: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 873372319744.0000 - val_loss: 906707206144.0000 - lr: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 872569700352.0000 - val_loss: 905920970752.0000 - lr: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 871772061696.0000 - val_loss: 905149087744.0000 - lr: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 870981632000.0000 - val_loss: 904380416000.0000 - lr: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 870198083584.0000 - val_loss: 903618494464.0000 - lr: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 869384716288.0000 - val_loss: 902877085696.0000 - lr: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 868595400704.0000 - val_loss: 902131417088.0000 - lr: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 867791863808.0000 - val_loss: 901369364480.0000 - lr: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 866983542784.0000 - val_loss: 900595712000.0000 - lr: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 866188460032.0000 - val_loss: 899820093440.0000 - lr: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 865382367232.0000 - val_loss: 899056402432.0000 - lr: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 864580009984.0000 - val_loss: 898294218752.0000 - lr: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 863765921792.0000 - val_loss: 897523253248.0000 - lr: 1.0000e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 862971822080.0000 - val_loss: 896752418816.0000 - lr: 1.0000e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 862168678400.0000 - val_loss: 895976734720.0000 - lr: 1.0000e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 861368352768.0000 - val_loss: 895203016704.0000 - lr: 1.0000e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 860553740288.0000 - val_loss: 894427332608.0000 - lr: 1.0000e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 859759050752.0000 - val_loss: 893650403328.0000 - lr: 1.0000e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 858951450624.0000 - val_loss: 892878389248.0000 - lr: 1.0000e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 858157416448.0000 - val_loss: 892107096064.0000 - lr: 1.0000e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 857349226496.0000 - val_loss: 891337703424.0000 - lr: 1.0000e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 856550866944.0000 - val_loss: 890569490432.0000 - lr: 1.0000e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 855737171968.0000 - val_loss: 889825001472.0000 - lr: 1.0000e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 854937174016.0000 - val_loss: 889072320512.0000 - lr: 1.0000e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 854140977152.0000 - val_loss: 888303976448.0000 - lr: 1.0000e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 853330427904.0000 - val_loss: 887512891392.0000 - lr: 1.0000e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 852505198592.0000 - val_loss: 886707585024.0000 - lr: 1.0000e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 851711557632.0000 - val_loss: 885908439040.0000 - lr: 1.0000e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 850902056960.0000 - val_loss: 885124497408.0000 - lr: 1.0000e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 850094587904.0000 - val_loss: 884360871936.0000 - lr: 1.0000e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 849276633088.0000 - val_loss: 883592462336.0000 - lr: 1.0000e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 848469032960.0000 - val_loss: 882831720448.0000 - lr: 1.0000e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 847658090496.0000 - val_loss: 882070126592.0000 - lr: 1.0000e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 846844919808.0000 - val_loss: 881299030016.0000 - lr: 1.0000e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 846033649664.0000 - val_loss: 880529637376.0000 - lr: 1.0000e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 845221658624.0000 - val_loss: 879761227776.0000 - lr: 1.0000e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 844416876544.0000 - val_loss: 878985216000.0000 - lr: 1.0000e-04\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 843608358912.0000 - val_loss: 878204092416.0000 - lr: 1.0000e-04\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 842782605312.0000 - val_loss: 877406126080.0000 - lr: 1.0000e-04\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 841976905728.0000 - val_loss: 876616876032.0000 - lr: 1.0000e-04\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 841153904640.0000 - val_loss: 875811110912.0000 - lr: 1.0000e-04\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 840341585920.0000 - val_loss: 875007377408.0000 - lr: 1.0000e-04\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 839528087552.0000 - val_loss: 874217734144.0000 - lr: 1.0000e-04\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 838711574528.0000 - val_loss: 873420357632.0000 - lr: 1.0000e-04\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 837929664512.0000 - val_loss: 872626061312.0000 - lr: 1.0000e-04\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 837098274816.0000 - val_loss: 871870038016.0000 - lr: 1.0000e-04\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 836258103296.0000 - val_loss: 871091011584.0000 - lr: 1.0000e-04\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 835435298816.0000 - val_loss: 870304907264.0000 - lr: 1.0000e-04\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 834625732608.0000 - val_loss: 869525422080.0000 - lr: 1.0000e-04\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 833796767744.0000 - val_loss: 868765663232.0000 - lr: 1.0000e-04\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 832961642496.0000 - val_loss: 868001710080.0000 - lr: 1.0000e-04\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 832170491904.0000 - val_loss: 867227402240.0000 - lr: 1.0000e-04\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 831356272640.0000 - val_loss: 866453946368.0000 - lr: 1.0000e-04\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 830524686336.0000 - val_loss: 865652834304.0000 - lr: 1.0000e-04\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 829702012928.0000 - val_loss: 864842809344.0000 - lr: 1.0000e-04\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 828873310208.0000 - val_loss: 864008273920.0000 - lr: 1.0000e-04\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 828043821056.0000 - val_loss: 863177539584.0000 - lr: 1.0000e-04\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 827242512384.0000 - val_loss: 862349950976.0000 - lr: 1.0000e-04\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 826415841280.0000 - val_loss: 861539467264.0000 - lr: 1.0000e-04\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 825598607360.0000 - val_loss: 860740976640.0000 - lr: 1.0000e-04\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 824765579264.0000 - val_loss: 859959263232.0000 - lr: 1.0000e-04\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 823948083200.0000 - val_loss: 859208220672.0000 - lr: 1.0000e-04\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 823139565568.0000 - val_loss: 858449772544.0000 - lr: 1.0000e-04\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 822308831232.0000 - val_loss: 857666748416.0000 - lr: 1.0000e-04\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 821473443840.0000 - val_loss: 856855412736.0000 - lr: 1.0000e-04\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 820652670976.0000 - val_loss: 856042831872.0000 - lr: 1.0000e-04\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 819814793216.0000 - val_loss: 855240605696.0000 - lr: 1.0000e-04\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 819017809920.0000 - val_loss: 854434840576.0000 - lr: 1.0000e-04\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 818186813440.0000 - val_loss: 853644476416.0000 - lr: 1.0000e-04\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 817367744512.0000 - val_loss: 852843888640.0000 - lr: 1.0000e-04\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 816541204480.0000 - val_loss: 852037337088.0000 - lr: 1.0000e-04\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 815725215744.0000 - val_loss: 851237666816.0000 - lr: 1.0000e-04\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 814910341120.0000 - val_loss: 850463096832.0000 - lr: 1.0000e-04\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 814080851968.0000 - val_loss: 849689378816.0000 - lr: 1.0000e-04\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 813251100672.0000 - val_loss: 848889118720.0000 - lr: 1.0000e-04\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 812439371776.0000 - val_loss: 848082436096.0000 - lr: 1.0000e-04\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 811619450880.0000 - val_loss: 847267692544.0000 - lr: 1.0000e-04\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 810786750464.0000 - val_loss: 846461992960.0000 - lr: 1.0000e-04\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 809964339200.0000 - val_loss: 845652688896.0000 - lr: 1.0000e-04\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 809135702016.0000 - val_loss: 844840828928.0000 - lr: 1.0000e-04\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 808331509760.0000 - val_loss: 844035260416.0000 - lr: 1.0000e-04\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 807491993600.0000 - val_loss: 843252170752.0000 - lr: 1.0000e-04\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 806679543808.0000 - val_loss: 842476617728.0000 - lr: 1.0000e-04\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 805854773248.0000 - val_loss: 841686908928.0000 - lr: 1.0000e-04\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 805021155328.0000 - val_loss: 840886124544.0000 - lr: 1.0000e-04\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 804187930624.0000 - val_loss: 840081408000.0000 - lr: 1.0000e-04\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 803366371328.0000 - val_loss: 839274201088.0000 - lr: 1.0000e-04\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 802537340928.0000 - val_loss: 838487900160.0000 - lr: 1.0000e-04\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 801720172544.0000 - val_loss: 837708611584.0000 - lr: 1.0000e-04\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 800883736576.0000 - val_loss: 836971659264.0000 - lr: 1.0000e-04\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 800051101696.0000 - val_loss: 836215767040.0000 - lr: 1.0000e-04\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 799241863168.0000 - val_loss: 835477962752.0000 - lr: 1.0000e-04\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 798472404992.0000 - val_loss: 834724757504.0000 - lr: 1.0000e-04\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 797612179456.0000 - val_loss: 833898020864.0000 - lr: 1.0000e-04\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 796787277824.0000 - val_loss: 833055752192.0000 - lr: 1.0000e-04\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 795945205760.0000 - val_loss: 832220692480.0000 - lr: 1.0000e-04\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 795133476864.0000 - val_loss: 831358304256.0000 - lr: 1.0000e-04\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 794283868160.0000 - val_loss: 830516887552.0000 - lr: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 793444810752.0000 - val_loss: 829677305856.0000 - lr: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 792654577664.0000 - val_loss: 828821733376.0000 - lr: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 791794155520.0000 - val_loss: 827995127808.0000 - lr: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 790976069632.0000 - val_loss: 827174617088.0000 - lr: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 790150053888.0000 - val_loss: 826372390912.0000 - lr: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 789308440576.0000 - val_loss: 825595723776.0000 - lr: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 788490223616.0000 - val_loss: 824817942528.0000 - lr: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 787657981952.0000 - val_loss: 824033345536.0000 - lr: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 786841206784.0000 - val_loss: 823230332928.0000 - lr: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 786023514112.0000 - val_loss: 822439772160.0000 - lr: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 785182490624.0000 - val_loss: 821611266048.0000 - lr: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 784362897408.0000 - val_loss: 820752154624.0000 - lr: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 783539240960.0000 - val_loss: 819899465728.0000 - lr: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 782692843520.0000 - val_loss: 819058704384.0000 - lr: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 781858242560.0000 - val_loss: 818228887552.0000 - lr: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 781036683264.0000 - val_loss: 817383800832.0000 - lr: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 780202803200.0000 - val_loss: 816551952384.0000 - lr: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 779382161408.0000 - val_loss: 815718137856.0000 - lr: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 778540941312.0000 - val_loss: 814909292544.0000 - lr: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 777709158400.0000 - val_loss: 814088912896.0000 - lr: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 776881045504.0000 - val_loss: 813275807744.0000 - lr: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 776048017408.0000 - val_loss: 812460146688.0000 - lr: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 775202930688.0000 - val_loss: 811649859584.0000 - lr: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 774383861760.0000 - val_loss: 810827710464.0000 - lr: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 773552209920.0000 - val_loss: 810003136512.0000 - lr: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 772703846400.0000 - val_loss: 809199009792.0000 - lr: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 771871408128.0000 - val_loss: 808390819840.0000 - lr: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 771038511104.0000 - val_loss: 807580532736.0000 - lr: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 770206924800.0000 - val_loss: 806774898688.0000 - lr: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 769379008512.0000 - val_loss: 805954387968.0000 - lr: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 768534708224.0000 - val_loss: 805124767744.0000 - lr: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 767724355584.0000 - val_loss: 804278632448.0000 - lr: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 766865309696.0000 - val_loss: 803469459456.0000 - lr: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 766050172928.0000 - val_loss: 802640232448.0000 - lr: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 765212884992.0000 - val_loss: 801833222144.0000 - lr: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 764377759744.0000 - val_loss: 801006813184.0000 - lr: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 763538898944.0000 - val_loss: 800152158208.0000 - lr: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 762709016576.0000 - val_loss: 799314411520.0000 - lr: 1.0000e-04\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 761876709376.0000 - val_loss: 798488330240.0000 - lr: 1.0000e-04\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 761044271104.0000 - val_loss: 797678895104.0000 - lr: 1.0000e-04\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 760216158208.0000 - val_loss: 796863954944.0000 - lr: 1.0000e-04\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 759366746112.0000 - val_loss: 796038594560.0000 - lr: 1.0000e-04\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 758548791296.0000 - val_loss: 795210481664.0000 - lr: 1.0000e-04\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 757729525760.0000 - val_loss: 794373849088.0000 - lr: 1.0000e-04\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 756886536192.0000 - val_loss: 793559498752.0000 - lr: 1.0000e-04\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 756051935232.0000 - val_loss: 792757665792.0000 - lr: 1.0000e-04\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 755223298048.0000 - val_loss: 791962255360.0000 - lr: 1.0000e-04\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 754396692480.0000 - val_loss: 791182508032.0000 - lr: 1.0000e-04\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 753586274304.0000 - val_loss: 790365274112.0000 - lr: 1.0000e-04\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 752730701824.0000 - val_loss: 789594636288.0000 - lr: 1.0000e-04\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 751903703040.0000 - val_loss: 788791951360.0000 - lr: 1.0000e-04\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 751072182272.0000 - val_loss: 787983695872.0000 - lr: 1.0000e-04\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 750242889728.0000 - val_loss: 787166330880.0000 - lr: 1.0000e-04\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 749412155392.0000 - val_loss: 786361417728.0000 - lr: 1.0000e-04\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 748579192832.0000 - val_loss: 785568169984.0000 - lr: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 747748458496.0000 - val_loss: 784732913664.0000 - lr: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 746913464320.0000 - val_loss: 783881011200.0000 - lr: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 746095771648.0000 - val_loss: 783036841984.0000 - lr: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 745240723456.0000 - val_loss: 782150729728.0000 - lr: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 744408743936.0000 - val_loss: 781258457088.0000 - lr: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 743577354240.0000 - val_loss: 780375097344.0000 - lr: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 742770212864.0000 - val_loss: 779513233408.0000 - lr: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 741953241088.0000 - val_loss: 778680270848.0000 - lr: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 741120475136.0000 - val_loss: 777844097024.0000 - lr: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 740306976768.0000 - val_loss: 777032630272.0000 - lr: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 739466870784.0000 - val_loss: 776250785792.0000 - lr: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 738629976064.0000 - val_loss: 775496990720.0000 - lr: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 737781547008.0000 - val_loss: 774740967424.0000 - lr: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 736969687040.0000 - val_loss: 773987434496.0000 - lr: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 736139476992.0000 - val_loss: 773228462080.0000 - lr: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 735320670208.0000 - val_loss: 772458151936.0000 - lr: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 734509334528.0000 - val_loss: 771688824832.0000 - lr: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 733670080512.0000 - val_loss: 770873360384.0000 - lr: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 732861759488.0000 - val_loss: 770046951424.0000 - lr: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 732030828544.0000 - val_loss: 769190068224.0000 - lr: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 731180892160.0000 - val_loss: 768328597504.0000 - lr: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 730353041408.0000 - val_loss: 767461949440.0000 - lr: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 729518505984.0000 - val_loss: 766608605184.0000 - lr: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 728684625920.0000 - val_loss: 765763125248.0000 - lr: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 727866343424.0000 - val_loss: 764927344640.0000 - lr: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 727042555904.0000 - val_loss: 764101591040.0000 - lr: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 726218768384.0000 - val_loss: 763282784256.0000 - lr: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 725393014784.0000 - val_loss: 762449166336.0000 - lr: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 724578861056.0000 - val_loss: 761616203776.0000 - lr: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 723758874624.0000 - val_loss: 760813649920.0000 - lr: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 722923749376.0000 - val_loss: 760006836224.0000 - lr: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 722092883968.0000 - val_loss: 759207493632.0000 - lr: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 721284366336.0000 - val_loss: 758405922816.0000 - lr: 1.0000e-04\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 720452911104.0000 - val_loss: 757603434496.0000 - lr: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 719624732672.0000 - val_loss: 756794327040.0000 - lr: 1.0000e-04\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 718780563456.0000 - val_loss: 756017856512.0000 - lr: 1.0000e-04\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 717964967936.0000 - val_loss: 755258163200.0000 - lr: 1.0000e-04\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 717136789504.0000 - val_loss: 754534187008.0000 - lr: 1.0000e-04\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 716322439168.0000 - val_loss: 753794809856.0000 - lr: 1.0000e-04\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 715505336320.0000 - val_loss: 753035116544.0000 - lr: 1.0000e-04\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 714689609728.0000 - val_loss: 752244490240.0000 - lr: 1.0000e-04\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 713879781376.0000 - val_loss: 751419260928.0000 - lr: 1.0000e-04\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 713029976064.0000 - val_loss: 750542192640.0000 - lr: 1.0000e-04\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 712194064384.0000 - val_loss: 749665976320.0000 - lr: 1.0000e-04\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 711368572928.0000 - val_loss: 748779143168.0000 - lr: 1.0000e-04\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 710568312832.0000 - val_loss: 747912626176.0000 - lr: 1.0000e-04\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 709726437376.0000 - val_loss: 747079008256.0000 - lr: 1.0000e-04\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 708933910528.0000 - val_loss: 746249781248.0000 - lr: 1.0000e-04\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 708099047424.0000 - val_loss: 745464266752.0000 - lr: 1.0000e-04\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 707256582144.0000 - val_loss: 744675409920.0000 - lr: 1.0000e-04\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 706464448512.0000 - val_loss: 743897628672.0000 - lr: 1.0000e-04\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 705617461248.0000 - val_loss: 743094288384.0000 - lr: 1.0000e-04\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 704798130176.0000 - val_loss: 742284787712.0000 - lr: 1.0000e-04\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 703971590144.0000 - val_loss: 741496717312.0000 - lr: 1.0000e-04\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 703180111872.0000 - val_loss: 740735320064.0000 - lr: 1.0000e-04\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 702347083776.0000 - val_loss: 739924770816.0000 - lr: 1.0000e-04\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 701554950144.0000 - val_loss: 739092070400.0000 - lr: 1.0000e-04\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 700702851072.0000 - val_loss: 738214412288.0000 - lr: 1.0000e-04\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 699886010368.0000 - val_loss: 737364869120.0000 - lr: 1.0000e-04\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 699079589888.0000 - val_loss: 736539508736.0000 - lr: 1.0000e-04\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 698252132352.0000 - val_loss: 735735382016.0000 - lr: 1.0000e-04\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 697451020288.0000 - val_loss: 734932369408.0000 - lr: 1.0000e-04\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 696650956800.0000 - val_loss: 734150787072.0000 - lr: 1.0000e-04\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 695813406720.0000 - val_loss: 733347315712.0000 - lr: 1.0000e-04\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 695007969280.0000 - val_loss: 732549414912.0000 - lr: 1.0000e-04\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 694190931968.0000 - val_loss: 731751776256.0000 - lr: 1.0000e-04\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 693385625600.0000 - val_loss: 730963050496.0000 - lr: 1.0000e-04\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 692558495744.0000 - val_loss: 730167836672.0000 - lr: 1.0000e-04\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 691749715968.0000 - val_loss: 729369477120.0000 - lr: 1.0000e-04\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 690931105792.0000 - val_loss: 728596807680.0000 - lr: 1.0000e-04\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 690111053824.0000 - val_loss: 727824662528.0000 - lr: 1.0000e-04\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 689295065088.0000 - val_loss: 727052386304.0000 - lr: 1.0000e-04\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 688497885184.0000 - val_loss: 726296035328.0000 - lr: 1.0000e-04\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 687675277312.0000 - val_loss: 725512683520.0000 - lr: 1.0000e-04\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 686864924672.0000 - val_loss: 724758364160.0000 - lr: 1.0000e-04\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 686055096320.0000 - val_loss: 723986546688.0000 - lr: 1.0000e-04\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 685246644224.0000 - val_loss: 723195068416.0000 - lr: 1.0000e-04\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 684445335552.0000 - val_loss: 722411192320.0000 - lr: 1.0000e-04\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 683615584256.0000 - val_loss: 721577050112.0000 - lr: 1.0000e-04\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 682805231616.0000 - val_loss: 720739303424.0000 - lr: 1.0000e-04\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 681988325376.0000 - val_loss: 719890022400.0000 - lr: 1.0000e-04\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 681189703680.0000 - val_loss: 719041265664.0000 - lr: 1.0000e-04\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 680377319424.0000 - val_loss: 718208761856.0000 - lr: 1.0000e-04\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 679567949824.0000 - val_loss: 717377896448.0000 - lr: 1.0000e-04\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 678759956480.0000 - val_loss: 716570624000.0000 - lr: 1.0000e-04\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 677944098816.0000 - val_loss: 715769380864.0000 - lr: 1.0000e-04\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 677145280512.0000 - val_loss: 714979672064.0000 - lr: 1.0000e-04\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 676341153792.0000 - val_loss: 714204774400.0000 - lr: 1.0000e-04\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 675527327744.0000 - val_loss: 713416638464.0000 - lr: 1.0000e-04\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 674731327488.0000 - val_loss: 712620376064.0000 - lr: 1.0000e-04\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 673929691136.0000 - val_loss: 711787085824.0000 - lr: 1.0000e-04\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 673114030080.0000 - val_loss: 710980534272.0000 - lr: 1.0000e-04\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 672323928064.0000 - val_loss: 710206947328.0000 - lr: 1.0000e-04\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 671508594688.0000 - val_loss: 709399478272.0000 - lr: 1.0000e-04\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 670691295232.0000 - val_loss: 708617633792.0000 - lr: 1.0000e-04\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 669897981952.0000 - val_loss: 707845357568.0000 - lr: 1.0000e-04\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 669106372608.0000 - val_loss: 707058008064.0000 - lr: 1.0000e-04\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 668281995264.0000 - val_loss: 706252242944.0000 - lr: 1.0000e-04\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 667491631104.0000 - val_loss: 705463648256.0000 - lr: 1.0000e-04\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 666672562176.0000 - val_loss: 704649494528.0000 - lr: 1.0000e-04\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 665872695296.0000 - val_loss: 703843139584.0000 - lr: 1.0000e-04\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 665073549312.0000 - val_loss: 703036194816.0000 - lr: 1.0000e-04\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 664281939968.0000 - val_loss: 702241112064.0000 - lr: 1.0000e-04\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 663475453952.0000 - val_loss: 701455400960.0000 - lr: 1.0000e-04\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 662664314880.0000 - val_loss: 700676112384.0000 - lr: 1.0000e-04\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 661874016256.0000 - val_loss: 699893940224.0000 - lr: 1.0000e-04\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 661077360640.0000 - val_loss: 699121467392.0000 - lr: 1.0000e-04\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 660272316416.0000 - val_loss: 698340605952.0000 - lr: 1.0000e-04\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 659466747904.0000 - val_loss: 697565315072.0000 - lr: 1.0000e-04\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 658675531776.0000 - val_loss: 696771608576.0000 - lr: 1.0000e-04\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 657874681856.0000 - val_loss: 695984390144.0000 - lr: 1.0000e-04\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 657085169664.0000 - val_loss: 695213817856.0000 - lr: 1.0000e-04\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 656277045248.0000 - val_loss: 694409625600.0000 - lr: 1.0000e-04\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 655482093568.0000 - val_loss: 693611134976.0000 - lr: 1.0000e-04\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 654691008512.0000 - val_loss: 692820705280.0000 - lr: 1.0000e-04\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 653880918016.0000 - val_loss: 692024311808.0000 - lr: 1.0000e-04\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 653087539200.0000 - val_loss: 691227459584.0000 - lr: 1.0000e-04\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 652300255232.0000 - val_loss: 690428313600.0000 - lr: 1.0000e-04\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 651500060672.0000 - val_loss: 689618616320.0000 - lr: 1.0000e-04\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 650708975616.0000 - val_loss: 688811802624.0000 - lr: 1.0000e-04\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 649917693952.0000 - val_loss: 688012460032.0000 - lr: 1.0000e-04\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 649140436992.0000 - val_loss: 687224782848.0000 - lr: 1.0000e-04\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 648330215424.0000 - val_loss: 686417313792.0000 - lr: 1.0000e-04\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 647555514368.0000 - val_loss: 685600866304.0000 - lr: 1.0000e-04\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 646752239616.0000 - val_loss: 684824592384.0000 - lr: 1.0000e-04\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 645957156864.0000 - val_loss: 684052578304.0000 - lr: 1.0000e-04\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 645165613056.0000 - val_loss: 683283972096.0000 - lr: 1.0000e-04\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 644378198016.0000 - val_loss: 682541842432.0000 - lr: 1.0000e-04\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 643581280256.0000 - val_loss: 681776971776.0000 - lr: 1.0000e-04\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 642783182848.0000 - val_loss: 680992702464.0000 - lr: 1.0000e-04\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 641998979072.0000 - val_loss: 680217214976.0000 - lr: 1.0000e-04\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 641204092928.0000 - val_loss: 679453786112.0000 - lr: 1.0000e-04\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 640421199872.0000 - val_loss: 678679740416.0000 - lr: 1.0000e-04\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 639633129472.0000 - val_loss: 677921226752.0000 - lr: 1.0000e-04\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 638846763008.0000 - val_loss: 677139382272.0000 - lr: 1.0000e-04\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 638053449728.0000 - val_loss: 676370907136.0000 - lr: 1.0000e-04\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 637262430208.0000 - val_loss: 675593912320.0000 - lr: 1.0000e-04\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 636485566464.0000 - val_loss: 674801647616.0000 - lr: 1.0000e-04\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 635692056576.0000 - val_loss: 674021703680.0000 - lr: 1.0000e-04\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 634896187392.0000 - val_loss: 673237762048.0000 - lr: 1.0000e-04\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 634116112384.0000 - val_loss: 672448118784.0000 - lr: 1.0000e-04\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 633338331136.0000 - val_loss: 671655591936.0000 - lr: 1.0000e-04\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 632550326272.0000 - val_loss: 670831738880.0000 - lr: 1.0000e-04\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 631748558848.0000 - val_loss: 669961224192.0000 - lr: 1.0000e-04\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 630948691968.0000 - val_loss: 669094445056.0000 - lr: 1.0000e-04\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 630169665536.0000 - val_loss: 668251979776.0000 - lr: 1.0000e-04\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 629395161088.0000 - val_loss: 667428061184.0000 - lr: 1.0000e-04\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 628628062208.0000 - val_loss: 666639728640.0000 - lr: 1.0000e-04\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 627845824512.0000 - val_loss: 665857490944.0000 - lr: 1.0000e-04\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 627099303936.0000 - val_loss: 665104941056.0000 - lr: 1.0000e-04\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 626270273536.0000 - val_loss: 664316149760.0000 - lr: 1.0000e-04\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 625495834624.0000 - val_loss: 663553572864.0000 - lr: 1.0000e-04\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 624713203712.0000 - val_loss: 662811246592.0000 - lr: 1.0000e-04\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 623947218944.0000 - val_loss: 662085042176.0000 - lr: 1.0000e-04\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 623156527104.0000 - val_loss: 661343502336.0000 - lr: 1.0000e-04\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 622371340288.0000 - val_loss: 660609302528.0000 - lr: 1.0000e-04\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 621621870592.0000 - val_loss: 659873857536.0000 - lr: 1.0000e-04\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 620845858816.0000 - val_loss: 659105972224.0000 - lr: 1.0000e-04\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 620075679744.0000 - val_loss: 658357878784.0000 - lr: 1.0000e-04\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 619293769728.0000 - val_loss: 657570267136.0000 - lr: 1.0000e-04\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 618532044800.0000 - val_loss: 656785473536.0000 - lr: 1.0000e-04\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 617752952832.0000 - val_loss: 655984623616.0000 - lr: 1.0000e-04\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 616981528576.0000 - val_loss: 655180496896.0000 - lr: 1.0000e-04\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 616206761984.0000 - val_loss: 654383120384.0000 - lr: 1.0000e-04\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 615428194304.0000 - val_loss: 653593870336.0000 - lr: 1.0000e-04\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 614662864896.0000 - val_loss: 652807831552.0000 - lr: 1.0000e-04\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 613898518528.0000 - val_loss: 652008947712.0000 - lr: 1.0000e-04\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 613144854528.0000 - val_loss: 651232280576.0000 - lr: 1.0000e-04\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 612357963776.0000 - val_loss: 650432282624.0000 - lr: 1.0000e-04\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 611578150912.0000 - val_loss: 649634709504.0000 - lr: 1.0000e-04\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 610839560192.0000 - val_loss: 648848015360.0000 - lr: 1.0000e-04\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 610067480576.0000 - val_loss: 648077967360.0000 - lr: 1.0000e-04\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 609302151168.0000 - val_loss: 647328890880.0000 - lr: 1.0000e-04\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 608524632064.0000 - val_loss: 646570967040.0000 - lr: 1.0000e-04\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 607760941056.0000 - val_loss: 645821956096.0000 - lr: 1.0000e-04\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 606990237696.0000 - val_loss: 645095882752.0000 - lr: 1.0000e-04\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 606217437184.0000 - val_loss: 644358930432.0000 - lr: 1.0000e-04\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 605445292032.0000 - val_loss: 643648913408.0000 - lr: 1.0000e-04\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 604685139968.0000 - val_loss: 642922315776.0000 - lr: 1.0000e-04\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 603933442048.0000 - val_loss: 642179727360.0000 - lr: 1.0000e-04\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 603149893632.0000 - val_loss: 641471873024.0000 - lr: 1.0000e-04\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 602412351488.0000 - val_loss: 640750845952.0000 - lr: 1.0000e-04\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 601652396032.0000 - val_loss: 640000393216.0000 - lr: 1.0000e-04\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 600881889280.0000 - val_loss: 639231000576.0000 - lr: 1.0000e-04\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 600121671680.0000 - val_loss: 638419795968.0000 - lr: 1.0000e-04\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 599368466432.0000 - val_loss: 637617045504.0000 - lr: 1.0000e-04\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 598593175552.0000 - val_loss: 636813180928.0000 - lr: 1.0000e-04\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 597828632576.0000 - val_loss: 636011610112.0000 - lr: 1.0000e-04\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 597076017152.0000 - val_loss: 635235860480.0000 - lr: 1.0000e-04\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 596336640000.0000 - val_loss: 634449428480.0000 - lr: 1.0000e-04\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 595562987520.0000 - val_loss: 633709002752.0000 - lr: 1.0000e-04\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 594841763840.0000 - val_loss: 632963137536.0000 - lr: 1.0000e-04\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 594083446784.0000 - val_loss: 632180834304.0000 - lr: 1.0000e-04\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 593300815872.0000 - val_loss: 631446175744.0000 - lr: 1.0000e-04\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 592562880512.0000 - val_loss: 630741204992.0000 - lr: 1.0000e-04\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 591799386112.0000 - val_loss: 630010675200.0000 - lr: 1.0000e-04\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 591050440704.0000 - val_loss: 629321170944.0000 - lr: 1.0000e-04\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 590283472896.0000 - val_loss: 628616003584.0000 - lr: 1.0000e-04\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 589550387200.0000 - val_loss: 627887702016.0000 - lr: 1.0000e-04\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 588797509632.0000 - val_loss: 627136004096.0000 - lr: 1.0000e-04\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 588068356096.0000 - val_loss: 626400165888.0000 - lr: 1.0000e-04\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 587313905664.0000 - val_loss: 625586536448.0000 - lr: 1.0000e-04\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 586554671104.0000 - val_loss: 624803774464.0000 - lr: 1.0000e-04\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 585796157440.0000 - val_loss: 624059809792.0000 - lr: 1.0000e-04\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 585055076352.0000 - val_loss: 623320301568.0000 - lr: 1.0000e-04\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 584301084672.0000 - val_loss: 622605238272.0000 - lr: 1.0000e-04\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 583566163968.0000 - val_loss: 621892599808.0000 - lr: 1.0000e-04\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 582806667264.0000 - val_loss: 621158203392.0000 - lr: 1.0000e-04\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 582078758912.0000 - val_loss: 620424396800.0000 - lr: 1.0000e-04\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 581329813504.0000 - val_loss: 619684429824.0000 - lr: 1.0000e-04\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 580577329152.0000 - val_loss: 618939547648.0000 - lr: 1.0000e-04\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 579840704512.0000 - val_loss: 618196107264.0000 - lr: 1.0000e-04\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 579106570240.0000 - val_loss: 617419243520.0000 - lr: 1.0000e-04\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 578350612480.0000 - val_loss: 616675082240.0000 - lr: 1.0000e-04\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 577610842112.0000 - val_loss: 615941275648.0000 - lr: 1.0000e-04\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 576872120320.0000 - val_loss: 615227588608.0000 - lr: 1.0000e-04\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 576150241280.0000 - val_loss: 614519078912.0000 - lr: 1.0000e-04\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 575406014464.0000 - val_loss: 613740642304.0000 - lr: 1.0000e-04\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 574638129152.0000 - val_loss: 613012209664.0000 - lr: 1.0000e-04\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 573907140608.0000 - val_loss: 612278272000.0000 - lr: 1.0000e-04\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 573178511360.0000 - val_loss: 611533979648.0000 - lr: 1.0000e-04\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 572439330816.0000 - val_loss: 610805874688.0000 - lr: 1.0000e-04\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 571692744704.0000 - val_loss: 610034188288.0000 - lr: 1.0000e-04\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 570956382208.0000 - val_loss: 609295728640.0000 - lr: 1.0000e-04\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 570237386752.0000 - val_loss: 608543965184.0000 - lr: 1.0000e-04\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 569501548544.0000 - val_loss: 607837880320.0000 - lr: 1.0000e-04\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 568749391872.0000 - val_loss: 607133892608.0000 - lr: 1.0000e-04\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 568019386368.0000 - val_loss: 606432788480.0000 - lr: 1.0000e-04\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 567288791040.0000 - val_loss: 605746692096.0000 - lr: 1.0000e-04\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 566559965184.0000 - val_loss: 605062168576.0000 - lr: 1.0000e-04\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 565865218048.0000 - val_loss: 604408446976.0000 - lr: 1.0000e-04\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 565110112256.0000 - val_loss: 603689779200.0000 - lr: 1.0000e-04\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 564377354240.0000 - val_loss: 602921893888.0000 - lr: 1.0000e-04\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 563642499072.0000 - val_loss: 602175635456.0000 - lr: 1.0000e-04\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 562916032512.0000 - val_loss: 601435734016.0000 - lr: 1.0000e-04\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 562186747904.0000 - val_loss: 600733450240.0000 - lr: 1.0000e-04\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 561458708480.0000 - val_loss: 600020221952.0000 - lr: 1.0000e-04\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 560728702976.0000 - val_loss: 599290019840.0000 - lr: 1.0000e-04\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 560003940352.0000 - val_loss: 598560997376.0000 - lr: 1.0000e-04\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 559275966464.0000 - val_loss: 597816246272.0000 - lr: 1.0000e-04\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 558554808320.0000 - val_loss: 597059043328.0000 - lr: 1.0000e-04\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 557843546112.0000 - val_loss: 596330676224.0000 - lr: 1.0000e-04\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 557116686336.0000 - val_loss: 595632783360.0000 - lr: 1.0000e-04\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 556408897536.0000 - val_loss: 594960318464.0000 - lr: 1.0000e-04\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 555669258240.0000 - val_loss: 594268913664.0000 - lr: 1.0000e-04\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 554960289792.0000 - val_loss: 593592188928.0000 - lr: 1.0000e-04\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 554245881856.0000 - val_loss: 592907730944.0000 - lr: 1.0000e-04\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 553523150848.0000 - val_loss: 592198828032.0000 - lr: 1.0000e-04\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 552807432192.0000 - val_loss: 591472099328.0000 - lr: 1.0000e-04\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 552088764416.0000 - val_loss: 590757232640.0000 - lr: 1.0000e-04\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 551376060416.0000 - val_loss: 590059536384.0000 - lr: 1.0000e-04\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 550656147456.0000 - val_loss: 589364002816.0000 - lr: 1.0000e-04\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 549952225280.0000 - val_loss: 588667813888.0000 - lr: 1.0000e-04\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 549239816192.0000 - val_loss: 587979554816.0000 - lr: 1.0000e-04\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 548516986880.0000 - val_loss: 587276550144.0000 - lr: 1.0000e-04\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 547821518848.0000 - val_loss: 586574528512.0000 - lr: 1.0000e-04\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 547096756224.0000 - val_loss: 585823879168.0000 - lr: 1.0000e-04\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 546392047616.0000 - val_loss: 585055207424.0000 - lr: 1.0000e-04\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 545687470080.0000 - val_loss: 584339947520.0000 - lr: 1.0000e-04\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 544972701696.0000 - val_loss: 583650115584.0000 - lr: 1.0000e-04\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 544263405568.0000 - val_loss: 582961266688.0000 - lr: 1.0000e-04\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 543553191936.0000 - val_loss: 582280937472.0000 - lr: 1.0000e-04\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 542847172608.0000 - val_loss: 581623873536.0000 - lr: 1.0000e-04\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 542128963584.0000 - val_loss: 580986667008.0000 - lr: 1.0000e-04\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 541428809728.0000 - val_loss: 580363091968.0000 - lr: 1.0000e-04\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 540720529408.0000 - val_loss: 579700850688.0000 - lr: 1.0000e-04\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 540013625344.0000 - val_loss: 579014885376.0000 - lr: 1.0000e-04\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 539313274880.0000 - val_loss: 578304409600.0000 - lr: 1.0000e-04\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 538608304128.0000 - val_loss: 577589084160.0000 - lr: 1.0000e-04\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 537938427904.0000 - val_loss: 576851345408.0000 - lr: 1.0000e-04\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 537197543424.0000 - val_loss: 576187006976.0000 - lr: 1.0000e-04\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 536488935424.0000 - val_loss: 575534727168.0000 - lr: 1.0000e-04\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 535794286592.0000 - val_loss: 574877073408.0000 - lr: 1.0000e-04\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 535090462720.0000 - val_loss: 574200807424.0000 - lr: 1.0000e-04\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 534396370944.0000 - val_loss: 573510057984.0000 - lr: 1.0000e-04\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 533699559424.0000 - val_loss: 572835037184.0000 - lr: 1.0000e-04\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 533002616832.0000 - val_loss: 572099198976.0000 - lr: 1.0000e-04\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 532291747840.0000 - val_loss: 571406483456.0000 - lr: 1.0000e-04\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 531588874240.0000 - val_loss: 570676215808.0000 - lr: 1.0000e-04\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 530878300160.0000 - val_loss: 569948307456.0000 - lr: 1.0000e-04\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 530189221888.0000 - val_loss: 569219940352.0000 - lr: 1.0000e-04\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 529487331328.0000 - val_loss: 568505794560.0000 - lr: 1.0000e-04\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 528793042944.0000 - val_loss: 567823433728.0000 - lr: 1.0000e-04\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 528091447296.0000 - val_loss: 567130718208.0000 - lr: 1.0000e-04\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 527401320448.0000 - val_loss: 566447046656.0000 - lr: 1.0000e-04\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 526703329280.0000 - val_loss: 565779693568.0000 - lr: 1.0000e-04\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 526015922176.0000 - val_loss: 565113716736.0000 - lr: 1.0000e-04\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 525318455296.0000 - val_loss: 564420018176.0000 - lr: 1.0000e-04\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 524628230144.0000 - val_loss: 563745259520.0000 - lr: 1.0000e-04\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 523922374656.0000 - val_loss: 563104907264.0000 - lr: 1.0000e-04\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 523243585536.0000 - val_loss: 562478252032.0000 - lr: 1.0000e-04\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 522568237056.0000 - val_loss: 561835147264.0000 - lr: 1.0000e-04\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 521870147584.0000 - val_loss: 561161437184.0000 - lr: 1.0000e-04\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 521194242048.0000 - val_loss: 560477962240.0000 - lr: 1.0000e-04\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 520496840704.0000 - val_loss: 559766568960.0000 - lr: 1.0000e-04\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 519817658368.0000 - val_loss: 559016706048.0000 - lr: 1.0000e-04\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 519120322560.0000 - val_loss: 558310096896.0000 - lr: 1.0000e-04\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 518426492928.0000 - val_loss: 557578911744.0000 - lr: 1.0000e-04\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 517743673344.0000 - val_loss: 556845957120.0000 - lr: 1.0000e-04\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 517076877312.0000 - val_loss: 556117983232.0000 - lr: 1.0000e-04\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 516408147968.0000 - val_loss: 555415896064.0000 - lr: 1.0000e-04\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 515746430976.0000 - val_loss: 554731831296.0000 - lr: 1.0000e-04\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 515051290624.0000 - val_loss: 554086105088.0000 - lr: 1.0000e-04\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 514358804480.0000 - val_loss: 553470656512.0000 - lr: 1.0000e-04\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 513722515456.0000 - val_loss: 552905801728.0000 - lr: 1.0000e-04\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 513026523136.0000 - val_loss: 552279080960.0000 - lr: 1.0000e-04\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 512323452928.0000 - val_loss: 551591673856.0000 - lr: 1.0000e-04\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 511658983424.0000 - val_loss: 550869860352.0000 - lr: 1.0000e-04\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 510972559360.0000 - val_loss: 550173409280.0000 - lr: 1.0000e-04\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 510307401728.0000 - val_loss: 549482201088.0000 - lr: 1.0000e-04\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 509628186624.0000 - val_loss: 548769857536.0000 - lr: 1.0000e-04\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 508943171584.0000 - val_loss: 548060102656.0000 - lr: 1.0000e-04\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 508284370944.0000 - val_loss: 547368861696.0000 - lr: 1.0000e-04\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 507616362496.0000 - val_loss: 546684731392.0000 - lr: 1.0000e-04\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 506965393408.0000 - val_loss: 546022621184.0000 - lr: 1.0000e-04\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 506287063040.0000 - val_loss: 545334657024.0000 - lr: 1.0000e-04\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 505599819776.0000 - val_loss: 544625655808.0000 - lr: 1.0000e-04\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 504948031488.0000 - val_loss: 543945588736.0000 - lr: 1.0000e-04\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 504302043136.0000 - val_loss: 543278202880.0000 - lr: 1.0000e-04\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 503615455232.0000 - val_loss: 542601543680.0000 - lr: 1.0000e-04\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 502950952960.0000 - val_loss: 541952802816.0000 - lr: 1.0000e-04\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 502273769472.0000 - val_loss: 541314187264.0000 - lr: 1.0000e-04\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 501608611840.0000 - val_loss: 540701196288.0000 - lr: 1.0000e-04\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 500933001216.0000 - val_loss: 540099346432.0000 - lr: 1.0000e-04\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 500283572224.0000 - val_loss: 539503788032.0000 - lr: 1.0000e-04\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 499617038336.0000 - val_loss: 538875232256.0000 - lr: 1.0000e-04\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 498957680640.0000 - val_loss: 538200276992.0000 - lr: 1.0000e-04\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 498297438208.0000 - val_loss: 537550815232.0000 - lr: 1.0000e-04\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 497623171072.0000 - val_loss: 536855085056.0000 - lr: 1.0000e-04\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 496968630272.0000 - val_loss: 536160206848.0000 - lr: 1.0000e-04\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 496300752896.0000 - val_loss: 535439835136.0000 - lr: 1.0000e-04\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 495639592960.0000 - val_loss: 534727262208.0000 - lr: 1.0000e-04\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 495010938880.0000 - val_loss: 534036152320.0000 - lr: 1.0000e-04\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 494337687552.0000 - val_loss: 533401796608.0000 - lr: 1.0000e-04\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 493677674496.0000 - val_loss: 532764655616.0000 - lr: 1.0000e-04\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 493014679552.0000 - val_loss: 532151894016.0000 - lr: 1.0000e-04\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 492372623360.0000 - val_loss: 531578224640.0000 - lr: 1.0000e-04\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 491705139200.0000 - val_loss: 530961104896.0000 - lr: 1.0000e-04\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 491078582272.0000 - val_loss: 530324848640.0000 - lr: 1.0000e-04\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 490405822464.0000 - val_loss: 529626955776.0000 - lr: 1.0000e-04\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 489725657088.0000 - val_loss: 528896819200.0000 - lr: 1.0000e-04\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 489095397376.0000 - val_loss: 528164388864.0000 - lr: 1.0000e-04\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 488455307264.0000 - val_loss: 527467380736.0000 - lr: 1.0000e-04\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 487800307712.0000 - val_loss: 526810218496.0000 - lr: 1.0000e-04\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 487136854016.0000 - val_loss: 526175600640.0000 - lr: 1.0000e-04\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 486505349120.0000 - val_loss: 525548421120.0000 - lr: 1.0000e-04\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 485846843392.0000 - val_loss: 524905644032.0000 - lr: 1.0000e-04\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 485207965696.0000 - val_loss: 524309954560.0000 - lr: 1.0000e-04\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 484544413696.0000 - val_loss: 523688509440.0000 - lr: 1.0000e-04\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 483887906816.0000 - val_loss: 523047501824.0000 - lr: 1.0000e-04\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 483242475520.0000 - val_loss: 522428350464.0000 - lr: 1.0000e-04\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 482609364992.0000 - val_loss: 521817161728.0000 - lr: 1.0000e-04\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 481954922496.0000 - val_loss: 521158393856.0000 - lr: 1.0000e-04\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 481311227904.0000 - val_loss: 520485961728.0000 - lr: 1.0000e-04\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 480663240704.0000 - val_loss: 519798358016.0000 - lr: 1.0000e-04\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 480033112064.0000 - val_loss: 519113834496.0000 - lr: 1.0000e-04\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 479370838016.0000 - val_loss: 518474104832.0000 - lr: 1.0000e-04\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 478731370496.0000 - val_loss: 517848989696.0000 - lr: 1.0000e-04\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 478095474688.0000 - val_loss: 517219090432.0000 - lr: 1.0000e-04\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 477452173312.0000 - val_loss: 516575035392.0000 - lr: 1.0000e-04\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 476802252800.0000 - val_loss: 515899916288.0000 - lr: 1.0000e-04\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 476162293760.0000 - val_loss: 515246489600.0000 - lr: 1.0000e-04\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 475528298496.0000 - val_loss: 514580217856.0000 - lr: 1.0000e-04\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 474874675200.0000 - val_loss: 513909063680.0000 - lr: 1.0000e-04\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 474252673024.0000 - val_loss: 513260945408.0000 - lr: 1.0000e-04\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 473602555904.0000 - val_loss: 512629669888.0000 - lr: 1.0000e-04\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 472970264576.0000 - val_loss: 512007340032.0000 - lr: 1.0000e-04\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 472337514496.0000 - val_loss: 511401918464.0000 - lr: 1.0000e-04\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 471694180352.0000 - val_loss: 510777819136.0000 - lr: 1.0000e-04\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 471050452992.0000 - val_loss: 510145757184.0000 - lr: 1.0000e-04\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 470412689408.0000 - val_loss: 509534044160.0000 - lr: 1.0000e-04\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 469788360704.0000 - val_loss: 508911779840.0000 - lr: 1.0000e-04\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 469181300736.0000 - val_loss: 508266774528.0000 - lr: 1.0000e-04\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 468525580288.0000 - val_loss: 507695398912.0000 - lr: 1.0000e-04\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 467888898048.0000 - val_loss: 507072315392.0000 - lr: 1.0000e-04\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 467263193088.0000 - val_loss: 506448314368.0000 - lr: 1.0000e-04\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 466633031680.0000 - val_loss: 505779388416.0000 - lr: 1.0000e-04\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 465985339392.0000 - val_loss: 505082740736.0000 - lr: 1.0000e-04\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 465360748544.0000 - val_loss: 504399429632.0000 - lr: 1.0000e-04\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 464757686272.0000 - val_loss: 503700750336.0000 - lr: 1.0000e-04\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 464110321664.0000 - val_loss: 503072948224.0000 - lr: 1.0000e-04\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 463480619008.0000 - val_loss: 502427353088.0000 - lr: 1.0000e-04\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 462858092544.0000 - val_loss: 501769338880.0000 - lr: 1.0000e-04\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 462231207936.0000 - val_loss: 501145698304.0000 - lr: 1.0000e-04\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 461609959424.0000 - val_loss: 500550303744.0000 - lr: 1.0000e-04\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 461023281152.0000 - val_loss: 499966214144.0000 - lr: 1.0000e-04\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 460358287360.0000 - val_loss: 499346735104.0000 - lr: 1.0000e-04\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 459736875008.0000 - val_loss: 498710609920.0000 - lr: 1.0000e-04\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 459119067136.0000 - val_loss: 498090934272.0000 - lr: 1.0000e-04\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 458494083072.0000 - val_loss: 497501405184.0000 - lr: 1.0000e-04\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 457872637952.0000 - val_loss: 496913219584.0000 - lr: 1.0000e-04\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 457254502400.0000 - val_loss: 496334372864.0000 - lr: 1.0000e-04\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 456647376896.0000 - val_loss: 495729934336.0000 - lr: 1.0000e-04\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 456023703552.0000 - val_loss: 495105441792.0000 - lr: 1.0000e-04\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 455426473984.0000 - val_loss: 494497169408.0000 - lr: 1.0000e-04\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 454799097856.0000 - val_loss: 493847937024.0000 - lr: 1.0000e-04\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 454182240256.0000 - val_loss: 493227704320.0000 - lr: 1.0000e-04\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 453568299008.0000 - val_loss: 492637192192.0000 - lr: 1.0000e-04\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 452946165760.0000 - val_loss: 492015681536.0000 - lr: 1.0000e-04\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 452347756544.0000 - val_loss: 491398692864.0000 - lr: 1.0000e-04\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 451725721600.0000 - val_loss: 490784227328.0000 - lr: 1.0000e-04\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 451109683200.0000 - val_loss: 490165272576.0000 - lr: 1.0000e-04\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 450500460544.0000 - val_loss: 489551724544.0000 - lr: 1.0000e-04\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 449900445696.0000 - val_loss: 488934047744.0000 - lr: 1.0000e-04\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 449280016384.0000 - val_loss: 488307425280.0000 - lr: 1.0000e-04\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 448673218560.0000 - val_loss: 487678967808.0000 - lr: 1.0000e-04\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 448064061440.0000 - val_loss: 487062896640.0000 - lr: 1.0000e-04\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 447470338048.0000 - val_loss: 486454296576.0000 - lr: 1.0000e-04\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 446859870208.0000 - val_loss: 485812666368.0000 - lr: 1.0000e-04\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 446259232768.0000 - val_loss: 485180571648.0000 - lr: 1.0000e-04\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 445657481216.0000 - val_loss: 484575182848.0000 - lr: 1.0000e-04\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 445058547712.0000 - val_loss: 483997188096.0000 - lr: 1.0000e-04\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 444438511616.0000 - val_loss: 483478208512.0000 - lr: 1.0000e-04\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 443842330624.0000 - val_loss: 482969583616.0000 - lr: 1.0000e-04\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 443239890944.0000 - val_loss: 482421473280.0000 - lr: 1.0000e-04\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 442638729216.0000 - val_loss: 481821818880.0000 - lr: 1.0000e-04\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 442049232896.0000 - val_loss: 481166458880.0000 - lr: 1.0000e-04\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 441434210304.0000 - val_loss: 480530071552.0000 - lr: 1.0000e-04\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 440855494656.0000 - val_loss: 479907446784.0000 - lr: 1.0000e-04\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 440234475520.0000 - val_loss: 479350587392.0000 - lr: 1.0000e-04\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 439666147328.0000 - val_loss: 478764498944.0000 - lr: 1.0000e-04\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 439037984768.0000 - val_loss: 478110515200.0000 - lr: 1.0000e-04\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 438435577856.0000 - val_loss: 477442768896.0000 - lr: 1.0000e-04\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 437846802432.0000 - val_loss: 476783640576.0000 - lr: 1.0000e-04\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 437261271040.0000 - val_loss: 476158492672.0000 - lr: 1.0000e-04\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 436677017600.0000 - val_loss: 475550580736.0000 - lr: 1.0000e-04\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 436072382464.0000 - val_loss: 474944012288.0000 - lr: 1.0000e-04\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 435497730048.0000 - val_loss: 474369064960.0000 - lr: 1.0000e-04\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 434898403328.0000 - val_loss: 473802342400.0000 - lr: 1.0000e-04\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 434300125184.0000 - val_loss: 473241452544.0000 - lr: 1.0000e-04\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 433692835840.0000 - val_loss: 472724570112.0000 - lr: 1.0000e-04\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 433112285184.0000 - val_loss: 472254939136.0000 - lr: 1.0000e-04\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 432531603456.0000 - val_loss: 471766171648.0000 - lr: 1.0000e-04\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 431959375872.0000 - val_loss: 471205150720.0000 - lr: 1.0000e-04\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 431369191424.0000 - val_loss: 470628302848.0000 - lr: 1.0000e-04\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 430781399040.0000 - val_loss: 470025142272.0000 - lr: 1.0000e-04\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 430194655232.0000 - val_loss: 469390065664.0000 - lr: 1.0000e-04\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 429599653888.0000 - val_loss: 468720549888.0000 - lr: 1.0000e-04\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 429014155264.0000 - val_loss: 468049920000.0000 - lr: 1.0000e-04\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 428404244480.0000 - val_loss: 467426967552.0000 - lr: 1.0000e-04\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 427814191104.0000 - val_loss: 466830950400.0000 - lr: 1.0000e-04\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 427227873280.0000 - val_loss: 466245648384.0000 - lr: 1.0000e-04\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 426655416320.0000 - val_loss: 465691213824.0000 - lr: 1.0000e-04\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 426053533696.0000 - val_loss: 465090412544.0000 - lr: 1.0000e-04\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 425470263296.0000 - val_loss: 464518905856.0000 - lr: 1.0000e-04\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 424884600832.0000 - val_loss: 463946416128.0000 - lr: 1.0000e-04\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 424334163968.0000 - val_loss: 463376908288.0000 - lr: 1.0000e-04\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 423714979840.0000 - val_loss: 462747041792.0000 - lr: 1.0000e-04\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 423146815488.0000 - val_loss: 462110818304.0000 - lr: 1.0000e-04\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 422563020800.0000 - val_loss: 461521715200.0000 - lr: 1.0000e-04\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 421975556096.0000 - val_loss: 460939984896.0000 - lr: 1.0000e-04\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 421392515072.0000 - val_loss: 460387647488.0000 - lr: 1.0000e-04\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 420811669504.0000 - val_loss: 459839930368.0000 - lr: 1.0000e-04\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 420235771904.0000 - val_loss: 459283202048.0000 - lr: 1.0000e-04\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 419651649536.0000 - val_loss: 458723229696.0000 - lr: 1.0000e-04\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 419073425408.0000 - val_loss: 458149691392.0000 - lr: 1.0000e-04\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 418505424896.0000 - val_loss: 457574121472.0000 - lr: 1.0000e-04\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 417921597440.0000 - val_loss: 457020506112.0000 - lr: 1.0000e-04\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 417359757312.0000 - val_loss: 456466006016.0000 - lr: 1.0000e-04\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 416775700480.0000 - val_loss: 455862714368.0000 - lr: 1.0000e-04\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 416200982528.0000 - val_loss: 455268204544.0000 - lr: 1.0000e-04\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 415639896064.0000 - val_loss: 454675070976.0000 - lr: 1.0000e-04\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 415050661888.0000 - val_loss: 454045171712.0000 - lr: 1.0000e-04\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 414484856832.0000 - val_loss: 453426479104.0000 - lr: 1.0000e-04\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 413913874432.0000 - val_loss: 452819812352.0000 - lr: 1.0000e-04\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 413358194688.0000 - val_loss: 452219568128.0000 - lr: 1.0000e-04\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 412796452864.0000 - val_loss: 451638919168.0000 - lr: 1.0000e-04\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 412224782336.0000 - val_loss: 451055681536.0000 - lr: 1.0000e-04\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 411657175040.0000 - val_loss: 450520973312.0000 - lr: 1.0000e-04\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 411073183744.0000 - val_loss: 450006810624.0000 - lr: 1.0000e-04\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 410496499712.0000 - val_loss: 449505886208.0000 - lr: 1.0000e-04\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 409925287936.0000 - val_loss: 448999227392.0000 - lr: 1.0000e-04\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 409367478272.0000 - val_loss: 448507117568.0000 - lr: 1.0000e-04\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 408810291200.0000 - val_loss: 447973261312.0000 - lr: 1.0000e-04\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 408271552512.0000 - val_loss: 447416205312.0000 - lr: 1.0000e-04\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 407695065088.0000 - val_loss: 446774280192.0000 - lr: 1.0000e-04\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 407105241088.0000 - val_loss: 446092804096.0000 - lr: 1.0000e-04\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 406546251776.0000 - val_loss: 445415129088.0000 - lr: 1.0000e-04\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 405974679552.0000 - val_loss: 444786540544.0000 - lr: 1.0000e-04\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 405418737664.0000 - val_loss: 444198748160.0000 - lr: 1.0000e-04\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 404852277248.0000 - val_loss: 443652833280.0000 - lr: 1.0000e-04\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 404281917440.0000 - val_loss: 443127758848.0000 - lr: 1.0000e-04\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 403710083072.0000 - val_loss: 442611957760.0000 - lr: 1.0000e-04\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 403145162752.0000 - val_loss: 442100973568.0000 - lr: 1.0000e-04\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 402598887424.0000 - val_loss: 441585926144.0000 - lr: 1.0000e-04\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 402033246208.0000 - val_loss: 441012289536.0000 - lr: 1.0000e-04\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 401458987008.0000 - val_loss: 440399724544.0000 - lr: 1.0000e-04\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 400900292608.0000 - val_loss: 439769366528.0000 - lr: 1.0000e-04\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 400343072768.0000 - val_loss: 439139008512.0000 - lr: 1.0000e-04\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 399788343296.0000 - val_loss: 438538108928.0000 - lr: 1.0000e-04\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 399232106496.0000 - val_loss: 437983543296.0000 - lr: 1.0000e-04\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 398670594048.0000 - val_loss: 437443756032.0000 - lr: 1.0000e-04\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 398104330240.0000 - val_loss: 436910030848.0000 - lr: 1.0000e-04\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 397562216448.0000 - val_loss: 436398522368.0000 - lr: 1.0000e-04\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 396998672384.0000 - val_loss: 435847987200.0000 - lr: 1.0000e-04\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 396435750912.0000 - val_loss: 435328778240.0000 - lr: 1.0000e-04\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 395880300544.0000 - val_loss: 434791153664.0000 - lr: 1.0000e-04\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 395332747264.0000 - val_loss: 434232459264.0000 - lr: 1.0000e-04\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 394790502400.0000 - val_loss: 433688051712.0000 - lr: 1.0000e-04\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 394218471424.0000 - val_loss: 433077190656.0000 - lr: 1.0000e-04\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 393664364544.0000 - val_loss: 432486776832.0000 - lr: 1.0000e-04\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 393106194432.0000 - val_loss: 431874670592.0000 - lr: 1.0000e-04\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 392581152768.0000 - val_loss: 431264989184.0000 - lr: 1.0000e-04\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 392005877760.0000 - val_loss: 430712684544.0000 - lr: 1.0000e-04\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 391457439744.0000 - val_loss: 430172569600.0000 - lr: 1.0000e-04\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 390907133952.0000 - val_loss: 429668794368.0000 - lr: 1.0000e-04\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 390348242944.0000 - val_loss: 429161938944.0000 - lr: 1.0000e-04\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 389795282944.0000 - val_loss: 428629131264.0000 - lr: 1.0000e-04\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 389245632512.0000 - val_loss: 428101238784.0000 - lr: 1.0000e-04\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 388704468992.0000 - val_loss: 427531370496.0000 - lr: 1.0000e-04\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 388146200576.0000 - val_loss: 426995089408.0000 - lr: 1.0000e-04\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 387602677760.0000 - val_loss: 426433085440.0000 - lr: 1.0000e-04\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 387039985664.0000 - val_loss: 425874784256.0000 - lr: 1.0000e-04\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 386498199552.0000 - val_loss: 425291612160.0000 - lr: 1.0000e-04\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 385948057600.0000 - val_loss: 424714207232.0000 - lr: 1.0000e-04\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 385410236416.0000 - val_loss: 424116682752.0000 - lr: 1.0000e-04\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 384854097920.0000 - val_loss: 423558479872.0000 - lr: 1.0000e-04\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 384303333376.0000 - val_loss: 422978682880.0000 - lr: 1.0000e-04\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 383757615104.0000 - val_loss: 422394724352.0000 - lr: 1.0000e-04\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 383217926144.0000 - val_loss: 421829672960.0000 - lr: 1.0000e-04\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 382674403328.0000 - val_loss: 421307645952.0000 - lr: 1.0000e-04\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 382122229760.0000 - val_loss: 420789354496.0000 - lr: 1.0000e-04\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 381573496832.0000 - val_loss: 420279058432.0000 - lr: 1.0000e-04\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 381040558080.0000 - val_loss: 419769909248.0000 - lr: 1.0000e-04\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 380503785472.0000 - val_loss: 419253780480.0000 - lr: 1.0000e-04\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 379966423040.0000 - val_loss: 418731589632.0000 - lr: 1.0000e-04\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 379435450368.0000 - val_loss: 418175680512.0000 - lr: 1.0000e-04\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 378893795328.0000 - val_loss: 417628848128.0000 - lr: 1.0000e-04\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 378350632960.0000 - val_loss: 417048788992.0000 - lr: 1.0000e-04\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 377813434368.0000 - val_loss: 416448675840.0000 - lr: 1.0000e-04\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 377266536448.0000 - val_loss: 415853805568.0000 - lr: 1.0000e-04\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 376777277440.0000 - val_loss: 415245139968.0000 - lr: 1.0000e-04\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 376191811584.0000 - val_loss: 414716854272.0000 - lr: 1.0000e-04\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 375662575616.0000 - val_loss: 414189289472.0000 - lr: 1.0000e-04\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 375124262912.0000 - val_loss: 413684269056.0000 - lr: 1.0000e-04\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 374580543488.0000 - val_loss: 413192847360.0000 - lr: 1.0000e-04\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 374061072384.0000 - val_loss: 412701655040.0000 - lr: 1.0000e-04\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 373524856832.0000 - val_loss: 412174909440.0000 - lr: 1.0000e-04\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 373005156352.0000 - val_loss: 411602616320.0000 - lr: 1.0000e-04\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 372462878720.0000 - val_loss: 410986479616.0000 - lr: 1.0000e-04\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 371934527488.0000 - val_loss: 410356416512.0000 - lr: 1.0000e-04\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 371422724096.0000 - val_loss: 409768787968.0000 - lr: 1.0000e-04\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 370870714368.0000 - val_loss: 409253871616.0000 - lr: 1.0000e-04\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 370336792576.0000 - val_loss: 408724406272.0000 - lr: 1.0000e-04\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 369808474112.0000 - val_loss: 408217092096.0000 - lr: 1.0000e-04\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 369275207680.0000 - val_loss: 407694999552.0000 - lr: 1.0000e-04\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 368746627072.0000 - val_loss: 407158063104.0000 - lr: 1.0000e-04\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 368224600064.0000 - val_loss: 406619258880.0000 - lr: 1.0000e-04\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 367706701824.0000 - val_loss: 406079078400.0000 - lr: 1.0000e-04\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 367170748416.0000 - val_loss: 405592342528.0000 - lr: 1.0000e-04\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 366643576832.0000 - val_loss: 405090435072.0000 - lr: 1.0000e-04\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 366120337408.0000 - val_loss: 404609531904.0000 - lr: 1.0000e-04\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 365604962304.0000 - val_loss: 404084948992.0000 - lr: 1.0000e-04\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 365090635776.0000 - val_loss: 403544145920.0000 - lr: 1.0000e-04\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 364561629184.0000 - val_loss: 402934104064.0000 - lr: 1.0000e-04\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 364025380864.0000 - val_loss: 402344083456.0000 - lr: 1.0000e-04\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 363526782976.0000 - val_loss: 401771462656.0000 - lr: 1.0000e-04\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 362991452160.0000 - val_loss: 401249697792.0000 - lr: 1.0000e-04\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 362467328000.0000 - val_loss: 400719708160.0000 - lr: 1.0000e-04\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 361936748544.0000 - val_loss: 400225468416.0000 - lr: 1.0000e-04\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 361428156416.0000 - val_loss: 399777202176.0000 - lr: 1.0000e-04\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 360915763200.0000 - val_loss: 399275032576.0000 - lr: 1.0000e-04\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 360388263936.0000 - val_loss: 398694678528.0000 - lr: 1.0000e-04\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 359853883392.0000 - val_loss: 398104559616.0000 - lr: 1.0000e-04\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 359329562624.0000 - val_loss: 397495074816.0000 - lr: 1.0000e-04\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 358807011328.0000 - val_loss: 396915441664.0000 - lr: 1.0000e-04\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 358302810112.0000 - val_loss: 396354846720.0000 - lr: 1.0000e-04\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 357782061056.0000 - val_loss: 395798806528.0000 - lr: 1.0000e-04\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 357279268864.0000 - val_loss: 395266621440.0000 - lr: 1.0000e-04\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 356758650880.0000 - val_loss: 394755276800.0000 - lr: 1.0000e-04\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 356239376384.0000 - val_loss: 394262970368.0000 - lr: 1.0000e-04\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 355726589952.0000 - val_loss: 393799630848.0000 - lr: 1.0000e-04\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 355187490816.0000 - val_loss: 393319743488.0000 - lr: 1.0000e-04\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 354696462336.0000 - val_loss: 392853946368.0000 - lr: 1.0000e-04\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 354171322368.0000 - val_loss: 392339161088.0000 - lr: 1.0000e-04\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 353650180096.0000 - val_loss: 391795867648.0000 - lr: 1.0000e-04\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 353154465792.0000 - val_loss: 391233437696.0000 - lr: 1.0000e-04\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 352641155072.0000 - val_loss: 390706200576.0000 - lr: 1.0000e-04\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 352121815040.0000 - val_loss: 390155730944.0000 - lr: 1.0000e-04\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 351614369792.0000 - val_loss: 389610438656.0000 - lr: 1.0000e-04\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 351104434176.0000 - val_loss: 389061771264.0000 - lr: 1.0000e-04\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 350612553728.0000 - val_loss: 388534009856.0000 - lr: 1.0000e-04\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 350090756096.0000 - val_loss: 388043472896.0000 - lr: 1.0000e-04\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 349578035200.0000 - val_loss: 387562536960.0000 - lr: 1.0000e-04\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 349069312000.0000 - val_loss: 387086417920.0000 - lr: 1.0000e-04\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 348571435008.0000 - val_loss: 386600009728.0000 - lr: 1.0000e-04\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 348061990912.0000 - val_loss: 386093481984.0000 - lr: 1.0000e-04\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 347552874496.0000 - val_loss: 385566998528.0000 - lr: 1.0000e-04\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 347051196416.0000 - val_loss: 385000931328.0000 - lr: 1.0000e-04\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 346552434688.0000 - val_loss: 384427556864.0000 - lr: 1.0000e-04\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 346043744256.0000 - val_loss: 383884558336.0000 - lr: 1.0000e-04\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 345545834496.0000 - val_loss: 383349096448.0000 - lr: 1.0000e-04\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 345032949760.0000 - val_loss: 382843453440.0000 - lr: 1.0000e-04\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 344534745088.0000 - val_loss: 382332698624.0000 - lr: 1.0000e-04\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 344033886208.0000 - val_loss: 381845569536.0000 - lr: 1.0000e-04\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 343543971840.0000 - val_loss: 381372071936.0000 - lr: 1.0000e-04\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 343034134528.0000 - val_loss: 380859449344.0000 - lr: 1.0000e-04\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 342539927552.0000 - val_loss: 380340764672.0000 - lr: 1.0000e-04\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 342044540928.0000 - val_loss: 379818573824.0000 - lr: 1.0000e-04\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 341568094208.0000 - val_loss: 379252834304.0000 - lr: 1.0000e-04\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 341042397184.0000 - val_loss: 378751680512.0000 - lr: 1.0000e-04\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 340540588032.0000 - val_loss: 378258751488.0000 - lr: 1.0000e-04\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 340052213760.0000 - val_loss: 377764020224.0000 - lr: 1.0000e-04\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 339563053056.0000 - val_loss: 377265258496.0000 - lr: 1.0000e-04\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 339052625920.0000 - val_loss: 376729632768.0000 - lr: 1.0000e-04\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 338594889728.0000 - val_loss: 376188895232.0000 - lr: 1.0000e-04\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 338075189248.0000 - val_loss: 375711989760.0000 - lr: 1.0000e-04\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 337570922496.0000 - val_loss: 375214800896.0000 - lr: 1.0000e-04\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 337077567488.0000 - val_loss: 374706274304.0000 - lr: 1.0000e-04\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 336591192064.0000 - val_loss: 374206398464.0000 - lr: 1.0000e-04\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 336096428032.0000 - val_loss: 373732835328.0000 - lr: 1.0000e-04\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 335605989376.0000 - val_loss: 373250359296.0000 - lr: 1.0000e-04\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 335108112384.0000 - val_loss: 372739014656.0000 - lr: 1.0000e-04\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 334621016064.0000 - val_loss: 372217937920.0000 - lr: 1.0000e-04\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 334136639488.0000 - val_loss: 371712393216.0000 - lr: 1.0000e-04\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 333644595200.0000 - val_loss: 371223789568.0000 - lr: 1.0000e-04\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 333151371264.0000 - val_loss: 370735808512.0000 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history2 = model2.fit(X_train.values, np.array(y_train), epochs=1000, batch_size=int(0.50*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "c0p2n9SYK2XD"
      },
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss2 = history2.history['loss']\n",
        "test_loss2 = history2.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RRRPkl2XK71D",
        "outputId": "0d1742a7-d18f-40ce-bda5-fd2f6bda154c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss2) + 1)\n",
        "plt.plot(epochs, train_loss2, label='Train Loss')\n",
        "plt.plot(epochs, test_loss2, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "v8ZH8POOLAYc",
        "outputId": "9610246b-4f46-49a9-e205-5286a4c4a045"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Interpolação para ajustar as curvas de perda com a mesma quantidade de pontos\n",
        "epochs1 = range(1, len(train_loss) + 1)\n",
        "epochs2 = np.linspace(1, len(train_loss), len(train_loss2))\n",
        "train_loss2_interp = np.interp(epochs2, epochs1, train_loss)\n",
        "test_loss2_interp = np.interp(epochs2, epochs1, test_loss)\n",
        "\n",
        "# Plotando o gráfico comparativo\n",
        "plt.plot(epochs1, train_loss, label='Train Loss 1', color='blue')\n",
        "plt.plot(epochs1, test_loss, label='Test Loss 1', color='cyan')\n",
        "plt.plot(epochs2, train_loss2_interp, label='Train Loss 2', color='green')\n",
        "plt.plot(epochs2, test_loss2_interp, label='Test Loss 2', color='lime')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Comparação de Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kidsuLr5Lbci"
      },
      "source": [
        "Neste exemplo, comparamos a mesma arquitetura de rede neural, alterando apenas a função de perda.\n",
        "\n",
        "No modelo 1, a função de perda era Huber Loss. No modelo 2, RMSE.\n",
        "\n",
        "Vale ressaltar, que os resultados dos modelos dependem da inicialização. Portanto, isso pode variar, dependendo da execução.\n",
        "\n",
        "**Percebemos que, o modelo 1 apresentou um erro melhor.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crie o model3o sequencial\n",
        "model3 = tf.keras.models.Sequential() #Definimos que é um model3o de rede neural sequencial\n",
        "\n",
        "# Adicione a primeira camada oculta\n",
        "model3.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],))) #Adicionamos a primeira camada que recebe os inputs e terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(64, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a quinta camada oculta\n",
        "model3.add(tf.keras.layers.Dense(32, activation='relu')) #Adicionamos a segunda camada que terá 2 neurônios\n",
        "\n",
        "# Adicione a camada de saída\n",
        "model3.add(tf.keras.layers.Dense(16, activation='relu')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "# Adicione a camada de saída\n",
        "model3.add(tf.keras.layers.Dense(16, activation='relu')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "# Adicione a camada de saída\n",
        "model3.add(tf.keras.layers.Dense(1, activation='relu')) #O valor 1 é porque vamos retornar apenas 1 output nessa camada de saída.\n",
        "\n",
        "# Compila o modelo3\n",
        "model3.compile(optimizer='adam', loss='mean_squared_error')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 163ms/step - loss: 133507422617600.0000 - val_loss: 132807225507840.0000 - lr: 0.0050\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 133507405840384.0000 - val_loss: 132807208730624.0000 - lr: 0.0050\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 133507380674560.0000 - val_loss: 132807166787584.0000 - lr: 0.0050\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 133507338731520.0000 - val_loss: 132807091290112.0000 - lr: 0.0050\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 133507254845440.0000 - val_loss: 132806940295168.0000 - lr: 0.0050\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 133507095461888.0000 - val_loss: 132806680248320.0000 - lr: 0.0050\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 133506793472000.0000 - val_loss: 132806210486272.0000 - lr: 0.0050\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 133506256601088.0000 - val_loss: 132805396791296.0000 - lr: 0.0050\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 133505333854208.0000 - val_loss: 132804029448192.0000 - lr: 0.0050\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 133503781961728.0000 - val_loss: 132801798078464.0000 - lr: 0.0050\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 133501307322368.0000 - val_loss: 132798291640320.0000 - lr: 0.0050\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 133497440174080.0000 - val_loss: 132792931319808.0000 - lr: 0.0050\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 133491501039616.0000 - val_loss: 132784802758656.0000 - lr: 0.0050\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 133482592337920.0000 - val_loss: 132772781883392.0000 - lr: 0.0050\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 133469397057536.0000 - val_loss: 132755258081280.0000 - lr: 0.0050\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 133450220699648.0000 - val_loss: 132730092257280.0000 - lr: 0.0050\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 133422899003392.0000 - val_loss: 132694465839104.0000 - lr: 0.0050\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 133384051359744.0000 - val_loss: 132644671062016.0000 - lr: 0.0050\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 133330104221696.0000 - val_loss: 132575867699200.0000 - lr: 0.0050\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 133255697268736.0000 - val_loss: 132481823014912.0000 - lr: 0.0050\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 133154438381568.0000 - val_loss: 132354618163200.0000 - lr: 0.0050\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 133017485967360.0000 - val_loss: 132184228757504.0000 - lr: 0.0050\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 132834245214208.0000 - val_loss: 131958214492160.0000 - lr: 0.0050\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 132591453732864.0000 - val_loss: 131661165494272.0000 - lr: 0.0050\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 132274540511232.0000 - val_loss: 131274148675584.0000 - lr: 0.0050\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 131860789198848.0000 - val_loss: 130774011478016.0000 - lr: 0.0050\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 131327047237632.0000 - val_loss: 130132970831872.0000 - lr: 0.0050\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 130642511659008.0000 - val_loss: 129317740740608.0000 - lr: 0.0050\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 129778258542592.0000 - val_loss: 128288953466880.0000 - lr: 0.0050\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 128681842311168.0000 - val_loss: 127000329060352.0000 - lr: 0.0050\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 127318416687104.0000 - val_loss: 125398507585536.0000 - lr: 0.0050\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 125619513851904.0000 - val_loss: 123422319312896.0000 - lr: 0.0050\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 123537293574144.0000 - val_loss: 121003204149248.0000 - lr: 0.0050\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 120977493065728.0000 - val_loss: 118065421352960.0000 - lr: 0.0050\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 117887188598784.0000 - val_loss: 114527517540352.0000 - lr: 0.0050\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 114177905524736.0000 - val_loss: 110305237532672.0000 - lr: 0.0050\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 109737177776128.0000 - val_loss: 105315165011968.0000 - lr: 0.0050\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 104518171754496.0000 - val_loss: 99480477106176.0000 - lr: 0.0050\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 98410736648192.0000 - val_loss: 92741732139008.0000 - lr: 0.0050\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 91428906598400.0000 - val_loss: 85068747898880.0000 - lr: 0.0050\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 83470692909056.0000 - val_loss: 76482269413376.0000 - lr: 0.0050\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 74564583292928.0000 - val_loss: 67073526988800.0000 - lr: 0.0050\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 64968711995392.0000 - val_loss: 57035693490176.0000 - lr: 0.0050\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 54778847559680.0000 - val_loss: 46714794803200.0000 - lr: 0.0050\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 44397718667264.0000 - val_loss: 36636234612736.0000 - lr: 0.0050\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 34460974186496.0000 - val_loss: 27534217445376.0000 - lr: 0.0050\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 25620018888704.0000 - val_loss: 20330554851328.0000 - lr: 0.0050\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 19003816804352.0000 - val_loss: 15952823451648.0000 - lr: 0.0050\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 15492250075136.0000 - val_loss: 14906048905216.0000 - lr: 0.0050\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 15350999547904.0000 - val_loss: 16519444561920.0000 - lr: 0.0050\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 17046489268224.0000 - val_loss: 16886122151936.0000 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 17417523691520.0000 - val_loss: 17051327397888.0000 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 17563270512640.0000 - val_loss: 17026069299200.0000 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 17504938229760.0000 - val_loss: 16849117904896.0000 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 17287073497088.0000 - val_loss: 16570557399040.0000 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16966252232704.0000 - val_loss: 16236928827392.0000 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 16590253850624.0000 - val_loss: 15888075980800.0000 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 16209206575104.0000 - val_loss: 15553163952128.0000 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 15821155860480.0000 - val_loss: 15253713715200.0000 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 15499750539264.0000 - val_loss: 14995507118080.0000 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 15208177205248.0000 - val_loss: 14785051623424.0000 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 14976284622848.0000 - val_loss: 14619933409280.0000 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 14776807718912.0000 - val_loss: 14496008503296.0000 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 14628315725824.0000 - val_loss: 14405587697664.0000 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14514733973504.0000 - val_loss: 14341798625280.0000 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14428141518848.0000 - val_loss: 14297993314304.0000 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 14369620492288.0000 - val_loss: 14268309176320.0000 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14326707519488.0000 - val_loss: 14247857750016.0000 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 14290805325824.0000 - val_loss: 14232316805120.0000 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 14262123626496.0000 - val_loss: 14218659102720.0000 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 14238757158912.0000 - val_loss: 14205112549376.0000 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14218671685632.0000 - val_loss: 14190433533952.0000 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14197583773696.0000 - val_loss: 14173664706560.0000 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14177129201664.0000 - val_loss: 14154603692032.0000 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 14154957062144.0000 - val_loss: 14132811137024.0000 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14130839814144.0000 - val_loss: 14108433842176.0000 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14105651970048.0000 - val_loss: 14081906966528.0000 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14079570739200.0000 - val_loss: 14053781012480.0000 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 14052076027904.0000 - val_loss: 14024788934656.0000 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14024776351744.0000 - val_loss: 13994978967552.0000 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13996800344064.0000 - val_loss: 13964873302016.0000 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13969228038144.0000 - val_loss: 13934562115584.0000 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13941875933184.0000 - val_loss: 13904524607488.0000 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13913528729600.0000 - val_loss: 13875119390720.0000 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 13887025971200.0000 - val_loss: 13845859926016.0000 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 13861309644800.0000 - val_loss: 13816995774464.0000 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13834808983552.0000 - val_loss: 13788949512192.0000 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13809311809536.0000 - val_loss: 13761487306752.0000 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 13783894327296.0000 - val_loss: 13734620692480.0000 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13759359746048.0000 - val_loss: 13708211257344.0000 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13734231670784.0000 - val_loss: 13682377490432.0000 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13709387759616.0000 - val_loss: 13656946376704.0000 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13685134196736.0000 - val_loss: 13631668355072.0000 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13661017997312.0000 - val_loss: 13606552862720.0000 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13636859854848.0000 - val_loss: 13581762428928.0000 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13612679692288.0000 - val_loss: 13557271887872.0000 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13588356923392.0000 - val_loss: 13533027762176.0000 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13564408496128.0000 - val_loss: 13508957700096.0000 - lr: 0.0010\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 13540222042112.0000 - val_loss: 13485134053376.0000 - lr: 0.0010\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13516206505984.0000 - val_loss: 13461372272640.0000 - lr: 0.0010\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 13494369910784.0000 - val_loss: 13449585229824.0000 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 13482375249920.0000 - val_loss: 13437883121664.0000 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13470443503616.0000 - val_loss: 13426209325056.0000 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13458437308416.0000 - val_loss: 13414664503296.0000 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13446532825088.0000 - val_loss: 13403058864128.0000 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13434518241280.0000 - val_loss: 13391510896640.0000 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13422584397824.0000 - val_loss: 13380011163648.0000 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13410700886016.0000 - val_loss: 13368391892992.0000 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13398777528320.0000 - val_loss: 13356895305728.0000 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13386935959552.0000 - val_loss: 13345389281280.0000 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 13374974853120.0000 - val_loss: 13333968191488.0000 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13363122798592.0000 - val_loss: 13322545004544.0000 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13351402864640.0000 - val_loss: 13311048417280.0000 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13339390377984.0000 - val_loss: 13299600064512.0000 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13327685124096.0000 - val_loss: 13287900053504.0000 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13315763863552.0000 - val_loss: 13276358377472.0000 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13304034492416.0000 - val_loss: 13264664657920.0000 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13292150980608.0000 - val_loss: 13252985618432.0000 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13280464601088.0000 - val_loss: 13241399902208.0000 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13268584235008.0000 - val_loss: 13229830963200.0000 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13256726937600.0000 - val_loss: 13218329133056.0000 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13245049995264.0000 - val_loss: 13206859808768.0000 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13233323769856.0000 - val_loss: 13195412504576.0000 - lr: 5.0000e-04\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13221507366912.0000 - val_loss: 13183995609088.0000 - lr: 5.0000e-04\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13209760169984.0000 - val_loss: 13172538867712.0000 - lr: 5.0000e-04\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13197994098688.0000 - val_loss: 13161101000704.0000 - lr: 5.0000e-04\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13186279407616.0000 - val_loss: 13149558276096.0000 - lr: 5.0000e-04\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13174696837120.0000 - val_loss: 13138020794368.0000 - lr: 5.0000e-04\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 13162840588288.0000 - val_loss: 13126589218816.0000 - lr: 5.0000e-04\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 13151221317632.0000 - val_loss: 13115166031872.0000 - lr: 5.0000e-04\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13139563249664.0000 - val_loss: 13103577169920.0000 - lr: 5.0000e-04\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13127683932160.0000 - val_loss: 13092106797056.0000 - lr: 5.0000e-04\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 13116111847424.0000 - val_loss: 13080518983680.0000 - lr: 5.0000e-04\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 13104381427712.0000 - val_loss: 13068943753216.0000 - lr: 5.0000e-04\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13092746428416.0000 - val_loss: 13057303511040.0000 - lr: 5.0000e-04\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13081011814400.0000 - val_loss: 13045718843392.0000 - lr: 5.0000e-04\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13069451264000.0000 - val_loss: 13033980035072.0000 - lr: 5.0000e-04\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13057761738752.0000 - val_loss: 13022367055872.0000 - lr: 5.0000e-04\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13046079553536.0000 - val_loss: 13010760368128.0000 - lr: 5.0000e-04\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13034617569280.0000 - val_loss: 12999125368832.0000 - lr: 5.0000e-04\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 13022803263488.0000 - val_loss: 12987586838528.0000 - lr: 5.0000e-04\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 13011132612608.0000 - val_loss: 12976030482432.0000 - lr: 5.0000e-04\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12999566819328.0000 - val_loss: 12964438474752.0000 - lr: 5.0000e-04\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12987966423040.0000 - val_loss: 12952805572608.0000 - lr: 5.0000e-04\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12976498147328.0000 - val_loss: 12941192593408.0000 - lr: 5.0000e-04\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12964846370816.0000 - val_loss: 12929543962624.0000 - lr: 5.0000e-04\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12953248071680.0000 - val_loss: 12918007529472.0000 - lr: 5.0000e-04\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12941779795968.0000 - val_loss: 12906486824960.0000 - lr: 5.0000e-04\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12930080833536.0000 - val_loss: 12895142281216.0000 - lr: 5.0000e-04\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12918642966528.0000 - val_loss: 12883737968640.0000 - lr: 5.0000e-04\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12908755943424.0000 - val_loss: 12881487724544.0000 - lr: 1.0000e-04\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 12906399793152.0000 - val_loss: 12879161982976.0000 - lr: 1.0000e-04\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12904118091776.0000 - val_loss: 12876820512768.0000 - lr: 1.0000e-04\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12901838487552.0000 - val_loss: 12874492674048.0000 - lr: 1.0000e-04\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12899500163072.0000 - val_loss: 12872204681216.0000 - lr: 1.0000e-04\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12897178615808.0000 - val_loss: 12869940805632.0000 - lr: 1.0000e-04\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12894852874240.0000 - val_loss: 12867660152832.0000 - lr: 1.0000e-04\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12892590047232.0000 - val_loss: 12865353285632.0000 - lr: 1.0000e-04\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12890283180032.0000 - val_loss: 12863079972864.0000 - lr: 1.0000e-04\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12887920738304.0000 - val_loss: 12860826583040.0000 - lr: 1.0000e-04\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12885614919680.0000 - val_loss: 12858522861568.0000 - lr: 1.0000e-04\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12883344752640.0000 - val_loss: 12856208654336.0000 - lr: 1.0000e-04\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12880986505216.0000 - val_loss: 12853921710080.0000 - lr: 1.0000e-04\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12878682783744.0000 - val_loss: 12851630571520.0000 - lr: 1.0000e-04\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 12876346556416.0000 - val_loss: 12849333141504.0000 - lr: 1.0000e-04\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12874025009152.0000 - val_loss: 12847042002944.0000 - lr: 1.0000e-04\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12871756939264.0000 - val_loss: 12844729892864.0000 - lr: 1.0000e-04\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 12869396594688.0000 - val_loss: 12842452385792.0000 - lr: 1.0000e-04\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12867079241728.0000 - val_loss: 12840201093120.0000 - lr: 1.0000e-04\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12864754548736.0000 - val_loss: 12837930926080.0000 - lr: 1.0000e-04\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12862473895936.0000 - val_loss: 12835684876288.0000 - lr: 1.0000e-04\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12860134522880.0000 - val_loss: 12833432535040.0000 - lr: 1.0000e-04\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12857805635584.0000 - val_loss: 12831210602496.0000 - lr: 1.0000e-04\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12855492476928.0000 - val_loss: 12828977135616.0000 - lr: 1.0000e-04\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12853166735360.0000 - val_loss: 12826731085824.0000 - lr: 1.0000e-04\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 12850872451072.0000 - val_loss: 12824493424640.0000 - lr: 1.0000e-04\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12848527835136.0000 - val_loss: 12822229549056.0000 - lr: 1.0000e-04\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12846247182336.0000 - val_loss: 12819927924736.0000 - lr: 1.0000e-04\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12843877400576.0000 - val_loss: 12817650417664.0000 - lr: 1.0000e-04\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12841572630528.0000 - val_loss: 12815362424832.0000 - lr: 1.0000e-04\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12839224868864.0000 - val_loss: 12813049266176.0000 - lr: 1.0000e-04\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12836958896128.0000 - val_loss: 12810694164480.0000 - lr: 1.0000e-04\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12834570240000.0000 - val_loss: 12808382054400.0000 - lr: 1.0000e-04\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12832271761408.0000 - val_loss: 12806084624384.0000 - lr: 1.0000e-04\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12829949165568.0000 - val_loss: 12803778805760.0000 - lr: 1.0000e-04\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12827578335232.0000 - val_loss: 12801500250112.0000 - lr: 1.0000e-04\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12825221136384.0000 - val_loss: 12799216451584.0000 - lr: 1.0000e-04\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12822926852096.0000 - val_loss: 12796916924416.0000 - lr: 1.0000e-04\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12820594819072.0000 - val_loss: 12794603765760.0000 - lr: 1.0000e-04\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12818237620224.0000 - val_loss: 12792270684160.0000 - lr: 1.0000e-04\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12815913975808.0000 - val_loss: 12789939699712.0000 - lr: 1.0000e-04\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12813559922688.0000 - val_loss: 12787631783936.0000 - lr: 1.0000e-04\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12811189092352.0000 - val_loss: 12785322819584.0000 - lr: 1.0000e-04\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12808891662336.0000 - val_loss: 12782992883712.0000 - lr: 1.0000e-04\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12806499860480.0000 - val_loss: 12780697550848.0000 - lr: 1.0000e-04\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12804195090432.0000 - val_loss: 12778363420672.0000 - lr: 1.0000e-04\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12801811677184.0000 - val_loss: 12776055504896.0000 - lr: 1.0000e-04\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12799494324224.0000 - val_loss: 12773731860480.0000 - lr: 1.0000e-04\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12797115105280.0000 - val_loss: 12771433381888.0000 - lr: 1.0000e-04\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12794782023680.0000 - val_loss: 12769128611840.0000 - lr: 1.0000e-04\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12792433213440.0000 - val_loss: 12766807064576.0000 - lr: 1.0000e-04\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12790080208896.0000 - val_loss: 12764481323008.0000 - lr: 1.0000e-04\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 12787730350080.0000 - val_loss: 12762152435712.0000 - lr: 1.0000e-04\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12785385734144.0000 - val_loss: 12759851859968.0000 - lr: 1.0000e-04\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12783031681024.0000 - val_loss: 12757540798464.0000 - lr: 1.0000e-04\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12780671336448.0000 - val_loss: 12755244417024.0000 - lr: 1.0000e-04\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12778326720512.0000 - val_loss: 12752932306944.0000 - lr: 1.0000e-04\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12775976861696.0000 - val_loss: 12750624391168.0000 - lr: 1.0000e-04\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12773610225664.0000 - val_loss: 12748308086784.0000 - lr: 1.0000e-04\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12771253026816.0000 - val_loss: 12745999122432.0000 - lr: 1.0000e-04\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12768905265152.0000 - val_loss: 12743684915200.0000 - lr: 1.0000e-04\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12766556454912.0000 - val_loss: 12741378048000.0000 - lr: 1.0000e-04\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12764171993088.0000 - val_loss: 12739090055168.0000 - lr: 1.0000e-04\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12761821085696.0000 - val_loss: 12736773750784.0000 - lr: 1.0000e-04\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12759507927040.0000 - val_loss: 12734431232000.0000 - lr: 1.0000e-04\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12757092007936.0000 - val_loss: 12732137996288.0000 - lr: 1.0000e-04\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12754745294848.0000 - val_loss: 12729846857728.0000 - lr: 1.0000e-04\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 12752356638720.0000 - val_loss: 12727544184832.0000 - lr: 1.0000e-04\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12750014119936.0000 - val_loss: 12725196423168.0000 - lr: 1.0000e-04\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12747653775360.0000 - val_loss: 12722859147264.0000 - lr: 1.0000e-04\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12745251487744.0000 - val_loss: 12720523968512.0000 - lr: 1.0000e-04\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12742898483200.0000 - val_loss: 12718153138176.0000 - lr: 1.0000e-04\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12740539187200.0000 - val_loss: 12715786502144.0000 - lr: 1.0000e-04\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12738188279808.0000 - val_loss: 12713434546176.0000 - lr: 1.0000e-04\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 12735784943616.0000 - val_loss: 12711099367424.0000 - lr: 1.0000e-04\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12733412016128.0000 - val_loss: 12708775723008.0000 - lr: 1.0000e-04\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12731050622976.0000 - val_loss: 12706456272896.0000 - lr: 1.0000e-04\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12728689229824.0000 - val_loss: 12704130531328.0000 - lr: 1.0000e-04\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12726339371008.0000 - val_loss: 12701797449728.0000 - lr: 1.0000e-04\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12723946520576.0000 - val_loss: 12699486388224.0000 - lr: 1.0000e-04\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12721630216192.0000 - val_loss: 12697169035264.0000 - lr: 1.0000e-04\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12719209054208.0000 - val_loss: 12694920888320.0000 - lr: 1.0000e-04\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12716846612480.0000 - val_loss: 12692651769856.0000 - lr: 1.0000e-04\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12714504093696.0000 - val_loss: 12690369019904.0000 - lr: 1.0000e-04\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12712125923328.0000 - val_loss: 12688083124224.0000 - lr: 1.0000e-04\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12709742510080.0000 - val_loss: 12685758431232.0000 - lr: 1.0000e-04\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12707428302848.0000 - val_loss: 12683403329536.0000 - lr: 1.0000e-04\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12705005043712.0000 - val_loss: 12681074442240.0000 - lr: 1.0000e-04\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12702640504832.0000 - val_loss: 12678749749248.0000 - lr: 1.0000e-04\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12700266528768.0000 - val_loss: 12676381016064.0000 - lr: 1.0000e-04\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12697900941312.0000 - val_loss: 12674014380032.0000 - lr: 1.0000e-04\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12695497605120.0000 - val_loss: 12671654035456.0000 - lr: 1.0000e-04\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12693124677632.0000 - val_loss: 12669279010816.0000 - lr: 1.0000e-04\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12690761187328.0000 - val_loss: 12666877771776.0000 - lr: 1.0000e-04\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12688426008576.0000 - val_loss: 12664476532736.0000 - lr: 1.0000e-04\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12686036303872.0000 - val_loss: 12662124576768.0000 - lr: 1.0000e-04\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12683653939200.0000 - val_loss: 12659800932352.0000 - lr: 1.0000e-04\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12681239068672.0000 - val_loss: 12657532862464.0000 - lr: 1.0000e-04\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12678860898304.0000 - val_loss: 12655258501120.0000 - lr: 1.0000e-04\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12676512088064.0000 - val_loss: 12652963168256.0000 - lr: 1.0000e-04\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12674131820544.0000 - val_loss: 12650652106752.0000 - lr: 1.0000e-04\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12671733727232.0000 - val_loss: 12648324268032.0000 - lr: 1.0000e-04\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12669401694208.0000 - val_loss: 12645966020608.0000 - lr: 1.0000e-04\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12667008843776.0000 - val_loss: 12643623501824.0000 - lr: 1.0000e-04\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12664591876096.0000 - val_loss: 12641261060096.0000 - lr: 1.0000e-04\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12662233628672.0000 - val_loss: 12638878695424.0000 - lr: 1.0000e-04\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12659834486784.0000 - val_loss: 12636525690880.0000 - lr: 1.0000e-04\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12657450024960.0000 - val_loss: 12634137034752.0000 - lr: 1.0000e-04\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12655078146048.0000 - val_loss: 12631748378624.0000 - lr: 1.0000e-04\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12652688441344.0000 - val_loss: 12629362868224.0000 - lr: 1.0000e-04\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12650295590912.0000 - val_loss: 12627020349440.0000 - lr: 1.0000e-04\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12647912177664.0000 - val_loss: 12624640081920.0000 - lr: 1.0000e-04\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12645529812992.0000 - val_loss: 12622255620096.0000 - lr: 1.0000e-04\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12643160031232.0000 - val_loss: 12619874304000.0000 - lr: 1.0000e-04\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12640762986496.0000 - val_loss: 12617523396608.0000 - lr: 1.0000e-04\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12638422564864.0000 - val_loss: 12615147323392.0000 - lr: 1.0000e-04\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 12636030763008.0000 - val_loss: 12612819484672.0000 - lr: 1.0000e-04\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 12633630572544.0000 - val_loss: 12610539880448.0000 - lr: 1.0000e-04\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12631251353600.0000 - val_loss: 12608265519104.0000 - lr: 1.0000e-04\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12628891009024.0000 - val_loss: 12605961797632.0000 - lr: 1.0000e-04\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12626519130112.0000 - val_loss: 12603677999104.0000 - lr: 1.0000e-04\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12624105308160.0000 - val_loss: 12601338626048.0000 - lr: 1.0000e-04\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12621753352192.0000 - val_loss: 12598952067072.0000 - lr: 1.0000e-04\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12619341627392.0000 - val_loss: 12596590673920.0000 - lr: 1.0000e-04\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12616966602752.0000 - val_loss: 12594177900544.0000 - lr: 1.0000e-04\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12614587383808.0000 - val_loss: 12591708504064.0000 - lr: 1.0000e-04\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12612220747776.0000 - val_loss: 12589269516288.0000 - lr: 1.0000e-04\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12609739816960.0000 - val_loss: 12586887151616.0000 - lr: 1.0000e-04\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12607354306560.0000 - val_loss: 12584483815424.0000 - lr: 1.0000e-04\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12604977184768.0000 - val_loss: 12582050070528.0000 - lr: 1.0000e-04\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12602552877056.0000 - val_loss: 12579626811392.0000 - lr: 1.0000e-04\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12600189386752.0000 - val_loss: 12577178386432.0000 - lr: 1.0000e-04\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12597812264960.0000 - val_loss: 12574721572864.0000 - lr: 1.0000e-04\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12595358597120.0000 - val_loss: 12572302508032.0000 - lr: 1.0000e-04\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12593037049856.0000 - val_loss: 12569888686080.0000 - lr: 1.0000e-04\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12590569750528.0000 - val_loss: 12567541972992.0000 - lr: 1.0000e-04\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 12588235620352.0000 - val_loss: 12565171142656.0000 - lr: 1.0000e-04\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12585815506944.0000 - val_loss: 12562829672448.0000 - lr: 1.0000e-04\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12583409025024.0000 - val_loss: 12560506028032.0000 - lr: 1.0000e-04\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12581014077440.0000 - val_loss: 12558170849280.0000 - lr: 1.0000e-04\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12578641149952.0000 - val_loss: 12555832524800.0000 - lr: 1.0000e-04\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12576228376576.0000 - val_loss: 12553492103168.0000 - lr: 1.0000e-04\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12573833428992.0000 - val_loss: 12551159021568.0000 - lr: 1.0000e-04\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12571474132992.0000 - val_loss: 12548815454208.0000 - lr: 1.0000e-04\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12569051922432.0000 - val_loss: 12546478178304.0000 - lr: 1.0000e-04\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12566662217728.0000 - val_loss: 12544161873920.0000 - lr: 1.0000e-04\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12564246298624.0000 - val_loss: 12541828792320.0000 - lr: 1.0000e-04\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12561856593920.0000 - val_loss: 12539486273536.0000 - lr: 1.0000e-04\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12559486812160.0000 - val_loss: 12537096568832.0000 - lr: 1.0000e-04\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12557064601600.0000 - val_loss: 12534756147200.0000 - lr: 1.0000e-04\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12554666508288.0000 - val_loss: 12532416774144.0000 - lr: 1.0000e-04\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12552268414976.0000 - val_loss: 12530058526720.0000 - lr: 1.0000e-04\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12549839912960.0000 - val_loss: 12527700279296.0000 - lr: 1.0000e-04\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12547486908416.0000 - val_loss: 12525329448960.0000 - lr: 1.0000e-04\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12545062600704.0000 - val_loss: 12522970152960.0000 - lr: 1.0000e-04\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12542693867520.0000 - val_loss: 12520542699520.0000 - lr: 1.0000e-04\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 12540274802688.0000 - val_loss: 12518165577728.0000 - lr: 1.0000e-04\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12537880903680.0000 - val_loss: 12515792650240.0000 - lr: 1.0000e-04\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12535477567488.0000 - val_loss: 12513428111360.0000 - lr: 1.0000e-04\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12533064794112.0000 - val_loss: 12511091884032.0000 - lr: 1.0000e-04\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12530655166464.0000 - val_loss: 12508754608128.0000 - lr: 1.0000e-04\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12528295870464.0000 - val_loss: 12506352320512.0000 - lr: 1.0000e-04\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12525889388544.0000 - val_loss: 12503961567232.0000 - lr: 1.0000e-04\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12523464032256.0000 - val_loss: 12501592834048.0000 - lr: 1.0000e-04\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12521072230400.0000 - val_loss: 12499160137728.0000 - lr: 1.0000e-04\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12518668894208.0000 - val_loss: 12496723247104.0000 - lr: 1.0000e-04\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12516256120832.0000 - val_loss: 12494292647936.0000 - lr: 1.0000e-04\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12513848590336.0000 - val_loss: 12491874631680.0000 - lr: 1.0000e-04\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12511430574080.0000 - val_loss: 12489438789632.0000 - lr: 1.0000e-04\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12509069180928.0000 - val_loss: 12486986170368.0000 - lr: 1.0000e-04\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12506637533184.0000 - val_loss: 12484584931328.0000 - lr: 1.0000e-04\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12504237342720.0000 - val_loss: 12482162720768.0000 - lr: 1.0000e-04\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12501859172352.0000 - val_loss: 12479750995968.0000 - lr: 1.0000e-04\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12499409698816.0000 - val_loss: 12477385408512.0000 - lr: 1.0000e-04\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12497004265472.0000 - val_loss: 12475033452544.0000 - lr: 1.0000e-04\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12494620852224.0000 - val_loss: 12472689885184.0000 - lr: 1.0000e-04\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12492209127424.0000 - val_loss: 12470364143616.0000 - lr: 1.0000e-04\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12489812082688.0000 - val_loss: 12468005896192.0000 - lr: 1.0000e-04\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12487406649344.0000 - val_loss: 12465644503040.0000 - lr: 1.0000e-04\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12484986535936.0000 - val_loss: 12463318761472.0000 - lr: 1.0000e-04\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12482566422528.0000 - val_loss: 12460980436992.0000 - lr: 1.0000e-04\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12480193495040.0000 - val_loss: 12458609606656.0000 - lr: 1.0000e-04\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12477746118656.0000 - val_loss: 12456215707648.0000 - lr: 1.0000e-04\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12475375288320.0000 - val_loss: 12453759942656.0000 - lr: 1.0000e-04\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12472942592000.0000 - val_loss: 12451316760576.0000 - lr: 1.0000e-04\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12470536110080.0000 - val_loss: 12448871481344.0000 - lr: 1.0000e-04\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12468109705216.0000 - val_loss: 12446448222208.0000 - lr: 1.0000e-04\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12465720000512.0000 - val_loss: 12444019720192.0000 - lr: 1.0000e-04\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12463277867008.0000 - val_loss: 12441605898240.0000 - lr: 1.0000e-04\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12460912279552.0000 - val_loss: 12439181590528.0000 - lr: 1.0000e-04\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12458467000320.0000 - val_loss: 12436805517312.0000 - lr: 1.0000e-04\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12456053178368.0000 - val_loss: 12434440978432.0000 - lr: 1.0000e-04\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12453662425088.0000 - val_loss: 12432057565184.0000 - lr: 1.0000e-04\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12451229728768.0000 - val_loss: 12429699317760.0000 - lr: 1.0000e-04\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12448833732608.0000 - val_loss: 12427321147392.0000 - lr: 1.0000e-04\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12446394744832.0000 - val_loss: 12424931442688.0000 - lr: 1.0000e-04\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12443983020032.0000 - val_loss: 12422530203648.0000 - lr: 1.0000e-04\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12441642598400.0000 - val_loss: 12420102750208.0000 - lr: 1.0000e-04\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12439157473280.0000 - val_loss: 12417737162752.0000 - lr: 1.0000e-04\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12436778254336.0000 - val_loss: 12415327535104.0000 - lr: 1.0000e-04\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12434330877952.0000 - val_loss: 12412934684672.0000 - lr: 1.0000e-04\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12431955853312.0000 - val_loss: 12410541834240.0000 - lr: 1.0000e-04\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12429506379776.0000 - val_loss: 12408191975424.0000 - lr: 1.0000e-04\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12427103043584.0000 - val_loss: 12405848408064.0000 - lr: 1.0000e-04\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12424715436032.0000 - val_loss: 12403452411904.0000 - lr: 1.0000e-04\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12422262816768.0000 - val_loss: 12401088921600.0000 - lr: 1.0000e-04\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12419853189120.0000 - val_loss: 12398701314048.0000 - lr: 1.0000e-04\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12417410007040.0000 - val_loss: 12396295880704.0000 - lr: 1.0000e-04\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12415033933824.0000 - val_loss: 12393883107328.0000 - lr: 1.0000e-04\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12412581314560.0000 - val_loss: 12391459848192.0000 - lr: 1.0000e-04\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12410150715392.0000 - val_loss: 12389016666112.0000 - lr: 1.0000e-04\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12407743184896.0000 - val_loss: 12386593406976.0000 - lr: 1.0000e-04\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12405332508672.0000 - val_loss: 12384153370624.0000 - lr: 1.0000e-04\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12402873597952.0000 - val_loss: 12381743742976.0000 - lr: 1.0000e-04\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12400447193088.0000 - val_loss: 12379337261056.0000 - lr: 1.0000e-04\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12398017642496.0000 - val_loss: 12376893030400.0000 - lr: 1.0000e-04\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 12395589140480.0000 - val_loss: 12374436216832.0000 - lr: 1.0000e-04\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12393189998592.0000 - val_loss: 12371968917504.0000 - lr: 1.0000e-04\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12390756253696.0000 - val_loss: 12369534124032.0000 - lr: 1.0000e-04\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12388349771776.0000 - val_loss: 12367108767744.0000 - lr: 1.0000e-04\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12385864646656.0000 - val_loss: 12364726403072.0000 - lr: 1.0000e-04\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12383470747648.0000 - val_loss: 12362356621312.0000 - lr: 1.0000e-04\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 12381035954176.0000 - val_loss: 12359983693824.0000 - lr: 1.0000e-04\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12378593820672.0000 - val_loss: 12357569871872.0000 - lr: 1.0000e-04\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12376175804416.0000 - val_loss: 12355151855616.0000 - lr: 1.0000e-04\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12373749399552.0000 - val_loss: 12352736985088.0000 - lr: 1.0000e-04\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12371305168896.0000 - val_loss: 12350321065984.0000 - lr: 1.0000e-04\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12368844161024.0000 - val_loss: 12347900952576.0000 - lr: 1.0000e-04\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12366443970560.0000 - val_loss: 12345466159104.0000 - lr: 1.0000e-04\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12364008128512.0000 - val_loss: 12343028219904.0000 - lr: 1.0000e-04\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12361542926336.0000 - val_loss: 12340598669312.0000 - lr: 1.0000e-04\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12359122812928.0000 - val_loss: 12338148147200.0000 - lr: 1.0000e-04\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12356711088128.0000 - val_loss: 12335664070656.0000 - lr: 1.0000e-04\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12354263711744.0000 - val_loss: 12333215645696.0000 - lr: 1.0000e-04\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12351803752448.0000 - val_loss: 12330803920896.0000 - lr: 1.0000e-04\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12349381541888.0000 - val_loss: 12328383807488.0000 - lr: 1.0000e-04\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12346976108544.0000 - val_loss: 12325966839808.0000 - lr: 1.0000e-04\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12344514052096.0000 - val_loss: 12323586572288.0000 - lr: 1.0000e-04\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12342088695808.0000 - val_loss: 12321215741952.0000 - lr: 1.0000e-04\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12339663339520.0000 - val_loss: 12318818697216.0000 - lr: 1.0000e-04\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12337221206016.0000 - val_loss: 12316447866880.0000 - lr: 1.0000e-04\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12334794801152.0000 - val_loss: 12314103250944.0000 - lr: 1.0000e-04\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12332378882048.0000 - val_loss: 12311761780736.0000 - lr: 1.0000e-04\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12329919971328.0000 - val_loss: 12309376270336.0000 - lr: 1.0000e-04\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12327511392256.0000 - val_loss: 12306972934144.0000 - lr: 1.0000e-04\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12325076598784.0000 - val_loss: 12304568549376.0000 - lr: 1.0000e-04\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12322650193920.0000 - val_loss: 12302162067456.0000 - lr: 1.0000e-04\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12320197574656.0000 - val_loss: 12299780751360.0000 - lr: 1.0000e-04\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12317735518208.0000 - val_loss: 12297384755200.0000 - lr: 1.0000e-04\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12315347910656.0000 - val_loss: 12294975127552.0000 - lr: 1.0000e-04\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12312907874304.0000 - val_loss: 12292571791360.0000 - lr: 1.0000e-04\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12310445817856.0000 - val_loss: 12290149580800.0000 - lr: 1.0000e-04\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12308068696064.0000 - val_loss: 12287689621504.0000 - lr: 1.0000e-04\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12305583570944.0000 - val_loss: 12285296771072.0000 - lr: 1.0000e-04\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12303136194560.0000 - val_loss: 12282920697856.0000 - lr: 1.0000e-04\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12300707692544.0000 - val_loss: 12280500584448.0000 - lr: 1.0000e-04\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12298256121856.0000 - val_loss: 12278094102528.0000 - lr: 1.0000e-04\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12295836008448.0000 - val_loss: 12275637288960.0000 - lr: 1.0000e-04\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12293415895040.0000 - val_loss: 12273184669696.0000 - lr: 1.0000e-04\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12290951741440.0000 - val_loss: 12270790770688.0000 - lr: 1.0000e-04\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12288529530880.0000 - val_loss: 12268415746048.0000 - lr: 1.0000e-04\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12286054891520.0000 - val_loss: 12266042818560.0000 - lr: 1.0000e-04\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12283625340928.0000 - val_loss: 12263661502464.0000 - lr: 1.0000e-04\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12281218859008.0000 - val_loss: 12261295915008.0000 - lr: 1.0000e-04\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12278808182784.0000 - val_loss: 12258992193536.0000 - lr: 1.0000e-04\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12276330397696.0000 - val_loss: 12256642334720.0000 - lr: 1.0000e-04\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12273897701376.0000 - val_loss: 12254311350272.0000 - lr: 1.0000e-04\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12271461859328.0000 - val_loss: 12251947859968.0000 - lr: 1.0000e-04\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12269041745920.0000 - val_loss: 12249552912384.0000 - lr: 1.0000e-04\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12266580738048.0000 - val_loss: 12247146430464.0000 - lr: 1.0000e-04\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12264191033344.0000 - val_loss: 12244724219904.0000 - lr: 1.0000e-04\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12261741559808.0000 - val_loss: 12242335563776.0000 - lr: 1.0000e-04\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12259328786432.0000 - val_loss: 12239913353216.0000 - lr: 1.0000e-04\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12256857292800.0000 - val_loss: 12237549862912.0000 - lr: 1.0000e-04\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12254478073856.0000 - val_loss: 12235166449664.0000 - lr: 1.0000e-04\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12251996094464.0000 - val_loss: 12232839659520.0000 - lr: 1.0000e-04\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12249585418240.0000 - val_loss: 12230465683456.0000 - lr: 1.0000e-04\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12247140139008.0000 - val_loss: 12228127358976.0000 - lr: 1.0000e-04\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 12244720025600.0000 - val_loss: 12225759674368.0000 - lr: 1.0000e-04\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12242276843520.0000 - val_loss: 12223410864128.0000 - lr: 1.0000e-04\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12239867215872.0000 - val_loss: 12221075685376.0000 - lr: 1.0000e-04\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12237441859584.0000 - val_loss: 12218651377664.0000 - lr: 1.0000e-04\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12234974560256.0000 - val_loss: 12216280547328.0000 - lr: 1.0000e-04\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12232563884032.0000 - val_loss: 12213864628224.0000 - lr: 1.0000e-04\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12230117556224.0000 - val_loss: 12211490652160.0000 - lr: 1.0000e-04\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12227631382528.0000 - val_loss: 12209099898880.0000 - lr: 1.0000e-04\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12225226997760.0000 - val_loss: 12206645182464.0000 - lr: 1.0000e-04\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12222823661568.0000 - val_loss: 12204168445952.0000 - lr: 1.0000e-04\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12220355313664.0000 - val_loss: 12201724215296.0000 - lr: 1.0000e-04\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12217905840128.0000 - val_loss: 12199289421824.0000 - lr: 1.0000e-04\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12215456366592.0000 - val_loss: 12196895522816.0000 - lr: 1.0000e-04\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12213058273280.0000 - val_loss: 12194468069376.0000 - lr: 1.0000e-04\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12210585731072.0000 - val_loss: 12192088850432.0000 - lr: 1.0000e-04\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 12208141500416.0000 - val_loss: 12189700194304.0000 - lr: 1.0000e-04\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 12205712998400.0000 - val_loss: 12187276935168.0000 - lr: 1.0000e-04\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12203283447808.0000 - val_loss: 12184835850240.0000 - lr: 1.0000e-04\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12200863334400.0000 - val_loss: 12182416785408.0000 - lr: 1.0000e-04\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12198385549312.0000 - val_loss: 12180042809344.0000 - lr: 1.0000e-04\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12195948658688.0000 - val_loss: 12177663590400.0000 - lr: 1.0000e-04\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12193521205248.0000 - val_loss: 12175303245824.0000 - lr: 1.0000e-04\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12191090606080.0000 - val_loss: 12172933464064.0000 - lr: 1.0000e-04\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12188613869568.0000 - val_loss: 12170538516480.0000 - lr: 1.0000e-04\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12186183270400.0000 - val_loss: 12168124694528.0000 - lr: 1.0000e-04\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12183748476928.0000 - val_loss: 12165664735232.0000 - lr: 1.0000e-04\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12181293760512.0000 - val_loss: 12163175415808.0000 - lr: 1.0000e-04\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12178863161344.0000 - val_loss: 12160679804928.0000 - lr: 1.0000e-04\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12176405299200.0000 - val_loss: 12158222991360.0000 - lr: 1.0000e-04\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12173964214272.0000 - val_loss: 12155705360384.0000 - lr: 1.0000e-04\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12171503206400.0000 - val_loss: 12153175146496.0000 - lr: 1.0000e-04\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 12169080995840.0000 - val_loss: 12150651224064.0000 - lr: 1.0000e-04\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12166579093504.0000 - val_loss: 12148183924736.0000 - lr: 1.0000e-04\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12164151640064.0000 - val_loss: 12145734451200.0000 - lr: 1.0000e-04\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12161749352448.0000 - val_loss: 12143214723072.0000 - lr: 1.0000e-04\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12159256887296.0000 - val_loss: 12140760006656.0000 - lr: 1.0000e-04\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12156842016768.0000 - val_loss: 12138283270144.0000 - lr: 1.0000e-04\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12154347454464.0000 - val_loss: 12135860011008.0000 - lr: 1.0000e-04\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12151933632512.0000 - val_loss: 12133433606144.0000 - lr: 1.0000e-04\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12149473673216.0000 - val_loss: 12131040755712.0000 - lr: 1.0000e-04\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12147050414080.0000 - val_loss: 12128643710976.0000 - lr: 1.0000e-04\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12144556900352.0000 - val_loss: 12126288609280.0000 - lr: 1.0000e-04\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12142143078400.0000 - val_loss: 12123905196032.0000 - lr: 1.0000e-04\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12139715624960.0000 - val_loss: 12121544851456.0000 - lr: 1.0000e-04\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12137268248576.0000 - val_loss: 12119159341056.0000 - lr: 1.0000e-04\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12134803046400.0000 - val_loss: 12116789559296.0000 - lr: 1.0000e-04\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12132345184256.0000 - val_loss: 12114426068992.0000 - lr: 1.0000e-04\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12129950236672.0000 - val_loss: 12112029024256.0000 - lr: 1.0000e-04\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12127488180224.0000 - val_loss: 12109655048192.0000 - lr: 1.0000e-04\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12125031366656.0000 - val_loss: 12107237031936.0000 - lr: 1.0000e-04\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12122620690432.0000 - val_loss: 12104770781184.0000 - lr: 1.0000e-04\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 12120162828288.0000 - val_loss: 12102311870464.0000 - lr: 1.0000e-04\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12117719646208.0000 - val_loss: 12099886514176.0000 - lr: 1.0000e-04\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 12115278561280.0000 - val_loss: 12097440186368.0000 - lr: 1.0000e-04\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12112850059264.0000 - val_loss: 12095037898752.0000 - lr: 1.0000e-04\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12110373322752.0000 - val_loss: 12092578988032.0000 - lr: 1.0000e-04\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12107963695104.0000 - val_loss: 12090104348672.0000 - lr: 1.0000e-04\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12105501638656.0000 - val_loss: 12087644389376.0000 - lr: 1.0000e-04\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12103077330944.0000 - val_loss: 12085195964416.0000 - lr: 1.0000e-04\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12100623663104.0000 - val_loss: 12082777948160.0000 - lr: 1.0000e-04\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12098180481024.0000 - val_loss: 12080332668928.0000 - lr: 1.0000e-04\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12095733104640.0000 - val_loss: 12077884243968.0000 - lr: 1.0000e-04\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12093289922560.0000 - val_loss: 12075462033408.0000 - lr: 1.0000e-04\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12090834157568.0000 - val_loss: 12073028288512.0000 - lr: 1.0000e-04\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12088398315520.0000 - val_loss: 12070593495040.0000 - lr: 1.0000e-04\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12085976104960.0000 - val_loss: 12068163944448.0000 - lr: 1.0000e-04\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12083493076992.0000 - val_loss: 12065784725504.0000 - lr: 1.0000e-04\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 12081080303616.0000 - val_loss: 12063457935360.0000 - lr: 1.0000e-04\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12078566866944.0000 - val_loss: 12061044113408.0000 - lr: 1.0000e-04\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12076167725056.0000 - val_loss: 12058616659968.0000 - lr: 1.0000e-04\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12073693085696.0000 - val_loss: 12056233246720.0000 - lr: 1.0000e-04\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12071231029248.0000 - val_loss: 12053797404672.0000 - lr: 1.0000e-04\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12068763729920.0000 - val_loss: 12051382534144.0000 - lr: 1.0000e-04\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12066313207808.0000 - val_loss: 12048997023744.0000 - lr: 1.0000e-04\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12063860588544.0000 - val_loss: 12046653456384.0000 - lr: 1.0000e-04\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12061421600768.0000 - val_loss: 12044292063232.0000 - lr: 1.0000e-04\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 12058940669952.0000 - val_loss: 12041952690176.0000 - lr: 1.0000e-04\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12056506925056.0000 - val_loss: 12039607025664.0000 - lr: 1.0000e-04\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12054014459904.0000 - val_loss: 12037331615744.0000 - lr: 1.0000e-04\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12051576520704.0000 - val_loss: 12035039428608.0000 - lr: 1.0000e-04\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12049128095744.0000 - val_loss: 12032736755712.0000 - lr: 1.0000e-04\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12046657650688.0000 - val_loss: 12030429888512.0000 - lr: 1.0000e-04\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12044217614336.0000 - val_loss: 12028107292672.0000 - lr: 1.0000e-04\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12041756606464.0000 - val_loss: 12025768968192.0000 - lr: 1.0000e-04\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12039319715840.0000 - val_loss: 12023419109376.0000 - lr: 1.0000e-04\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12036872339456.0000 - val_loss: 12021018918912.0000 - lr: 1.0000e-04\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12034380922880.0000 - val_loss: 12018535890944.0000 - lr: 1.0000e-04\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12031939837952.0000 - val_loss: 12016053911552.0000 - lr: 1.0000e-04\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12029512384512.0000 - val_loss: 12013561446400.0000 - lr: 1.0000e-04\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 12027025162240.0000 - val_loss: 12011135041536.0000 - lr: 1.0000e-04\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 12024576737280.0000 - val_loss: 12008643624960.0000 - lr: 1.0000e-04\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12022163963904.0000 - val_loss: 12006187859968.0000 - lr: 1.0000e-04\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 12019659964416.0000 - val_loss: 12003811786752.0000 - lr: 1.0000e-04\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 12017186373632.0000 - val_loss: 12001452490752.0000 - lr: 1.0000e-04\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12014747385856.0000 - val_loss: 11999097389056.0000 - lr: 1.0000e-04\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12012300009472.0000 - val_loss: 11996718170112.0000 - lr: 1.0000e-04\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 12009862070272.0000 - val_loss: 11994308542464.0000 - lr: 1.0000e-04\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12007384285184.0000 - val_loss: 11991939809280.0000 - lr: 1.0000e-04\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12004936908800.0000 - val_loss: 11989553250304.0000 - lr: 1.0000e-04\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12002480095232.0000 - val_loss: 11987167739904.0000 - lr: 1.0000e-04\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 12000048447488.0000 - val_loss: 11984791666688.0000 - lr: 1.0000e-04\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11997591633920.0000 - val_loss: 11982465925120.0000 - lr: 1.0000e-04\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11995155791872.0000 - val_loss: 11980044763136.0000 - lr: 1.0000e-04\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11992643403776.0000 - val_loss: 11977678127104.0000 - lr: 1.0000e-04\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11990212804608.0000 - val_loss: 11975260110848.0000 - lr: 1.0000e-04\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11987771719680.0000 - val_loss: 11972853628928.0000 - lr: 1.0000e-04\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11985301274624.0000 - val_loss: 11970368503808.0000 - lr: 1.0000e-04\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11982810906624.0000 - val_loss: 11967883378688.0000 - lr: 1.0000e-04\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11980389744640.0000 - val_loss: 11965357359104.0000 - lr: 1.0000e-04\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11977884696576.0000 - val_loss: 11962858602496.0000 - lr: 1.0000e-04\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11975412154368.0000 - val_loss: 11960349360128.0000 - lr: 1.0000e-04\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11973026643968.0000 - val_loss: 11957828583424.0000 - lr: 1.0000e-04\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11970514255872.0000 - val_loss: 11955402178560.0000 - lr: 1.0000e-04\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11968083656704.0000 - val_loss: 11952906567680.0000 - lr: 1.0000e-04\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11965579657216.0000 - val_loss: 11950478065664.0000 - lr: 1.0000e-04\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11963141718016.0000 - val_loss: 11948053757952.0000 - lr: 1.0000e-04\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11960669175808.0000 - val_loss: 11945676636160.0000 - lr: 1.0000e-04\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11958200827904.0000 - val_loss: 11943217725440.0000 - lr: 1.0000e-04\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11955747160064.0000 - val_loss: 11940777689088.0000 - lr: 1.0000e-04\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11953289297920.0000 - val_loss: 11938310389760.0000 - lr: 1.0000e-04\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11950853455872.0000 - val_loss: 11935875596288.0000 - lr: 1.0000e-04\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11948377767936.0000 - val_loss: 11933467017216.0000 - lr: 1.0000e-04\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11945924100096.0000 - val_loss: 11931055292416.0000 - lr: 1.0000e-04\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11943474626560.0000 - val_loss: 11928618401792.0000 - lr: 1.0000e-04\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11941009424384.0000 - val_loss: 11926218211328.0000 - lr: 1.0000e-04\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11938535833600.0000 - val_loss: 11923816972288.0000 - lr: 1.0000e-04\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11936117817344.0000 - val_loss: 11921384275968.0000 - lr: 1.0000e-04\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11933647372288.0000 - val_loss: 11918963113984.0000 - lr: 1.0000e-04\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11931165392896.0000 - val_loss: 11916575506432.0000 - lr: 1.0000e-04\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 11928730599424.0000 - val_loss: 11914196287488.0000 - lr: 1.0000e-04\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11926244425728.0000 - val_loss: 11911862157312.0000 - lr: 1.0000e-04\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11923826409472.0000 - val_loss: 11909464064000.0000 - lr: 1.0000e-04\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11921321361408.0000 - val_loss: 11907017736192.0000 - lr: 1.0000e-04\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11918870839296.0000 - val_loss: 11904585039872.0000 - lr: 1.0000e-04\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11916386762752.0000 - val_loss: 11902135566336.0000 - lr: 1.0000e-04\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11913942532096.0000 - val_loss: 11899643101184.0000 - lr: 1.0000e-04\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11911449018368.0000 - val_loss: 11897137004544.0000 - lr: 1.0000e-04\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11908999544832.0000 - val_loss: 11894648733696.0000 - lr: 1.0000e-04\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 11906516516864.0000 - val_loss: 11892192968704.0000 - lr: 1.0000e-04\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11904059703296.0000 - val_loss: 11889764466688.0000 - lr: 1.0000e-04\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11901646929920.0000 - val_loss: 11887332818944.0000 - lr: 1.0000e-04\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11899112521728.0000 - val_loss: 11884994494464.0000 - lr: 1.0000e-04\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11896666193920.0000 - val_loss: 11882643587072.0000 - lr: 1.0000e-04\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11894208331776.0000 - val_loss: 11880224522240.0000 - lr: 1.0000e-04\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 11891736838144.0000 - val_loss: 11877808603136.0000 - lr: 1.0000e-04\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11889281073152.0000 - val_loss: 11875386392576.0000 - lr: 1.0000e-04\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11886814822400.0000 - val_loss: 11872954744832.0000 - lr: 1.0000e-04\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11884322357248.0000 - val_loss: 11870572380160.0000 - lr: 1.0000e-04\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11881890709504.0000 - val_loss: 11868121858048.0000 - lr: 1.0000e-04\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11879437041664.0000 - val_loss: 11865673433088.0000 - lr: 1.0000e-04\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11876945625088.0000 - val_loss: 11863254368256.0000 - lr: 1.0000e-04\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11874491957248.0000 - val_loss: 11860754563072.0000 - lr: 1.0000e-04\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11872039337984.0000 - val_loss: 11858237980672.0000 - lr: 1.0000e-04\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11869567844352.0000 - val_loss: 11855775924224.0000 - lr: 1.0000e-04\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11867090059264.0000 - val_loss: 11853373636608.0000 - lr: 1.0000e-04\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11864647925760.0000 - val_loss: 11850988126208.0000 - lr: 1.0000e-04\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11862148120576.0000 - val_loss: 11848634073088.0000 - lr: 1.0000e-04\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11859702841344.0000 - val_loss: 11846218153984.0000 - lr: 1.0000e-04\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11857232396288.0000 - val_loss: 11843799089152.0000 - lr: 1.0000e-04\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11854778728448.0000 - val_loss: 11841388412928.0000 - lr: 1.0000e-04\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11852327157760.0000 - val_loss: 11839025971200.0000 - lr: 1.0000e-04\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11849873489920.0000 - val_loss: 11836629975040.0000 - lr: 1.0000e-04\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11847405142016.0000 - val_loss: 11834260193280.0000 - lr: 1.0000e-04\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11844934696960.0000 - val_loss: 11831892508672.0000 - lr: 1.0000e-04\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11842463203328.0000 - val_loss: 11829460860928.0000 - lr: 1.0000e-04\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11839991709696.0000 - val_loss: 11826950569984.0000 - lr: 1.0000e-04\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11837606199296.0000 - val_loss: 11824362684416.0000 - lr: 1.0000e-04\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11835067596800.0000 - val_loss: 11821873364992.0000 - lr: 1.0000e-04\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11832636997632.0000 - val_loss: 11819393482752.0000 - lr: 1.0000e-04\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11830122512384.0000 - val_loss: 11816932474880.0000 - lr: 1.0000e-04\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11827634241536.0000 - val_loss: 11814434766848.0000 - lr: 1.0000e-04\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11825218322432.0000 - val_loss: 11811921330176.0000 - lr: 1.0000e-04\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11822743683072.0000 - val_loss: 11809428865024.0000 - lr: 1.0000e-04\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11820273238016.0000 - val_loss: 11806952128512.0000 - lr: 1.0000e-04\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11817802792960.0000 - val_loss: 11804525723648.0000 - lr: 1.0000e-04\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11815322910720.0000 - val_loss: 11802125533184.0000 - lr: 1.0000e-04\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11812884971520.0000 - val_loss: 11799665573888.0000 - lr: 1.0000e-04\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11810375729152.0000 - val_loss: 11797240217600.0000 - lr: 1.0000e-04\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11807917867008.0000 - val_loss: 11794795986944.0000 - lr: 1.0000e-04\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11805443227648.0000 - val_loss: 11792388456448.0000 - lr: 1.0000e-04\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 11802963345408.0000 - val_loss: 11789947371520.0000 - lr: 1.0000e-04\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11800512823296.0000 - val_loss: 11787513626624.0000 - lr: 1.0000e-04\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11798066495488.0000 - val_loss: 11785044230144.0000 - lr: 1.0000e-04\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11795578224640.0000 - val_loss: 11782628311040.0000 - lr: 1.0000e-04\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11793074225152.0000 - val_loss: 11780263772160.0000 - lr: 1.0000e-04\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11790621605888.0000 - val_loss: 11777819541504.0000 - lr: 1.0000e-04\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11788160598016.0000 - val_loss: 11775379505152.0000 - lr: 1.0000e-04\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11785654501376.0000 - val_loss: 11772978266112.0000 - lr: 1.0000e-04\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11783195590656.0000 - val_loss: 11770494189568.0000 - lr: 1.0000e-04\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11780736679936.0000 - val_loss: 11768047861760.0000 - lr: 1.0000e-04\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11778335440896.0000 - val_loss: 11765526036480.0000 - lr: 1.0000e-04\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11775824101376.0000 - val_loss: 11763112214528.0000 - lr: 1.0000e-04\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11773334781952.0000 - val_loss: 11760802201600.0000 - lr: 1.0000e-04\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11770851753984.0000 - val_loss: 11758456537088.0000 - lr: 1.0000e-04\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11768388648960.0000 - val_loss: 11756130795520.0000 - lr: 1.0000e-04\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11765930786816.0000 - val_loss: 11753842802688.0000 - lr: 1.0000e-04\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11763463487488.0000 - val_loss: 11751527546880.0000 - lr: 1.0000e-04\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11761020305408.0000 - val_loss: 11749161959424.0000 - lr: 1.0000e-04\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11758544617472.0000 - val_loss: 11746746040320.0000 - lr: 1.0000e-04\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11756085706752.0000 - val_loss: 11744321732608.0000 - lr: 1.0000e-04\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11753629941760.0000 - val_loss: 11741946707968.0000 - lr: 1.0000e-04\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11751143768064.0000 - val_loss: 11739550711808.0000 - lr: 1.0000e-04\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11748689051648.0000 - val_loss: 11737131646976.0000 - lr: 1.0000e-04\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11746208120832.0000 - val_loss: 11734699999232.0000 - lr: 1.0000e-04\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11743727190016.0000 - val_loss: 11732318683136.0000 - lr: 1.0000e-04\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11741272473600.0000 - val_loss: 11729906958336.0000 - lr: 1.0000e-04\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11738808320000.0000 - val_loss: 11727452241920.0000 - lr: 1.0000e-04\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11736301174784.0000 - val_loss: 11724959776768.0000 - lr: 1.0000e-04\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11733924052992.0000 - val_loss: 11722379231232.0000 - lr: 1.0000e-04\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11731377061888.0000 - val_loss: 11719921369088.0000 - lr: 1.0000e-04\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11728854188032.0000 - val_loss: 11717467701248.0000 - lr: 1.0000e-04\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11726436171776.0000 - val_loss: 11715009839104.0000 - lr: 1.0000e-04\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 11723953143808.0000 - val_loss: 11712590774272.0000 - lr: 1.0000e-04\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11721490038784.0000 - val_loss: 11710095163392.0000 - lr: 1.0000e-04\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11719002816512.0000 - val_loss: 11707639398400.0000 - lr: 1.0000e-04\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11716529225728.0000 - val_loss: 11705197264896.0000 - lr: 1.0000e-04\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11714049343488.0000 - val_loss: 11702724722688.0000 - lr: 1.0000e-04\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11711596724224.0000 - val_loss: 11700172488704.0000 - lr: 1.0000e-04\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11709150396416.0000 - val_loss: 11697586700288.0000 - lr: 1.0000e-04\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11706623328256.0000 - val_loss: 11695085846528.0000 - lr: 1.0000e-04\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11704157077504.0000 - val_loss: 11692540952576.0000 - lr: 1.0000e-04\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11701706555392.0000 - val_loss: 11690003398656.0000 - lr: 1.0000e-04\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11699216187392.0000 - val_loss: 11687459553280.0000 - lr: 1.0000e-04\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11696765665280.0000 - val_loss: 11684890542080.0000 - lr: 1.0000e-04\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11694279491584.0000 - val_loss: 11682379202560.0000 - lr: 1.0000e-04\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11691806949376.0000 - val_loss: 11679862620160.0000 - lr: 1.0000e-04\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 11689361670144.0000 - val_loss: 11677370155008.0000 - lr: 1.0000e-04\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 11686853476352.0000 - val_loss: 11674894467072.0000 - lr: 1.0000e-04\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11684418682880.0000 - val_loss: 11672391516160.0000 - lr: 1.0000e-04\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11681959772160.0000 - val_loss: 11669883322368.0000 - lr: 1.0000e-04\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11679444238336.0000 - val_loss: 11667406585856.0000 - lr: 1.0000e-04\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11677025173504.0000 - val_loss: 11664908877824.0000 - lr: 1.0000e-04\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11674543194112.0000 - val_loss: 11662425849856.0000 - lr: 1.0000e-04\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11672093720576.0000 - val_loss: 11659947016192.0000 - lr: 1.0000e-04\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11669610692608.0000 - val_loss: 11657514319872.0000 - lr: 1.0000e-04\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11667171704832.0000 - val_loss: 11655043874816.0000 - lr: 1.0000e-04\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11664680288256.0000 - val_loss: 11652617469952.0000 - lr: 1.0000e-04\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11662205648896.0000 - val_loss: 11650138636288.0000 - lr: 1.0000e-04\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11659756175360.0000 - val_loss: 11647657705472.0000 - lr: 1.0000e-04\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11657271050240.0000 - val_loss: 11645182017536.0000 - lr: 1.0000e-04\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11654793265152.0000 - val_loss: 11642650755072.0000 - lr: 1.0000e-04\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11652368957440.0000 - val_loss: 11640109006848.0000 - lr: 1.0000e-04\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11649840840704.0000 - val_loss: 11637612347392.0000 - lr: 1.0000e-04\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11647379832832.0000 - val_loss: 11635138756608.0000 - lr: 1.0000e-04\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11644923019264.0000 - val_loss: 11632644194304.0000 - lr: 1.0000e-04\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11642416922624.0000 - val_loss: 11630185283584.0000 - lr: 1.0000e-04\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11639958011904.0000 - val_loss: 11627734761472.0000 - lr: 1.0000e-04\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11637443526656.0000 - val_loss: 11625254879232.0000 - lr: 1.0000e-04\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11635009781760.0000 - val_loss: 11622734102528.0000 - lr: 1.0000e-04\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11632499490816.0000 - val_loss: 11620240588800.0000 - lr: 1.0000e-04\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11630021705728.0000 - val_loss: 11617722957824.0000 - lr: 1.0000e-04\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11627659264000.0000 - val_loss: 11615202181120.0000 - lr: 1.0000e-04\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11625092349952.0000 - val_loss: 11612827156480.0000 - lr: 1.0000e-04\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11622604079104.0000 - val_loss: 11610460520448.0000 - lr: 1.0000e-04\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11620126294016.0000 - val_loss: 11608151556096.0000 - lr: 1.0000e-04\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11617674723328.0000 - val_loss: 11605847834624.0000 - lr: 1.0000e-04\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11615189598208.0000 - val_loss: 11603577667584.0000 - lr: 1.0000e-04\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11612749561856.0000 - val_loss: 11601258217472.0000 - lr: 1.0000e-04\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11610265485312.0000 - val_loss: 11598876901376.0000 - lr: 1.0000e-04\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11607817060352.0000 - val_loss: 11596545916928.0000 - lr: 1.0000e-04\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11605309915136.0000 - val_loss: 11594149920768.0000 - lr: 1.0000e-04\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11602867781632.0000 - val_loss: 11591753924608.0000 - lr: 1.0000e-04\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11600372170752.0000 - val_loss: 11589355831296.0000 - lr: 1.0000e-04\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11597940523008.0000 - val_loss: 11586996535296.0000 - lr: 1.0000e-04\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11595461689344.0000 - val_loss: 11584595296256.0000 - lr: 1.0000e-04\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11592996487168.0000 - val_loss: 11582174134272.0000 - lr: 1.0000e-04\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11590493536256.0000 - val_loss: 11579764506624.0000 - lr: 1.0000e-04\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11588028334080.0000 - val_loss: 11577277284352.0000 - lr: 1.0000e-04\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11585573617664.0000 - val_loss: 11574775382016.0000 - lr: 1.0000e-04\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11583123095552.0000 - val_loss: 11572277673984.0000 - lr: 1.0000e-04\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11580644261888.0000 - val_loss: 11569853366272.0000 - lr: 1.0000e-04\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11578125582336.0000 - val_loss: 11567513993216.0000 - lr: 1.0000e-04\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11575666671616.0000 - val_loss: 11565162037248.0000 - lr: 1.0000e-04\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11573193080832.0000 - val_loss: 11562810081280.0000 - lr: 1.0000e-04\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11570718441472.0000 - val_loss: 11560480145408.0000 - lr: 1.0000e-04\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11568273162240.0000 - val_loss: 11558115606528.0000 - lr: 1.0000e-04\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11565766017024.0000 - val_loss: 11555791962112.0000 - lr: 1.0000e-04\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11563298717696.0000 - val_loss: 11553437908992.0000 - lr: 1.0000e-04\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11560850292736.0000 - val_loss: 11551073370112.0000 - lr: 1.0000e-04\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11558376701952.0000 - val_loss: 11548628090880.0000 - lr: 1.0000e-04\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11555895771136.0000 - val_loss: 11546194345984.0000 - lr: 1.0000e-04\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11553388625920.0000 - val_loss: 11543749066752.0000 - lr: 1.0000e-04\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11550946492416.0000 - val_loss: 11541313224704.0000 - lr: 1.0000e-04\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 11548450881536.0000 - val_loss: 11538863751168.0000 - lr: 1.0000e-04\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11545978339328.0000 - val_loss: 11536411131904.0000 - lr: 1.0000e-04\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11543509991424.0000 - val_loss: 11533976338432.0000 - lr: 1.0000e-04\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11541035352064.0000 - val_loss: 11531538399232.0000 - lr: 1.0000e-04\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11538536595456.0000 - val_loss: 11529136111616.0000 - lr: 1.0000e-04\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11536110190592.0000 - val_loss: 11526710755328.0000 - lr: 1.0000e-04\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11533569490944.0000 - val_loss: 11524368236544.0000 - lr: 1.0000e-04\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11531126308864.0000 - val_loss: 11521973288960.0000 - lr: 1.0000e-04\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11528640135168.0000 - val_loss: 11519537446912.0000 - lr: 1.0000e-04\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11526161301504.0000 - val_loss: 11517103702016.0000 - lr: 1.0000e-04\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11523692953600.0000 - val_loss: 11514669957120.0000 - lr: 1.0000e-04\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11521196294144.0000 - val_loss: 11512250892288.0000 - lr: 1.0000e-04\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11518771986432.0000 - val_loss: 11509786738688.0000 - lr: 1.0000e-04\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11516259598336.0000 - val_loss: 11507398082560.0000 - lr: 1.0000e-04\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11513787056128.0000 - val_loss: 11505047175168.0000 - lr: 1.0000e-04\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 11511294590976.0000 - val_loss: 11502629158912.0000 - lr: 1.0000e-04\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11508854554624.0000 - val_loss: 11500154519552.0000 - lr: 1.0000e-04\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11506379915264.0000 - val_loss: 11497726017536.0000 - lr: 1.0000e-04\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11503867527168.0000 - val_loss: 11495257669632.0000 - lr: 1.0000e-04\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11501461045248.0000 - val_loss: 11492722212864.0000 - lr: 1.0000e-04\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11498966482944.0000 - val_loss: 11490280079360.0000 - lr: 1.0000e-04\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11496448851968.0000 - val_loss: 11487876743168.0000 - lr: 1.0000e-04\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11493998329856.0000 - val_loss: 11485453484032.0000 - lr: 1.0000e-04\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11491568779264.0000 - val_loss: 11482945290240.0000 - lr: 1.0000e-04\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11489051148288.0000 - val_loss: 11480518885376.0000 - lr: 1.0000e-04\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11486550294528.0000 - val_loss: 11478031663104.0000 - lr: 1.0000e-04\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11484081946624.0000 - val_loss: 11475511934976.0000 - lr: 1.0000e-04\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11481619890176.0000 - val_loss: 11472995352576.0000 - lr: 1.0000e-04\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11479121133568.0000 - val_loss: 11470421098496.0000 - lr: 1.0000e-04\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11476645445632.0000 - val_loss: 11467890884608.0000 - lr: 1.0000e-04\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11474144591872.0000 - val_loss: 11465342844928.0000 - lr: 1.0000e-04\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11471662612480.0000 - val_loss: 11462827311104.0000 - lr: 1.0000e-04\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11469180633088.0000 - val_loss: 11460353720320.0000 - lr: 1.0000e-04\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11466673487872.0000 - val_loss: 11457832943616.0000 - lr: 1.0000e-04\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11464216674304.0000 - val_loss: 11455296438272.0000 - lr: 1.0000e-04\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11461699043328.0000 - val_loss: 11452837527552.0000 - lr: 1.0000e-04\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11459212869632.0000 - val_loss: 11450378616832.0000 - lr: 1.0000e-04\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11456689995776.0000 - val_loss: 11447888248832.0000 - lr: 1.0000e-04\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11454276173824.0000 - val_loss: 11445334966272.0000 - lr: 1.0000e-04\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11451767980032.0000 - val_loss: 11442866618368.0000 - lr: 1.0000e-04\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11449244057600.0000 - val_loss: 11440426582016.0000 - lr: 1.0000e-04\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11446765223936.0000 - val_loss: 11437989691392.0000 - lr: 1.0000e-04\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 11444273807360.0000 - val_loss: 11435549655040.0000 - lr: 1.0000e-04\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11441809653760.0000 - val_loss: 11433075015680.0000 - lr: 1.0000e-04\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11439311945728.0000 - val_loss: 11430640222208.0000 - lr: 1.0000e-04\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11436817383424.0000 - val_loss: 11428166631424.0000 - lr: 1.0000e-04\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11434328064000.0000 - val_loss: 11425643757568.0000 - lr: 1.0000e-04\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11431884881920.0000 - val_loss: 11423137660928.0000 - lr: 1.0000e-04\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11429342085120.0000 - val_loss: 11420701818880.0000 - lr: 1.0000e-04\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11426939797504.0000 - val_loss: 11418243956736.0000 - lr: 1.0000e-04\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11424378126336.0000 - val_loss: 11415901437952.0000 - lr: 1.0000e-04\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11421902438400.0000 - val_loss: 11413525364736.0000 - lr: 1.0000e-04\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11419423604736.0000 - val_loss: 11411135660032.0000 - lr: 1.0000e-04\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11416951062528.0000 - val_loss: 11408691429376.0000 - lr: 1.0000e-04\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11414447063040.0000 - val_loss: 11406325841920.0000 - lr: 1.0000e-04\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 11412013318144.0000 - val_loss: 11403872174080.0000 - lr: 1.0000e-04\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11409481007104.0000 - val_loss: 11401474080768.0000 - lr: 1.0000e-04\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11407033630720.0000 - val_loss: 11399067598848.0000 - lr: 1.0000e-04\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11404521242624.0000 - val_loss: 11396711448576.0000 - lr: 1.0000e-04\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11402050797568.0000 - val_loss: 11394380464128.0000 - lr: 1.0000e-04\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11399597129728.0000 - val_loss: 11392068354048.0000 - lr: 1.0000e-04\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11397135073280.0000 - val_loss: 11389644046336.0000 - lr: 1.0000e-04\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11394626879488.0000 - val_loss: 11387272167424.0000 - lr: 1.0000e-04\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11392142802944.0000 - val_loss: 11384927551488.0000 - lr: 1.0000e-04\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11389684940800.0000 - val_loss: 11382573498368.0000 - lr: 1.0000e-04\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11387214495744.0000 - val_loss: 11380261388288.0000 - lr: 1.0000e-04\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11384757682176.0000 - val_loss: 11377845469184.0000 - lr: 1.0000e-04\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11382241099776.0000 - val_loss: 11375452618752.0000 - lr: 1.0000e-04\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11379773800448.0000 - val_loss: 11373056622592.0000 - lr: 1.0000e-04\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11377296015360.0000 - val_loss: 11370611343360.0000 - lr: 1.0000e-04\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 11374817181696.0000 - val_loss: 11368171307008.0000 - lr: 1.0000e-04\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11372307939328.0000 - val_loss: 11365752242176.0000 - lr: 1.0000e-04\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11369839591424.0000 - val_loss: 11363285991424.0000 - lr: 1.0000e-04\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11367351320576.0000 - val_loss: 11360761020416.0000 - lr: 1.0000e-04\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11364855709696.0000 - val_loss: 11358180474880.0000 - lr: 1.0000e-04\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11362371633152.0000 - val_loss: 11355618803712.0000 - lr: 1.0000e-04\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11359863439360.0000 - val_loss: 11353034063872.0000 - lr: 1.0000e-04\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11357350002688.0000 - val_loss: 11350432546816.0000 - lr: 1.0000e-04\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11354870120448.0000 - val_loss: 11347812155392.0000 - lr: 1.0000e-04\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11352358780928.0000 - val_loss: 11345199104000.0000 - lr: 1.0000e-04\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11349914550272.0000 - val_loss: 11342582906880.0000 - lr: 1.0000e-04\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11347453542400.0000 - val_loss: 11340031721472.0000 - lr: 1.0000e-04\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 11344885579776.0000 - val_loss: 11337596928000.0000 - lr: 1.0000e-04\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11342414086144.0000 - val_loss: 11335167377408.0000 - lr: 1.0000e-04\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11339903795200.0000 - val_loss: 11332691689472.0000 - lr: 1.0000e-04\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11337433350144.0000 - val_loss: 11330212855808.0000 - lr: 1.0000e-04\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11334918864896.0000 - val_loss: 11327713050624.0000 - lr: 1.0000e-04\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11332416962560.0000 - val_loss: 11325199613952.0000 - lr: 1.0000e-04\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11329972731904.0000 - val_loss: 11322597048320.0000 - lr: 1.0000e-04\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11327426789376.0000 - val_loss: 11320065785856.0000 - lr: 1.0000e-04\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11324930129920.0000 - val_loss: 11317503066112.0000 - lr: 1.0000e-04\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11322454441984.0000 - val_loss: 11314898403328.0000 - lr: 1.0000e-04\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11320012308480.0000 - val_loss: 11312242360320.0000 - lr: 1.0000e-04\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11317470560256.0000 - val_loss: 11309696417792.0000 - lr: 1.0000e-04\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11315001163776.0000 - val_loss: 11307126358016.0000 - lr: 1.0000e-04\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11312512892928.0000 - val_loss: 11304634941440.0000 - lr: 1.0000e-04\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11309985824768.0000 - val_loss: 11302206439424.0000 - lr: 1.0000e-04\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11307559419904.0000 - val_loss: 11299687759872.0000 - lr: 1.0000e-04\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11305013477376.0000 - val_loss: 11297256112128.0000 - lr: 1.0000e-04\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11302523109376.0000 - val_loss: 11294790909952.0000 - lr: 1.0000e-04\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11300047421440.0000 - val_loss: 11292340387840.0000 - lr: 1.0000e-04\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11297542373376.0000 - val_loss: 11289905594368.0000 - lr: 1.0000e-04\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 11295080316928.0000 - val_loss: 11287443537920.0000 - lr: 1.0000e-04\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11292546957312.0000 - val_loss: 11284975190016.0000 - lr: 1.0000e-04\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11290069172224.0000 - val_loss: 11282475384832.0000 - lr: 1.0000e-04\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11287597678592.0000 - val_loss: 11279962996736.0000 - lr: 1.0000e-04\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11285067464704.0000 - val_loss: 11277492551680.0000 - lr: 1.0000e-04\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 11282595971072.0000 - val_loss: 11274979115008.0000 - lr: 1.0000e-04\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11280106651648.0000 - val_loss: 11272450998272.0000 - lr: 1.0000e-04\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11277650886656.0000 - val_loss: 11269965873152.0000 - lr: 1.0000e-04\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11275091312640.0000 - val_loss: 11267554148352.0000 - lr: 1.0000e-04\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11272624013312.0000 - val_loss: 11265098383360.0000 - lr: 1.0000e-04\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11270155665408.0000 - val_loss: 11262610112512.0000 - lr: 1.0000e-04\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11267631742976.0000 - val_loss: 11260122890240.0000 - lr: 1.0000e-04\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11265203240960.0000 - val_loss: 11257652445184.0000 - lr: 1.0000e-04\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11262666735616.0000 - val_loss: 11255269031936.0000 - lr: 1.0000e-04\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11260191047680.0000 - val_loss: 11252824801280.0000 - lr: 1.0000e-04\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11257704873984.0000 - val_loss: 11250310316032.0000 - lr: 1.0000e-04\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11255185145856.0000 - val_loss: 11247820996608.0000 - lr: 1.0000e-04\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11252733575168.0000 - val_loss: 11245384105984.0000 - lr: 1.0000e-04\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11250208604160.0000 - val_loss: 11242975526912.0000 - lr: 1.0000e-04\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11247744450560.0000 - val_loss: 11240564850688.0000 - lr: 1.0000e-04\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11245267714048.0000 - val_loss: 11238191923200.0000 - lr: 1.0000e-04\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11242757423104.0000 - val_loss: 11235747692544.0000 - lr: 1.0000e-04\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11240257617920.0000 - val_loss: 11233349599232.0000 - lr: 1.0000e-04\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 11237781929984.0000 - val_loss: 11230923194368.0000 - lr: 1.0000e-04\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11235249618944.0000 - val_loss: 11228490498048.0000 - lr: 1.0000e-04\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11232790708224.0000 - val_loss: 11226033684480.0000 - lr: 1.0000e-04\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11230312923136.0000 - val_loss: 11223595745280.0000 - lr: 1.0000e-04\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11227791097856.0000 - val_loss: 11221189263360.0000 - lr: 1.0000e-04\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11225304924160.0000 - val_loss: 11218710429696.0000 - lr: 1.0000e-04\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11222828187648.0000 - val_loss: 11216292413440.0000 - lr: 1.0000e-04\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11220346208256.0000 - val_loss: 11213857619968.0000 - lr: 1.0000e-04\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11217823334400.0000 - val_loss: 11211481546752.0000 - lr: 1.0000e-04\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 11215330869248.0000 - val_loss: 11209132736512.0000 - lr: 1.0000e-04\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 11212850987008.0000 - val_loss: 11206750371840.0000 - lr: 1.0000e-04\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11210345938944.0000 - val_loss: 11204362764288.0000 - lr: 1.0000e-04\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11207852425216.0000 - val_loss: 11201963622400.0000 - lr: 1.0000e-04\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 11205415534592.0000 - val_loss: 11199565529088.0000 - lr: 1.0000e-04\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11202852814848.0000 - val_loss: 11197276487680.0000 - lr: 1.0000e-04\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11200380272640.0000 - val_loss: 11194984300544.0000 - lr: 1.0000e-04\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11197887807488.0000 - val_loss: 11192637587456.0000 - lr: 1.0000e-04\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11195405828096.0000 - val_loss: 11190280388608.0000 - lr: 1.0000e-04\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11192916508672.0000 - val_loss: 11187903266816.0000 - lr: 1.0000e-04\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11190422994944.0000 - val_loss: 11185530339328.0000 - lr: 1.0000e-04\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11187911655424.0000 - val_loss: 11183135391744.0000 - lr: 1.0000e-04\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11185447501824.0000 - val_loss: 11180715278336.0000 - lr: 1.0000e-04\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 11182943502336.0000 - val_loss: 11178338156544.0000 - lr: 1.0000e-04\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11180441600000.0000 - val_loss: 11175964180480.0000 - lr: 1.0000e-04\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11177939697664.0000 - val_loss: 11173488492544.0000 - lr: 1.0000e-04\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11175443038208.0000 - val_loss: 11170933112832.0000 - lr: 1.0000e-04\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11172969447424.0000 - val_loss: 11168349421568.0000 - lr: 1.0000e-04\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11170442379264.0000 - val_loss: 11165789847552.0000 - lr: 1.0000e-04\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11167978225664.0000 - val_loss: 11163177844736.0000 - lr: 1.0000e-04\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11165427040256.0000 - val_loss: 11160665456640.0000 - lr: 1.0000e-04\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11162957643776.0000 - val_loss: 11158105882624.0000 - lr: 1.0000e-04\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11160410652672.0000 - val_loss: 11155585105920.0000 - lr: 1.0000e-04\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11157910847488.0000 - val_loss: 11153052794880.0000 - lr: 1.0000e-04\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11155402653696.0000 - val_loss: 11150459666432.0000 - lr: 1.0000e-04\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 11152938500096.0000 - val_loss: 11147791040512.0000 - lr: 1.0000e-04\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11150386266112.0000 - val_loss: 11145147580416.0000 - lr: 1.0000e-04\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11147889606656.0000 - val_loss: 11142491537408.0000 - lr: 1.0000e-04\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11145395044352.0000 - val_loss: 11139833397248.0000 - lr: 1.0000e-04\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11142876364800.0000 - val_loss: 11137195180032.0000 - lr: 1.0000e-04\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11140405919744.0000 - val_loss: 11134545428480.0000 - lr: 1.0000e-04\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11137875705856.0000 - val_loss: 11131956494336.0000 - lr: 1.0000e-04\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11135401066496.0000 - val_loss: 11129376997376.0000 - lr: 1.0000e-04\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11132901261312.0000 - val_loss: 11126881386496.0000 - lr: 1.0000e-04\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11130374193152.0000 - val_loss: 11124279869440.0000 - lr: 1.0000e-04\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11127886970880.0000 - val_loss: 11121721344000.0000 - lr: 1.0000e-04\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 11125406040064.0000 - val_loss: 11119198470144.0000 - lr: 1.0000e-04\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 11122905186304.0000 - val_loss: 11116769968128.0000 - lr: 1.0000e-04\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11120346660864.0000 - val_loss: 11114246045696.0000 - lr: 1.0000e-04\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11117873070080.0000 - val_loss: 11111713734656.0000 - lr: 1.0000e-04\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11115357536256.0000 - val_loss: 11109187715072.0000 - lr: 1.0000e-04\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11112828370944.0000 - val_loss: 11106653306880.0000 - lr: 1.0000e-04\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11110338002944.0000 - val_loss: 11104031866880.0000 - lr: 1.0000e-04\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11107830857728.0000 - val_loss: 11101440835584.0000 - lr: 1.0000e-04\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11105327906816.0000 - val_loss: 11098857144320.0000 - lr: 1.0000e-04\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11102810275840.0000 - val_loss: 11096353144832.0000 - lr: 1.0000e-04\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11100345073664.0000 - val_loss: 11093779939328.0000 - lr: 1.0000e-04\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 11097805422592.0000 - val_loss: 11091308445696.0000 - lr: 1.0000e-04\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 11095267868672.0000 - val_loss: 11088813883392.0000 - lr: 1.0000e-04\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 11092782743552.0000 - val_loss: 11086342389760.0000 - lr: 1.0000e-04\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 11090263015424.0000 - val_loss: 11083820564480.0000 - lr: 1.0000e-04\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11087767404544.0000 - val_loss: 11081320759296.0000 - lr: 1.0000e-04\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11085224607744.0000 - val_loss: 11078825148416.0000 - lr: 1.0000e-04\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 11082712219648.0000 - val_loss: 11076348411904.0000 - lr: 1.0000e-04\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11080223948800.0000 - val_loss: 11073850703872.0000 - lr: 1.0000e-04\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11077743017984.0000 - val_loss: 11071325732864.0000 - lr: 1.0000e-04\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11075232727040.0000 - val_loss: 11068893036544.0000 - lr: 1.0000e-04\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11072683638784.0000 - val_loss: 11066487603200.0000 - lr: 1.0000e-04\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11070178590720.0000 - val_loss: 11064057004032.0000 - lr: 1.0000e-04\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 11067688222720.0000 - val_loss: 11061587607552.0000 - lr: 1.0000e-04\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 11065182126080.0000 - val_loss: 11059193708544.0000 - lr: 1.0000e-04\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11062645620736.0000 - val_loss: 11056716972032.0000 - lr: 1.0000e-04\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11060126941184.0000 - val_loss: 11054212972544.0000 - lr: 1.0000e-04\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11057669079040.0000 - val_loss: 11051668078592.0000 - lr: 1.0000e-04\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11055109505024.0000 - val_loss: 11049250062336.0000 - lr: 1.0000e-04\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11052609699840.0000 - val_loss: 11046734528512.0000 - lr: 1.0000e-04\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11050105700352.0000 - val_loss: 11044201168896.0000 - lr: 1.0000e-04\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 11047637352448.0000 - val_loss: 11041728626688.0000 - lr: 1.0000e-04\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11045048418304.0000 - val_loss: 11039358844928.0000 - lr: 1.0000e-04\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11042603139072.0000 - val_loss: 11037008986112.0000 - lr: 1.0000e-04\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11040091799552.0000 - val_loss: 11034541686784.0000 - lr: 1.0000e-04\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11037539565568.0000 - val_loss: 11032006230016.0000 - lr: 1.0000e-04\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11035040808960.0000 - val_loss: 11029537882112.0000 - lr: 1.0000e-04\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 11032547295232.0000 - val_loss: 11027007668224.0000 - lr: 1.0000e-04\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11030007644160.0000 - val_loss: 11024468017152.0000 - lr: 1.0000e-04\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11027528810496.0000 - val_loss: 11021912637440.0000 - lr: 1.0000e-04\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11025037393920.0000 - val_loss: 11019411783680.0000 - lr: 1.0000e-04\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11022565900288.0000 - val_loss: 11016848015360.0000 - lr: 1.0000e-04\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11020009472000.0000 - val_loss: 11014422659072.0000 - lr: 1.0000e-04\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11017519104000.0000 - val_loss: 11012051828736.0000 - lr: 1.0000e-04\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11014979452928.0000 - val_loss: 11009649541120.0000 - lr: 1.0000e-04\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 11012519493632.0000 - val_loss: 11007323799552.0000 - lr: 1.0000e-04\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11009946288128.0000 - val_loss: 11004882714624.0000 - lr: 1.0000e-04\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 11007473745920.0000 - val_loss: 11002439532544.0000 - lr: 1.0000e-04\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 11004914171904.0000 - val_loss: 10999983767552.0000 - lr: 1.0000e-04\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 11002464698368.0000 - val_loss: 10997509128192.0000 - lr: 1.0000e-04\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 10999934484480.0000 - val_loss: 10995128860672.0000 - lr: 1.0000e-04\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10997393784832.0000 - val_loss: 10992723427328.0000 - lr: 1.0000e-04\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10994898173952.0000 - val_loss: 10990302265344.0000 - lr: 1.0000e-04\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10992399417344.0000 - val_loss: 10987827625984.0000 - lr: 1.0000e-04\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10989872349184.0000 - val_loss: 10985383395328.0000 - lr: 1.0000e-04\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10987372544000.0000 - val_loss: 10982940213248.0000 - lr: 1.0000e-04\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10984850718720.0000 - val_loss: 10980551557120.0000 - lr: 1.0000e-04\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10982354059264.0000 - val_loss: 10978063286272.0000 - lr: 1.0000e-04\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10979839574016.0000 - val_loss: 10975623249920.0000 - lr: 1.0000e-04\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10977315651584.0000 - val_loss: 10973209427968.0000 - lr: 1.0000e-04\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10974829477888.0000 - val_loss: 10970750517248.0000 - lr: 1.0000e-04\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 10972325478400.0000 - val_loss: 10968128028672.0000 - lr: 1.0000e-04\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 10969846644736.0000 - val_loss: 10965514977280.0000 - lr: 1.0000e-04\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10967236739072.0000 - val_loss: 10963042435072.0000 - lr: 1.0000e-04\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 10964791459840.0000 - val_loss: 10960578281472.0000 - lr: 1.0000e-04\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10962264391680.0000 - val_loss: 10958159216640.0000 - lr: 1.0000e-04\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10959721594880.0000 - val_loss: 10955679334400.0000 - lr: 1.0000e-04\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10957248004096.0000 - val_loss: 10953203646464.0000 - lr: 1.0000e-04\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10954732470272.0000 - val_loss: 10950752075776.0000 - lr: 1.0000e-04\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10952272510976.0000 - val_loss: 10948308893696.0000 - lr: 1.0000e-04\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10949749637120.0000 - val_loss: 10945963229184.0000 - lr: 1.0000e-04\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10947223617536.0000 - val_loss: 10943537872896.0000 - lr: 1.0000e-04\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10944751075328.0000 - val_loss: 10941152362496.0000 - lr: 1.0000e-04\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10942233444352.0000 - val_loss: 10938873806848.0000 - lr: 1.0000e-04\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10939730493440.0000 - val_loss: 10936497733632.0000 - lr: 1.0000e-04\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10937236979712.0000 - val_loss: 10934083911680.0000 - lr: 1.0000e-04\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 10934720397312.0000 - val_loss: 10931692109824.0000 - lr: 1.0000e-04\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10932221640704.0000 - val_loss: 10929294016512.0000 - lr: 1.0000e-04\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 10929721835520.0000 - val_loss: 10926925283328.0000 - lr: 1.0000e-04\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10927203155968.0000 - val_loss: 10924464275456.0000 - lr: 1.0000e-04\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10924727468032.0000 - val_loss: 10921925672960.0000 - lr: 1.0000e-04\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 10922202497024.0000 - val_loss: 10919354564608.0000 - lr: 1.0000e-04\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10919665991680.0000 - val_loss: 10916835885056.0000 - lr: 1.0000e-04\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10917142069248.0000 - val_loss: 10914351808512.0000 - lr: 1.0000e-04\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10914634924032.0000 - val_loss: 10911815303168.0000 - lr: 1.0000e-04\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10912160284672.0000 - val_loss: 10909262020608.0000 - lr: 1.0000e-04\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10909616439296.0000 - val_loss: 10906781089792.0000 - lr: 1.0000e-04\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10907112439808.0000 - val_loss: 10904268701696.0000 - lr: 1.0000e-04\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10904594808832.0000 - val_loss: 10901816082432.0000 - lr: 1.0000e-04\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 10902071934976.0000 - val_loss: 10899328860160.0000 - lr: 1.0000e-04\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 10899563741184.0000 - val_loss: 10896854220800.0000 - lr: 1.0000e-04\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10897046110208.0000 - val_loss: 10894387970048.0000 - lr: 1.0000e-04\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10894531624960.0000 - val_loss: 10891950030848.0000 - lr: 1.0000e-04\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10892049645568.0000 - val_loss: 10889501605888.0000 - lr: 1.0000e-04\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10889536208896.0000 - val_loss: 10887078346752.0000 - lr: 1.0000e-04\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10887000752128.0000 - val_loss: 10884682350592.0000 - lr: 1.0000e-04\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10884515627008.0000 - val_loss: 10882156331008.0000 - lr: 1.0000e-04\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 10881983315968.0000 - val_loss: 10879631360000.0000 - lr: 1.0000e-04\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10879473025024.0000 - val_loss: 10877067591680.0000 - lr: 1.0000e-04\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10876942811136.0000 - val_loss: 10874524794880.0000 - lr: 1.0000e-04\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10874412597248.0000 - val_loss: 10872011358208.0000 - lr: 1.0000e-04\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10871908597760.0000 - val_loss: 10869447589888.0000 - lr: 1.0000e-04\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10869496872960.0000 - val_loss: 10866803081216.0000 - lr: 1.0000e-04\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 10866843975680.0000 - val_loss: 10864319004672.0000 - lr: 1.0000e-04\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10864379822080.0000 - val_loss: 10861839122432.0000 - lr: 1.0000e-04\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 10861837025280.0000 - val_loss: 10859390697472.0000 - lr: 1.0000e-04\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 10859304714240.0000 - val_loss: 10856964292608.0000 - lr: 1.0000e-04\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10856797569024.0000 - val_loss: 10854515867648.0000 - lr: 1.0000e-04\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10854317686784.0000 - val_loss: 10852023402496.0000 - lr: 1.0000e-04\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10851802152960.0000 - val_loss: 10849620066304.0000 - lr: 1.0000e-04\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10849255161856.0000 - val_loss: 10847238750208.0000 - lr: 1.0000e-04\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10846746968064.0000 - val_loss: 10844795568128.0000 - lr: 1.0000e-04\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 10844252405760.0000 - val_loss: 10842330365952.0000 - lr: 1.0000e-04\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10841716948992.0000 - val_loss: 10839814832128.0000 - lr: 1.0000e-04\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10839237066752.0000 - val_loss: 10837257355264.0000 - lr: 1.0000e-04\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 10836692172800.0000 - val_loss: 10834785861632.0000 - lr: 1.0000e-04\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10834212290560.0000 - val_loss: 10832302833664.0000 - lr: 1.0000e-04\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 10831656910848.0000 - val_loss: 10829897400320.0000 - lr: 1.0000e-04\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 10829145571328.0000 - val_loss: 10827474141184.0000 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history3 = model3.fit(X_train.values, np.array(y_train), epochs=1000, batch_size=int(0.50*len(X)), verbose=1,\n",
        "                    callbacks=[early_stopping_callback,lr_scheduler_callback],\n",
        "                    validation_data=(X_test.values, np.array(y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Acessando o histórico de treinamento para visualizar a perda no conjunto de treinamento e no conjunto de teste\n",
        "train_loss3 = history3.history['loss']\n",
        "test_loss3 = history3.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotando o gráfico comparativo\n",
        "epochs = range(1, len(train_loss3) + 1)\n",
        "plt.plot(epochs, train_loss3, label='Train Loss')\n",
        "plt.plot(epochs, test_loss3, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train Loss vs. Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqrhtY-w_ssZ"
      },
      "source": [
        "### Teste Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "a6AQmRnCOmDX"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9ycAfTvL_2AQ"
      },
      "outputs": [],
      "source": [
        "# Criar e treinar o modelo de Random Forest\n",
        "model_rf = RandomForestRegressor(min_samples_leaf=int(len(X_train)*0.05),random_state=2023,n_estimators=250)\n",
        "# n_estimators = Qt de arvores;\n",
        "# min_samples_leaf = qt de dados necessario em cada folha\n",
        "# random_state = semente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "46NFgdTWA5k7",
        "outputId": "12376795-a740-41be-a1a1-19ceee77ec5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_leaf=200, n_estimators=250, random_state=2023)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_leaf=200, n_estimators=250, random_state=2023)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(min_samples_leaf=200, n_estimators=250, random_state=2023)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gerando o CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_val.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "colunas_diferentes = X_test.columns.difference(X_val.columns)\n",
        "\n",
        "colunas_diferentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>INT_SQFT</th>\n",
              "      <th>DIST_MAINROAD</th>\n",
              "      <th>N_BEDROOM</th>\n",
              "      <th>N_BATHROOM</th>\n",
              "      <th>N_ROOM</th>\n",
              "      <th>QS_ROOMS</th>\n",
              "      <th>QS_BATHROOM</th>\n",
              "      <th>QS_BEDROOM</th>\n",
              "      <th>QS_OVERALL</th>\n",
              "      <th>DECADE_BUILD</th>\n",
              "      <th>AREA_Anna Nagar</th>\n",
              "      <th>AREA_Chrompet</th>\n",
              "      <th>...</th>\n",
              "      <th>PARK_FACIL_Yes</th>\n",
              "      <th>BUILDTYPE_House</th>\n",
              "      <th>BUILDTYPE_Others</th>\n",
              "      <th>UTILITY_AVAIL_ELO</th>\n",
              "      <th>UTILITY_AVAIL_NoSeWa</th>\n",
              "      <th>STREET_No Access</th>\n",
              "      <th>STREET_Paved</th>\n",
              "      <th>MZZONE_C</th>\n",
              "      <th>MZZONE_I</th>\n",
              "      <th>MZZONE_RH</th>\n",
              "      <th>MZZONE_RL</th>\n",
              "      <th>MZZONE_RM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1501</th>\n",
              "      <td>0.268268</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.536082</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2586</th>\n",
              "      <td>0.416917</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.470790</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>0.544545</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.628866</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>0.533534</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.738832</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>0.319319</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343643</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      INT_SQFT  DIST_MAINROAD  N_BEDROOM  N_BATHROOM  N_ROOM  QS_ROOMS  \\\n",
              "1501  0.268268          0.160   0.000000         0.0    0.25  0.466667   \n",
              "2586  0.416917          0.390   0.333333         0.0    0.50  0.733333   \n",
              "2653  0.544545          0.400   0.333333         0.0    0.50  0.733333   \n",
              "1055  0.533534          0.425   0.000000         0.0    0.50  0.733333   \n",
              "705   0.319319          0.115   0.000000         0.0    0.25  0.200000   \n",
              "\n",
              "      QS_BATHROOM  QS_BEDROOM  QS_OVERALL  DECADE_BUILD  AREA_Anna Nagar  \\\n",
              "1501     0.800000    0.400000    0.536082      0.714286              0.0   \n",
              "2586     0.366667    0.366667    0.470790      0.714286              0.0   \n",
              "2653     0.966667    0.033333    0.628866      0.285714              0.0   \n",
              "1055     0.866667    0.666667    0.738832      0.571429              0.0   \n",
              "705      0.733333    0.000000    0.343643      0.714286              0.0   \n",
              "\n",
              "      AREA_Chrompet  ...  PARK_FACIL_Yes  BUILDTYPE_House  BUILDTYPE_Others  \\\n",
              "1501            0.0  ...             1.0              1.0               0.0   \n",
              "2586            0.0  ...             1.0              1.0               0.0   \n",
              "2653            0.0  ...             1.0              0.0               0.0   \n",
              "1055            0.0  ...             0.0              0.0               0.0   \n",
              "705             1.0  ...             1.0              0.0               0.0   \n",
              "\n",
              "      UTILITY_AVAIL_ELO  UTILITY_AVAIL_NoSeWa  STREET_No Access  STREET_Paved  \\\n",
              "1501                0.0                   1.0               0.0           0.0   \n",
              "2586                0.0                   1.0               0.0           0.0   \n",
              "2653                0.0                   0.0               1.0           0.0   \n",
              "1055                0.0                   1.0               1.0           0.0   \n",
              "705                 0.0                   1.0               0.0           0.0   \n",
              "\n",
              "      MZZONE_C  MZZONE_I  MZZONE_RH  MZZONE_RL  MZZONE_RM  \n",
              "1501       0.0       0.0        0.0        0.0        1.0  \n",
              "2586       0.0       0.0        0.0        0.0        1.0  \n",
              "2653       0.0       0.0        0.0        0.0        0.0  \n",
              "1055       0.0       0.0        0.0        1.0        0.0  \n",
              "705        0.0       0.0        1.0        0.0        0.0  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Chrompet      1192\n",
              "Karapakkam     950\n",
              "KK Nagar       707\n",
              "Velachery      671\n",
              "Adyar          575\n",
              "Anna Nagar     555\n",
              "T Nagar        350\n",
              "Name: AREA, dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_treino['AREA'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Criando o DataFrame que Irá Armazenar os Resultados\n",
        "result = pd.DataFrame(index=ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "INT_SQFT                   int64\n",
              "DIST_MAINROAD              int64\n",
              "N_BEDROOM                float64\n",
              "N_BATHROOM               float64\n",
              "N_ROOM                     int64\n",
              "QS_ROOMS                 float64\n",
              "QS_BATHROOM              float64\n",
              "QS_BEDROOM               float64\n",
              "QS_OVERALL               float64\n",
              "DECADE_BUILD               int64\n",
              "AREA_Anna Nagar            uint8\n",
              "AREA_Chrompet              uint8\n",
              "AREA_KK Nagar              uint8\n",
              "AREA_Karapakkam            uint8\n",
              "AREA_T Nagar               uint8\n",
              "AREA_Velachery             uint8\n",
              "SALE_COND_Adj Land         uint8\n",
              "SALE_COND_Family           uint8\n",
              "SALE_COND_Normal Sale      uint8\n",
              "SALE_COND_Partial          uint8\n",
              "PARK_FACIL_Yes             uint8\n",
              "BUILDTYPE_House            uint8\n",
              "BUILDTYPE_Others           uint8\n",
              "UTILITY_AVAIL_ELO          uint8\n",
              "UTILITY_AVAIL_NoSeWa       uint8\n",
              "STREET_No Access           uint8\n",
              "STREET_Paved               uint8\n",
              "MZZONE_C                   uint8\n",
              "MZZONE_I                   uint8\n",
              "MZZONE_RH                  uint8\n",
              "MZZONE_RL                  uint8\n",
              "MZZONE_RM                  uint8\n",
              "dtype: object"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(np.array(X_val)).flatten()\n",
        "\n",
        "result['Model_1'] = y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model2.predict(np.array(X_val)).flatten()\n",
        "\n",
        "result['Model_2'] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66/66 [==============================] - 0s 703us/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model3.predict(np.array(X_val)).flatten()\n",
        "\n",
        "result['Model_3'] = y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_export = result[['Model_1', 'Model_2', 'Model_3']]\n",
        "\n",
        "result_export.to_csv('Result/LARISSA_IONAFA_ROBERTA_YUMI.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
